{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5228538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2f3d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_path = 'Hetero_Data.xlsx'\n",
    "df = pd.read_excel(excel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "169eff0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(213, 340)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>time.1</th>\n",
       "      <th>time.2</th>\n",
       "      <th>time.3</th>\n",
       "      <th>time.4</th>\n",
       "      <th>time.5</th>\n",
       "      <th>time.6</th>\n",
       "      <th>time.7</th>\n",
       "      <th>time.8</th>\n",
       "      <th>time.9</th>\n",
       "      <th>...</th>\n",
       "      <th>time.330</th>\n",
       "      <th>time.331</th>\n",
       "      <th>time.332</th>\n",
       "      <th>time.333</th>\n",
       "      <th>time.334</th>\n",
       "      <th>time.335</th>\n",
       "      <th>time.336</th>\n",
       "      <th>time.337</th>\n",
       "      <th>time.338</th>\n",
       "      <th>Original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.038189</td>\n",
       "      <td>1.059892</td>\n",
       "      <td>1.034006</td>\n",
       "      <td>1.023853</td>\n",
       "      <td>1.028510</td>\n",
       "      <td>1.030863</td>\n",
       "      <td>1.035258</td>\n",
       "      <td>1.039198</td>\n",
       "      <td>1.042250</td>\n",
       "      <td>...</td>\n",
       "      <td>1.029452</td>\n",
       "      <td>1.019635</td>\n",
       "      <td>1.013665</td>\n",
       "      <td>1.012057</td>\n",
       "      <td>1.018319</td>\n",
       "      <td>1.033108</td>\n",
       "      <td>1.030647</td>\n",
       "      <td>1.020431</td>\n",
       "      <td>1.013621</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.042940</td>\n",
       "      <td>1.067785</td>\n",
       "      <td>1.040393</td>\n",
       "      <td>1.029157</td>\n",
       "      <td>1.033387</td>\n",
       "      <td>1.036497</td>\n",
       "      <td>1.042586</td>\n",
       "      <td>1.049073</td>\n",
       "      <td>1.053859</td>\n",
       "      <td>...</td>\n",
       "      <td>1.035474</td>\n",
       "      <td>1.040027</td>\n",
       "      <td>1.044808</td>\n",
       "      <td>1.045222</td>\n",
       "      <td>1.049973</td>\n",
       "      <td>1.062408</td>\n",
       "      <td>1.053485</td>\n",
       "      <td>1.035657</td>\n",
       "      <td>1.023771</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.050455</td>\n",
       "      <td>1.081516</td>\n",
       "      <td>1.056593</td>\n",
       "      <td>1.046919</td>\n",
       "      <td>1.048408</td>\n",
       "      <td>1.050272</td>\n",
       "      <td>1.052385</td>\n",
       "      <td>1.058426</td>\n",
       "      <td>1.062399</td>\n",
       "      <td>...</td>\n",
       "      <td>1.033852</td>\n",
       "      <td>1.024401</td>\n",
       "      <td>1.016267</td>\n",
       "      <td>1.010845</td>\n",
       "      <td>1.020747</td>\n",
       "      <td>1.049803</td>\n",
       "      <td>1.058463</td>\n",
       "      <td>1.052934</td>\n",
       "      <td>1.038534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.051986</td>\n",
       "      <td>1.080560</td>\n",
       "      <td>1.041552</td>\n",
       "      <td>1.029965</td>\n",
       "      <td>1.039257</td>\n",
       "      <td>1.045918</td>\n",
       "      <td>1.055883</td>\n",
       "      <td>1.066993</td>\n",
       "      <td>1.073642</td>\n",
       "      <td>...</td>\n",
       "      <td>1.354359</td>\n",
       "      <td>1.328754</td>\n",
       "      <td>1.297513</td>\n",
       "      <td>1.242373</td>\n",
       "      <td>1.183352</td>\n",
       "      <td>1.129709</td>\n",
       "      <td>1.089348</td>\n",
       "      <td>1.059565</td>\n",
       "      <td>1.039710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.042848</td>\n",
       "      <td>1.063593</td>\n",
       "      <td>1.020535</td>\n",
       "      <td>1.008532</td>\n",
       "      <td>1.022222</td>\n",
       "      <td>1.027057</td>\n",
       "      <td>1.033692</td>\n",
       "      <td>1.036392</td>\n",
       "      <td>1.036106</td>\n",
       "      <td>...</td>\n",
       "      <td>1.120878</td>\n",
       "      <td>1.095236</td>\n",
       "      <td>1.068684</td>\n",
       "      <td>1.047268</td>\n",
       "      <td>1.035145</td>\n",
       "      <td>1.033099</td>\n",
       "      <td>1.026046</td>\n",
       "      <td>1.017364</td>\n",
       "      <td>1.011576</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 340 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time    time.1    time.2    time.3    time.4    time.5    time.6    time.7  \\\n",
       "0     1  1.038189  1.059892  1.034006  1.023853  1.028510  1.030863  1.035258   \n",
       "1     1  1.042940  1.067785  1.040393  1.029157  1.033387  1.036497  1.042586   \n",
       "2     1  1.050455  1.081516  1.056593  1.046919  1.048408  1.050272  1.052385   \n",
       "3     1  1.051986  1.080560  1.041552  1.029965  1.039257  1.045918  1.055883   \n",
       "4     1  1.042848  1.063593  1.020535  1.008532  1.022222  1.027057  1.033692   \n",
       "\n",
       "     time.8    time.9  ...  time.330  time.331  time.332  time.333  time.334  \\\n",
       "0  1.039198  1.042250  ...  1.029452  1.019635  1.013665  1.012057  1.018319   \n",
       "1  1.049073  1.053859  ...  1.035474  1.040027  1.044808  1.045222  1.049973   \n",
       "2  1.058426  1.062399  ...  1.033852  1.024401  1.016267  1.010845  1.020747   \n",
       "3  1.066993  1.073642  ...  1.354359  1.328754  1.297513  1.242373  1.183352   \n",
       "4  1.036392  1.036106  ...  1.120878  1.095236  1.068684  1.047268  1.035145   \n",
       "\n",
       "   time.335  time.336  time.337  time.338  Original  \n",
       "0  1.033108  1.030647  1.020431  1.013621         1  \n",
       "1  1.062408  1.053485  1.035657  1.023771         1  \n",
       "2  1.049803  1.058463  1.052934  1.038534         1  \n",
       "3  1.129709  1.089348  1.059565  1.039710         1  \n",
       "4  1.033099  1.026046  1.017364  1.011576         1  \n",
       "\n",
       "[5 rows x 340 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f1f3a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of 1s: 52\n",
      "Count of 2s: 52\n",
      "Count of 3s: 55\n",
      "Count of 4s: 54\n"
     ]
    }
   ],
   "source": [
    "# Counting the occurrences of each class in the specified column\n",
    "column_name = 'Original'\n",
    "value_counts = df[column_name].value_counts().sort_index()\n",
    "\n",
    "# Display the counts\n",
    "for value, count in value_counts.items():\n",
    "    print(f'Count of {value}s: {count}')\n",
    "\n",
    "classes = range(1, 5)\n",
    "\n",
    "# Create a dictionary to store separate DataFrames for each class\n",
    "dfs_by_class = {}\n",
    "\n",
    "# Filter the data for each value and store in separate DataFrames\n",
    "for value in classes:\n",
    "    filtered_df = df[df[column_name] == value].head(52)\n",
    "    dfs_by_class[value] = filtered_df\n",
    "\n",
    "# # Access the separate DataFrames using the dictionary\n",
    "# for cls, filtered_df in dfs_by_class.items():\n",
    "#     print(f'DataFrame for {cls}s:')\n",
    "#     print(filtered_df.head())\n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8d38b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameConverter:\n",
    "    def __init__(self, dfs_by_class):\n",
    "        self.dfs_by_class = dfs_by_class\n",
    "\n",
    "    def convert_to_numpy(self):\n",
    "        numpy_data_by_class = {}\n",
    "\n",
    "        for cls, df in self.dfs_by_class.items():\n",
    "            numpy_data = df.iloc[:, :-1].to_numpy()\n",
    "            numpy_data_by_class[cls] = numpy_data\n",
    "\n",
    "        return numpy_data_by_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b417bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrameConverter instance\n",
    "converter = DataFrameConverter(dfs_by_class)\n",
    "\n",
    "# Converting DataFrames to NumPy arrays\n",
    "numpy_data_by_class = converter.convert_to_numpy()\n",
    "\n",
    "# # Accessing the NumPy arrays using the dictionary\n",
    "# for cls, numpy_data in numpy_data_by_class.items():\n",
    "#     print(f'NumPy array for class {cls}:')\n",
    "#     print(numpy_data[:2])\n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "949d30a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlidingWindowProcessor:\n",
    "    def __init__(self, window_size, step):\n",
    "        self.window_size = window_size\n",
    "        self.step = step\n",
    "\n",
    "    def process_data(self, numpy_data):\n",
    "        data_with_windows = []\n",
    "\n",
    "        for row in numpy_data:\n",
    "            samples_row = []\n",
    "            for i in range(0, len(row) - self.window_size + 1, self.step):\n",
    "                window = row[i:i + self.window_size]\n",
    "                samples_row.append(window)\n",
    "            data_with_windows.append(samples_row)\n",
    "\n",
    "        return np.array(data_with_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0cdd4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10\n",
    "step = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b24d3516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 165, 10)\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of SlidingWindowProcessor\n",
    "window_processor = SlidingWindowProcessor(window_size, step)\n",
    "\n",
    "np_data = {}\n",
    "\n",
    "for i in range(1, 5):\n",
    "    np_data[i] = window_processor.process_data(numpy_data_by_class[i])\n",
    "\n",
    "print(np_data[4].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40267bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSplitter:\n",
    "    def __init__(self, s1, s2, s3):\n",
    "        self.s1 = s1\n",
    "        self.s2 = s2\n",
    "        self.s3 = s3\n",
    "        self.class_splitter = {}  # Dictionary to store splitters for each class\n",
    "\n",
    "    def shuffle_and_split(self, data, cls_number):\n",
    "        data_shuffled = shuffle(data, random_state=42)\n",
    "\n",
    "        index1 = int(data_shuffled.shape[0] * self.s1)\n",
    "        index2 = int(data_shuffled.shape[0] * (self.s1 + self.s2))\n",
    "\n",
    "        x_train = data_shuffled[:index1]\n",
    "        x_val = data_shuffled[index1:index2]\n",
    "        x_test = data_shuffled[index2:]\n",
    "\n",
    "        y_train = np.zeros((x_train.shape[0], 4))\n",
    "        y_train[:, cls_number - 1] = 1\n",
    "\n",
    "        y_val = np.zeros((x_val.shape[0], 4))\n",
    "        y_val[:, cls_number - 1] = 1\n",
    "\n",
    "        y_test = np.zeros((x_test.shape[0], 4))\n",
    "        y_test[:, cls_number - 1] = 1\n",
    "\n",
    "        # Save the split data for later concatenation\n",
    "        self.class_splitter[cls_number] = (x_train, x_val, x_test, y_train, y_val, y_test)\n",
    "\n",
    "        return x_train, x_val, x_test, y_train, y_val, y_test\n",
    "\n",
    "    def splitter(self, data, cls_number):\n",
    "        x_train, x_val, x_test, y_train, y_val, y_test = self.shuffle_and_split(data, cls_number)\n",
    "\n",
    "        return x_train, x_val, x_test, y_train, y_val, y_test\n",
    "    \n",
    "    def concatenate_data(self):\n",
    "        # Concatenate data from all classes\n",
    "        x_train_concat = np.concatenate([split[0] for split in self.class_splitter.values()], axis=0)\n",
    "        x_val_concat = np.concatenate([split[1] for split in self.class_splitter.values()], axis=0)\n",
    "        x_test_concat = np.concatenate([split[2] for split in self.class_splitter.values()], axis=0)\n",
    "        y_train_concat = np.concatenate([split[3] for split in self.class_splitter.values()], axis=0)\n",
    "        y_val_concat = np.concatenate([split[4] for split in self.class_splitter.values()], axis=0)\n",
    "        y_test_concat = np.concatenate([split[5] for split in self.class_splitter.values()], axis=0)\n",
    "\n",
    "        return x_train_concat, x_val_concat, x_test_concat, y_train_concat, y_val_concat, y_test_concat\n",
    "    \n",
    "    def __str__(self):\n",
    "        result = \"DataSplitter class:\\n\"\n",
    "        for cls_number, split_data in self.class_splitter.items():\n",
    "            result += f\"Class {cls_number}:\\n\"\n",
    "            result += f\"  x_train shape: {split_data[0].shape}\\n\"\n",
    "            result += f\"  x_val shape: {split_data[1].shape}\\n\"\n",
    "            result += f\"  x_test shape: {split_data[2].shape}\\n\"\n",
    "            result += f\"  y_train shape: {split_data[3].shape}\\n\"\n",
    "            result += f\"  y_val shape: {split_data[4].shape}\\n\"\n",
    "            result += f\"  y_test shape: {split_data[5].shape}\\n\"\n",
    "            result += \"\\n\"\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1abd3175",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = DataSplitter(s1=0.7, s2=0.1, s3=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "716ce770",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, x_test, y_train, y_val, y_test= {}, {}, {}, {}, {}, {}\n",
    "\n",
    "for i in range(1,5):\n",
    "    x_train[i], x_val[i], x_test[i], y_train[i], x_val[i], y_test[i] = p.splitter(np_data[i], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce700a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSplitter class:\n",
      "Class 1:\n",
      "  x_train shape: (36, 165, 10)\n",
      "  x_val shape: (5, 165, 10)\n",
      "  x_test shape: (11, 165, 10)\n",
      "  y_train shape: (36, 4)\n",
      "  y_val shape: (5, 4)\n",
      "  y_test shape: (11, 4)\n",
      "\n",
      "Class 2:\n",
      "  x_train shape: (36, 165, 10)\n",
      "  x_val shape: (5, 165, 10)\n",
      "  x_test shape: (11, 165, 10)\n",
      "  y_train shape: (36, 4)\n",
      "  y_val shape: (5, 4)\n",
      "  y_test shape: (11, 4)\n",
      "\n",
      "Class 3:\n",
      "  x_train shape: (36, 165, 10)\n",
      "  x_val shape: (5, 165, 10)\n",
      "  x_test shape: (11, 165, 10)\n",
      "  y_train shape: (36, 4)\n",
      "  y_val shape: (5, 4)\n",
      "  y_test shape: (11, 4)\n",
      "\n",
      "Class 4:\n",
      "  x_train shape: (36, 165, 10)\n",
      "  x_val shape: (5, 165, 10)\n",
      "  x_test shape: (11, 165, 10)\n",
      "  y_train shape: (36, 4)\n",
      "  y_val shape: (5, 4)\n",
      "  y_test shape: (11, 4)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a0b1559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 165, 10)\n",
      "(20, 165, 10)\n",
      "(44, 165, 10)\n",
      "(144, 4)\n",
      "(20, 4)\n",
      "(44, 4)\n",
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "x_train1, x_val1, x_test1, y_train1, y_val1, y_test1 = p.concatenate_data()\n",
    "\n",
    "print(x_train1.shape)\n",
    "print(x_val1.shape)\n",
    "print(x_test1.shape)\n",
    "print(y_train1.shape)\n",
    "print(y_val1.shape)\n",
    "print(y_test1.shape)\n",
    "print(y_test1[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2ed515f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "indices_1 = list(np.arange(len(x_train1)))\n",
    "random.shuffle(indices_1)\n",
    "x_train = x_train1[indices_1]\n",
    "y_train = y_train1[indices_1]\n",
    "\n",
    "indices_2 = list(np.arange(len(x_val1)))\n",
    "random.shuffle(indices_2)\n",
    "x_val = x_val1[indices_2]\n",
    "y_val = y_val1[indices_2]\n",
    "\n",
    "indices_3 = list(np.arange(len(x_test1)))\n",
    "random.shuffle(indices_3)\n",
    "x_test = x_test1[indices_3]\n",
    "y_test = y_test1[indices_3]\n",
    "\n",
    "print(y_test[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "855a9f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, History, ReduceLROnPlateau\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a99210ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kishore\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,376</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m165\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,376\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,588</span> (14.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,588\u001b[0m (14.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,588</span> (14.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,588\u001b[0m (14.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a RNN model\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(SimpleRNN(32, input_shape = (165, 10), activation = 'relu', return_sequences = True))\n",
    "rnn_model.add(SimpleRNN(32, activation = 'relu'))\n",
    "rnn_model.add(Dense(4, activation = 'softmax'))\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96f5cf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2381 - loss: 1.5653 - rmse: 0.4557\n",
      "Epoch 1: val_loss improved from inf to 1.40502, saving model to best_rnn_model_weights.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.2378 - loss: 1.5581 - rmse: 0.4548 - val_accuracy: 0.2500 - val_loss: 1.4050 - val_rmse: 0.4358\n",
      "Epoch 2/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2179 - loss: 1.4032 - rmse: 0.4356\n",
      "Epoch 2: val_loss improved from 1.40502 to 1.38748, saving model to best_rnn_model_weights.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.2188 - loss: 1.4029 - rmse: 0.4355 - val_accuracy: 0.3000 - val_loss: 1.3875 - val_rmse: 0.4332\n",
      "Epoch 3/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2663 - loss: 1.3832 - rmse: 0.4326\n",
      "Epoch 3: val_loss improved from 1.38748 to 1.38522, saving model to best_rnn_model_weights.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.2662 - loss: 1.3833 - rmse: 0.4326 - val_accuracy: 0.3000 - val_loss: 1.3852 - val_rmse: 0.4328\n",
      "Epoch 4/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2410 - loss: 1.3853 - rmse: 0.4328\n",
      "Epoch 4: val_loss improved from 1.38522 to 1.38012, saving model to best_rnn_model_weights.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.2408 - loss: 1.3855 - rmse: 0.4329 - val_accuracy: 0.3500 - val_loss: 1.3801 - val_rmse: 0.4321\n",
      "Epoch 5/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2774 - loss: 1.3776 - rmse: 0.4317\n",
      "Epoch 5: val_loss did not improve from 1.38012\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.2772 - loss: 1.3776 - rmse: 0.4317 - val_accuracy: 0.3000 - val_loss: 1.3803 - val_rmse: 0.4321\n",
      "Epoch 6/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.2261 - loss: 1.3798 - rmse: 0.4321\n",
      "Epoch 6: val_loss improved from 1.38012 to 1.37184, saving model to best_rnn_model_weights.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.2268 - loss: 1.3798 - rmse: 0.4321 - val_accuracy: 0.2500 - val_loss: 1.3718 - val_rmse: 0.4308\n",
      "Epoch 7/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3502 - loss: 1.3744 - rmse: 0.4313\n",
      "Epoch 7: val_loss did not improve from 1.37184\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3477 - loss: 1.3748 - rmse: 0.4313 - val_accuracy: 0.2500 - val_loss: 1.3829 - val_rmse: 0.4328\n",
      "Epoch 8/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.2529 - loss: 1.3834 - rmse: 0.4326\n",
      "Epoch 8: val_loss improved from 1.37184 to 1.35927, saving model to best_rnn_model_weights.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.2534 - loss: 1.3832 - rmse: 0.4326 - val_accuracy: 0.3500 - val_loss: 1.3593 - val_rmse: 0.4290\n",
      "Epoch 9/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4044 - loss: 1.3494 - rmse: 0.4270\n",
      "Epoch 9: val_loss improved from 1.35927 to 1.35308, saving model to best_rnn_model_weights.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.4030 - loss: 1.3497 - rmse: 0.4271 - val_accuracy: 0.4000 - val_loss: 1.3531 - val_rmse: 0.4283\n",
      "Epoch 10/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3311 - loss: 1.3427 - rmse: 0.4260\n",
      "Epoch 10: val_loss did not improve from 1.35308\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.3279 - loss: 1.3436 - rmse: 0.4261 - val_accuracy: 0.1000 - val_loss: 1.3532 - val_rmse: 0.4294\n",
      "Epoch 11/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2806 - loss: 1.3504 - rmse: 0.4274\n",
      "Epoch 11: val_loss did not improve from 1.35308\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.2813 - loss: 1.3504 - rmse: 0.4274 - val_accuracy: 0.2500 - val_loss: 1.3629 - val_rmse: 0.4310\n",
      "Epoch 12/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3111 - loss: 1.3338 - rmse: 0.4244\n",
      "Epoch 12: val_loss improved from 1.35308 to 1.34126, saving model to best_rnn_model_weights.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.3146 - loss: 1.3348 - rmse: 0.4246 - val_accuracy: 0.3500 - val_loss: 1.3413 - val_rmse: 0.4268\n",
      "Epoch 13/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3477 - loss: 1.3408 - rmse: 0.4264\n",
      "Epoch 13: val_loss did not improve from 1.34126\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.3453 - loss: 1.3423 - rmse: 0.4266 - val_accuracy: 0.4000 - val_loss: 1.3616 - val_rmse: 0.4295\n",
      "Epoch 14/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2720 - loss: 1.3662 - rmse: 0.4301\n",
      "Epoch 14: val_loss did not improve from 1.34126\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.2752 - loss: 1.3662 - rmse: 0.4301 - val_accuracy: 0.4000 - val_loss: 1.3622 - val_rmse: 0.4293\n",
      "Epoch 15/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3203 - loss: 1.3464 - rmse: 0.4271\n",
      "Epoch 15: val_loss did not improve from 1.34126\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.3184 - loss: 1.3468 - rmse: 0.4272 - val_accuracy: 0.2500 - val_loss: 1.3701 - val_rmse: 0.4308\n",
      "Epoch 16/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.2765 - loss: 1.3530 - rmse: 0.4281\n",
      "Epoch 16: val_loss did not improve from 1.34126\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.2765 - loss: 1.3530 - rmse: 0.4281 - val_accuracy: 0.4000 - val_loss: 1.3557 - val_rmse: 0.4286\n",
      "Epoch 17/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5069 - loss: 1.3363 - rmse: 0.4256\n",
      "Epoch 17: val_loss did not improve from 1.34126\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5035 - loss: 1.3366 - rmse: 0.4256 - val_accuracy: 0.3500 - val_loss: 1.3435 - val_rmse: 0.4267\n",
      "Epoch 18/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3580 - loss: 1.3333 - rmse: 0.4251\n",
      "Epoch 18: val_loss improved from 1.34126 to 1.33057, saving model to best_rnn_model_weights.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3580 - loss: 1.3333 - rmse: 0.4251 - val_accuracy: 0.4500 - val_loss: 1.3306 - val_rmse: 0.4245\n",
      "Epoch 19/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5096 - loss: 1.3134 - rmse: 0.4220\n",
      "Epoch 19: val_loss improved from 1.33057 to 1.32605, saving model to best_rnn_model_weights.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5080 - loss: 1.3137 - rmse: 0.4221 - val_accuracy: 0.4000 - val_loss: 1.3261 - val_rmse: 0.4242\n",
      "Epoch 20/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4152 - loss: 1.2973 - rmse: 0.4194\n",
      "Epoch 20: val_loss improved from 1.32605 to 1.29668, saving model to best_rnn_model_weights.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.4123 - loss: 1.2977 - rmse: 0.4195 - val_accuracy: 0.3500 - val_loss: 1.2967 - val_rmse: 0.4193\n",
      "Epoch 21/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4748 - loss: 1.2967 - rmse: 0.4194\n",
      "Epoch 21: val_loss improved from 1.29668 to 1.28842, saving model to best_rnn_model_weights.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.4746 - loss: 1.2966 - rmse: 0.4194 - val_accuracy: 0.5000 - val_loss: 1.2884 - val_rmse: 0.4172\n",
      "Epoch 22/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5683 - loss: 1.2780 - rmse: 0.4160\n",
      "Epoch 22: val_loss improved from 1.28842 to 1.23368, saving model to best_rnn_model_weights.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5613 - loss: 1.2775 - rmse: 0.4160 - val_accuracy: 0.3500 - val_loss: 1.2337 - val_rmse: 0.4096\n",
      "Epoch 23/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3661 - loss: 1.2040 - rmse: 0.4053\n",
      "Epoch 23: val_loss improved from 1.23368 to 1.20483, saving model to best_rnn_model_weights.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.3704 - loss: 1.2062 - rmse: 0.4056 - val_accuracy: 0.6000 - val_loss: 1.2048 - val_rmse: 0.4029\n",
      "Epoch 24/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5178 - loss: 1.1862 - rmse: 0.4015\n",
      "Epoch 24: val_loss improved from 1.20483 to 1.19391, saving model to best_rnn_model_weights.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5182 - loss: 1.1859 - rmse: 0.4015 - val_accuracy: 0.5500 - val_loss: 1.1939 - val_rmse: 0.4049\n",
      "Epoch 25/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5667 - loss: 1.2324 - rmse: 0.4082\n",
      "Epoch 25: val_loss improved from 1.19391 to 1.03405, saving model to best_rnn_model_weights.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5659 - loss: 1.2311 - rmse: 0.4080 - val_accuracy: 0.6000 - val_loss: 1.0340 - val_rmse: 0.3755\n",
      "Epoch 26/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3929 - loss: 1.1657 - rmse: 0.3996\n",
      "Epoch 26: val_loss did not improve from 1.03405\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3930 - loss: 1.1669 - rmse: 0.3998 - val_accuracy: 0.4500 - val_loss: 1.2212 - val_rmse: 0.4114\n",
      "Epoch 27/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4859 - loss: 1.1742 - rmse: 0.4000\n",
      "Epoch 27: val_loss did not improve from 1.03405\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.4864 - loss: 1.1736 - rmse: 0.3999 - val_accuracy: 0.3500 - val_loss: 1.6584 - val_rmse: 0.4582\n",
      "Epoch 28/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4133 - loss: 1.2921 - rmse: 0.4175\n",
      "Epoch 28: val_loss did not improve from 1.03405\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4173 - loss: 1.2883 - rmse: 0.4170 - val_accuracy: 0.4500 - val_loss: 1.2652 - val_rmse: 0.4134\n",
      "Epoch 29/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5421 - loss: 1.1620 - rmse: 0.3978\n",
      "Epoch 29: val_loss did not improve from 1.03405\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5373 - loss: 1.1627 - rmse: 0.3980 - val_accuracy: 0.4000 - val_loss: 1.1938 - val_rmse: 0.4065\n",
      "Epoch 30/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4387 - loss: 1.1456 - rmse: 0.3988\n",
      "Epoch 30: val_loss did not improve from 1.03405\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4404 - loss: 1.1449 - rmse: 0.3986 - val_accuracy: 0.4000 - val_loss: 1.2938 - val_rmse: 0.4223\n",
      "Epoch 31/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5023 - loss: 1.0843 - rmse: 0.3875\n",
      "Epoch 31: val_loss did not improve from 1.03405\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5004 - loss: 1.0870 - rmse: 0.3879 - val_accuracy: 0.5500 - val_loss: 1.0964 - val_rmse: 0.3887\n",
      "Epoch 32/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6579 - loss: 0.9646 - rmse: 0.3577\n",
      "Epoch 32: val_loss did not improve from 1.03405\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6539 - loss: 0.9694 - rmse: 0.3588 - val_accuracy: 0.5500 - val_loss: 1.1460 - val_rmse: 0.3966\n",
      "Epoch 33/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6237 - loss: 0.9571 - rmse: 0.3609\n",
      "Epoch 33: val_loss improved from 1.03405 to 1.01913, saving model to best_rnn_model_weights.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6216 - loss: 0.9598 - rmse: 0.3615 - val_accuracy: 0.6000 - val_loss: 1.0191 - val_rmse: 0.3716\n",
      "Epoch 34/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6064 - loss: 1.0241 - rmse: 0.3746\n",
      "Epoch 34: val_loss improved from 1.01913 to 0.99726, saving model to best_rnn_model_weights.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6086 - loss: 1.0227 - rmse: 0.3743 - val_accuracy: 0.6500 - val_loss: 0.9973 - val_rmse: 0.3643\n",
      "Epoch 35/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6816 - loss: 0.8736 - rmse: 0.3383\n",
      "Epoch 35: val_loss did not improve from 0.99726\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6791 - loss: 0.8770 - rmse: 0.3391 - val_accuracy: 0.6000 - val_loss: 1.0980 - val_rmse: 0.3792\n",
      "Epoch 36/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6321 - loss: 0.9728 - rmse: 0.3661\n",
      "Epoch 36: val_loss did not improve from 0.99726\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6320 - loss: 0.9719 - rmse: 0.3658 - val_accuracy: 0.5500 - val_loss: 1.1352 - val_rmse: 0.3962\n",
      "Epoch 37/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6385 - loss: 0.8790 - rmse: 0.3484\n",
      "Epoch 37: val_loss did not improve from 0.99726\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6372 - loss: 0.8810 - rmse: 0.3488 - val_accuracy: 0.6000 - val_loss: 1.0167 - val_rmse: 0.3668\n",
      "Epoch 38/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6509 - loss: 0.9229 - rmse: 0.3538\n",
      "Epoch 38: val_loss did not improve from 0.99726\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6455 - loss: 0.9269 - rmse: 0.3548 - val_accuracy: 0.5000 - val_loss: 1.1219 - val_rmse: 0.3913\n",
      "Epoch 39/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5635 - loss: 1.0798 - rmse: 0.3865\n",
      "Epoch 39: val_loss did not improve from 0.99726\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5646 - loss: 1.0797 - rmse: 0.3864 - val_accuracy: 0.4000 - val_loss: 1.1879 - val_rmse: 0.4031\n",
      "Epoch 40/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5713 - loss: 1.0441 - rmse: 0.3759\n",
      "Epoch 40: val_loss did not improve from 0.99726\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5693 - loss: 1.0454 - rmse: 0.3762 - val_accuracy: 0.5500 - val_loss: 1.0118 - val_rmse: 0.3715\n",
      "Epoch 41/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5984 - loss: 1.0008 - rmse: 0.3691\n",
      "Epoch 41: val_loss improved from 0.99726 to 0.89177, saving model to best_rnn_model_weights.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5961 - loss: 1.0032 - rmse: 0.3696 - val_accuracy: 0.7500 - val_loss: 0.8918 - val_rmse: 0.3419\n",
      "Epoch 42/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5080 - loss: 1.0939 - rmse: 0.3899\n",
      "Epoch 42: val_loss did not improve from 0.89177\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5095 - loss: 1.0939 - rmse: 0.3897 - val_accuracy: 0.6000 - val_loss: 1.0958 - val_rmse: 0.3857\n",
      "Epoch 43/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5771 - loss: 1.0972 - rmse: 0.3814\n",
      "Epoch 43: val_loss did not improve from 0.89177\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5760 - loss: 1.0968 - rmse: 0.3814 - val_accuracy: 0.7000 - val_loss: 0.9806 - val_rmse: 0.3617\n",
      "Epoch 44/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5523 - loss: 1.0666 - rmse: 0.3834\n",
      "Epoch 44: val_loss did not improve from 0.89177\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5511 - loss: 1.0647 - rmse: 0.3829 - val_accuracy: 0.6000 - val_loss: 0.9392 - val_rmse: 0.3529\n",
      "Epoch 45/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6271 - loss: 0.9541 - rmse: 0.3605\n",
      "Epoch 45: val_loss did not improve from 0.89177\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6234 - loss: 0.9566 - rmse: 0.3611 - val_accuracy: 0.7000 - val_loss: 0.9942 - val_rmse: 0.3670\n",
      "Epoch 46/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5147 - loss: 1.0258 - rmse: 0.3766\n",
      "Epoch 46: val_loss did not improve from 0.89177\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5184 - loss: 1.0223 - rmse: 0.3758 - val_accuracy: 0.6000 - val_loss: 0.9717 - val_rmse: 0.3620\n",
      "Epoch 47/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6218 - loss: 0.9040 - rmse: 0.3507\n",
      "Epoch 47: val_loss improved from 0.89177 to 0.89017, saving model to best_rnn_model_weights.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6201 - loss: 0.9056 - rmse: 0.3511 - val_accuracy: 0.5500 - val_loss: 0.8902 - val_rmse: 0.3457\n",
      "Epoch 48/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6067 - loss: 0.9186 - rmse: 0.3543\n",
      "Epoch 48: val_loss improved from 0.89017 to 0.88495, saving model to best_rnn_model_weights.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6092 - loss: 0.9173 - rmse: 0.3540 - val_accuracy: 0.6000 - val_loss: 0.8849 - val_rmse: 0.3431\n",
      "Epoch 49/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6153 - loss: 0.9032 - rmse: 0.3517\n",
      "Epoch 49: val_loss did not improve from 0.88495\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6160 - loss: 0.9044 - rmse: 0.3519 - val_accuracy: 0.6000 - val_loss: 0.9159 - val_rmse: 0.3492\n",
      "Epoch 50/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6631 - loss: 0.8863 - rmse: 0.3447\n",
      "Epoch 50: val_loss improved from 0.88495 to 0.88012, saving model to best_rnn_model_weights.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6630 - loss: 0.8868 - rmse: 0.3449 - val_accuracy: 0.7000 - val_loss: 0.8801 - val_rmse: 0.3416\n",
      "Epoch 51/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6733 - loss: 0.8455 - rmse: 0.3396\n",
      "Epoch 51: val_loss did not improve from 0.88012\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6731 - loss: 0.8463 - rmse: 0.3397 - val_accuracy: 0.6000 - val_loss: 0.9384 - val_rmse: 0.3544\n",
      "Epoch 52/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6951 - loss: 0.8226 - rmse: 0.3356\n",
      "Epoch 52: val_loss did not improve from 0.88012\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6899 - loss: 0.8275 - rmse: 0.3367 - val_accuracy: 0.6500 - val_loss: 0.9408 - val_rmse: 0.3545\n",
      "Epoch 53/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6433 - loss: 0.9120 - rmse: 0.3476\n",
      "Epoch 53: val_loss did not improve from 0.88012\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6442 - loss: 0.9090 - rmse: 0.3474 - val_accuracy: 0.5000 - val_loss: 1.0153 - val_rmse: 0.3762\n",
      "Epoch 54/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6065 - loss: 0.8779 - rmse: 0.3455\n",
      "Epoch 54: val_loss improved from 0.88012 to 0.81167, saving model to best_rnn_model_weights.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6094 - loss: 0.8791 - rmse: 0.3455 - val_accuracy: 0.7000 - val_loss: 0.8117 - val_rmse: 0.3323\n",
      "Epoch 55/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6223 - loss: 0.9299 - rmse: 0.3422\n",
      "Epoch 55: val_loss did not improve from 0.81167\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6181 - loss: 0.9371 - rmse: 0.3441 - val_accuracy: 0.5000 - val_loss: 1.1215 - val_rmse: 0.3919\n",
      "Epoch 56/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5217 - loss: 1.1359 - rmse: 0.3880\n",
      "Epoch 56: val_loss did not improve from 0.81167\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5171 - loss: 1.1404 - rmse: 0.3890 - val_accuracy: 0.5500 - val_loss: 1.3243 - val_rmse: 0.4125\n",
      "Epoch 57/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5411 - loss: 1.1549 - rmse: 0.3957\n",
      "Epoch 57: val_loss did not improve from 0.81167\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5409 - loss: 1.1547 - rmse: 0.3957 - val_accuracy: 0.5500 - val_loss: 1.3338 - val_rmse: 0.4176\n",
      "Epoch 58/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5953 - loss: 1.0145 - rmse: 0.3720\n",
      "Epoch 58: val_loss did not improve from 0.81167\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5946 - loss: 1.0158 - rmse: 0.3722 - val_accuracy: 0.5000 - val_loss: 1.2672 - val_rmse: 0.4077\n",
      "Epoch 59/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6331 - loss: 0.9677 - rmse: 0.3604\n",
      "Epoch 59: val_loss did not improve from 0.81167\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6310 - loss: 0.9698 - rmse: 0.3608 - val_accuracy: 0.5000 - val_loss: 1.2526 - val_rmse: 0.4063\n",
      "Epoch 60/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6368 - loss: 0.8965 - rmse: 0.3470\n",
      "Epoch 60: val_loss did not improve from 0.81167\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6365 - loss: 0.8963 - rmse: 0.3470 - val_accuracy: 0.5000 - val_loss: 1.1352 - val_rmse: 0.3845\n",
      "Epoch 61/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5614 - loss: 1.0998 - rmse: 0.3686\n",
      "Epoch 61: val_loss did not improve from 0.81167\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5579 - loss: 1.1130 - rmse: 0.3698 - val_accuracy: 0.4000 - val_loss: 1.2330 - val_rmse: 0.4136\n",
      "Epoch 62/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4283 - loss: 1.2245 - rmse: 0.4063\n",
      "Epoch 62: val_loss did not improve from 0.81167\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4310 - loss: 1.2221 - rmse: 0.4060 - val_accuracy: 0.5500 - val_loss: 1.0711 - val_rmse: 0.3793\n",
      "Epoch 63/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5124 - loss: 1.1101 - rmse: 0.3849\n",
      "Epoch 63: val_loss did not improve from 0.81167\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5157 - loss: 1.1075 - rmse: 0.3848 - val_accuracy: 0.5500 - val_loss: 1.0297 - val_rmse: 0.3715\n",
      "Epoch 64/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5944 - loss: 1.0353 - rmse: 0.3761\n",
      "Epoch 64: val_loss did not improve from 0.81167\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5941 - loss: 1.0352 - rmse: 0.3760 - val_accuracy: 0.6000 - val_loss: 0.9962 - val_rmse: 0.3638\n",
      "Epoch 65/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5235 - loss: 1.1198 - rmse: 0.3892\n",
      "Epoch 65: val_loss did not improve from 0.81167\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5259 - loss: 1.1150 - rmse: 0.3884 - val_accuracy: 0.6500 - val_loss: 1.0210 - val_rmse: 0.3674\n",
      "Epoch 66/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5862 - loss: 1.0157 - rmse: 0.3726\n",
      "Epoch 66: val_loss did not improve from 0.81167\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5875 - loss: 1.0145 - rmse: 0.3724 - val_accuracy: 0.7000 - val_loss: 0.9705 - val_rmse: 0.3577\n",
      "Epoch 67/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6585 - loss: 0.9192 - rmse: 0.3503\n",
      "Epoch 67: val_loss did not improve from 0.81167\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6572 - loss: 0.9208 - rmse: 0.3509 - val_accuracy: 0.6500 - val_loss: 0.9280 - val_rmse: 0.3502\n",
      "Epoch 68/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6767 - loss: 0.8830 - rmse: 0.3443\n",
      "Epoch 68: val_loss did not improve from 0.81167\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6760 - loss: 0.8839 - rmse: 0.3445 - val_accuracy: 0.7000 - val_loss: 0.9090 - val_rmse: 0.3423\n",
      "Epoch 69/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6304 - loss: 0.9456 - rmse: 0.3555\n",
      "Epoch 69: val_loss did not improve from 0.81167\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6317 - loss: 0.9431 - rmse: 0.3552 - val_accuracy: 0.7500 - val_loss: 0.9374 - val_rmse: 0.3503\n",
      "Epoch 70/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6922 - loss: 0.8803 - rmse: 0.3476\n",
      "Epoch 70: val_loss did not improve from 0.81167\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6919 - loss: 0.8800 - rmse: 0.3475 - val_accuracy: 0.7500 - val_loss: 0.8839 - val_rmse: 0.3408\n",
      "Epoch 71/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6498 - loss: 0.9666 - rmse: 0.3644\n",
      "Epoch 71: val_loss did not improve from 0.81167\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6516 - loss: 0.9585 - rmse: 0.3628 - val_accuracy: 0.6500 - val_loss: 0.8683 - val_rmse: 0.3420\n",
      "Epoch 72/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6651 - loss: 0.8458 - rmse: 0.3413\n",
      "Epoch 72: val_loss did not improve from 0.81167\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6655 - loss: 0.8455 - rmse: 0.3412 - val_accuracy: 0.7500 - val_loss: 0.8959 - val_rmse: 0.3456\n",
      "Epoch 73/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6936 - loss: 0.8327 - rmse: 0.3356\n",
      "Epoch 73: val_loss did not improve from 0.81167\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6934 - loss: 0.8327 - rmse: 0.3356 - val_accuracy: 0.6000 - val_loss: 0.9013 - val_rmse: 0.3491\n",
      "Epoch 74/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7102 - loss: 0.7737 - rmse: 0.3170\n",
      "Epoch 74: val_loss did not improve from 0.81167\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7088 - loss: 0.7764 - rmse: 0.3177 - val_accuracy: 0.7000 - val_loss: 0.8476 - val_rmse: 0.3342\n",
      "Epoch 75/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6504 - loss: 0.8237 - rmse: 0.3418\n",
      "Epoch 75: val_loss did not improve from 0.81167\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6492 - loss: 0.8256 - rmse: 0.3422 - val_accuracy: 0.6500 - val_loss: 0.8926 - val_rmse: 0.3476\n",
      "Epoch 76/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7221 - loss: 0.7078 - rmse: 0.3051\n",
      "Epoch 76: val_loss improved from 0.81167 to 0.80357, saving model to best_rnn_model_weights.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7179 - loss: 0.7183 - rmse: 0.3075 - val_accuracy: 0.6500 - val_loss: 0.8036 - val_rmse: 0.3277\n",
      "Epoch 77/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7022 - loss: 0.7501 - rmse: 0.3196\n",
      "Epoch 77: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7014 - loss: 0.7527 - rmse: 0.3202 - val_accuracy: 0.5000 - val_loss: 1.0538 - val_rmse: 0.3831\n",
      "Epoch 78/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5340 - loss: 1.1084 - rmse: 0.3837\n",
      "Epoch 78: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5351 - loss: 1.1055 - rmse: 0.3833 - val_accuracy: 0.7000 - val_loss: 0.9107 - val_rmse: 0.3511\n",
      "Epoch 79/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5872 - loss: 0.9765 - rmse: 0.3651\n",
      "Epoch 79: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5886 - loss: 0.9744 - rmse: 0.3648 - val_accuracy: 0.5500 - val_loss: 0.8937 - val_rmse: 0.3527\n",
      "Epoch 80/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7115 - loss: 0.8627 - rmse: 0.3447\n",
      "Epoch 80: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7113 - loss: 0.8594 - rmse: 0.3440 - val_accuracy: 0.6000 - val_loss: 0.8972 - val_rmse: 0.3499\n",
      "Epoch 81/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7053 - loss: 0.8170 - rmse: 0.3357\n",
      "Epoch 81: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7062 - loss: 0.8138 - rmse: 0.3351 - val_accuracy: 0.4500 - val_loss: 1.1286 - val_rmse: 0.3993\n",
      "Epoch 82/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6827 - loss: 0.8001 - rmse: 0.3323\n",
      "Epoch 82: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6815 - loss: 0.8002 - rmse: 0.3323 - val_accuracy: 0.5500 - val_loss: 0.9220 - val_rmse: 0.3531\n",
      "Epoch 83/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7514 - loss: 0.7212 - rmse: 0.3071\n",
      "Epoch 83: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7498 - loss: 0.7233 - rmse: 0.3078 - val_accuracy: 0.5500 - val_loss: 0.9161 - val_rmse: 0.3552\n",
      "Epoch 84/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6625 - loss: 0.7631 - rmse: 0.3226\n",
      "Epoch 84: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6633 - loss: 0.7631 - rmse: 0.3226 - val_accuracy: 0.6000 - val_loss: 0.8609 - val_rmse: 0.3411\n",
      "Epoch 85/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7347 - loss: 0.7662 - rmse: 0.3189\n",
      "Epoch 85: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7334 - loss: 0.7682 - rmse: 0.3194 - val_accuracy: 0.5000 - val_loss: 1.0810 - val_rmse: 0.3914\n",
      "Epoch 86/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6664 - loss: 0.8653 - rmse: 0.3401\n",
      "Epoch 86: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6666 - loss: 0.8648 - rmse: 0.3401 - val_accuracy: 0.6500 - val_loss: 0.9304 - val_rmse: 0.3535\n",
      "Epoch 87/1500\n",
      "\u001b[1m33/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6696 - loss: 0.8357 - rmse: 0.3409\n",
      "Epoch 87: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6787 - loss: 0.8238 - rmse: 0.3382 - val_accuracy: 0.7000 - val_loss: 0.8442 - val_rmse: 0.3361\n",
      "Epoch 88/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7925 - loss: 0.6447 - rmse: 0.2958\n",
      "Epoch 88: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7902 - loss: 0.6469 - rmse: 0.2964 - val_accuracy: 0.6000 - val_loss: 0.9848 - val_rmse: 0.3605\n",
      "Epoch 89/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6352 - loss: 0.8863 - rmse: 0.3459\n",
      "Epoch 89: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6361 - loss: 0.8849 - rmse: 0.3457 - val_accuracy: 0.6500 - val_loss: 0.9321 - val_rmse: 0.3532\n",
      "Epoch 90/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7122 - loss: 0.6795 - rmse: 0.3039\n",
      "Epoch 90: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7119 - loss: 0.6806 - rmse: 0.3042 - val_accuracy: 0.3000 - val_loss: 2.0432 - val_rmse: 0.4689\n",
      "Epoch 91/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5448 - loss: 1.1254 - rmse: 0.3836\n",
      "Epoch 91: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5429 - loss: 1.1234 - rmse: 0.3836 - val_accuracy: 0.5000 - val_loss: 1.1410 - val_rmse: 0.3796\n",
      "Epoch 92/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6265 - loss: 0.9798 - rmse: 0.3636\n",
      "Epoch 92: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6260 - loss: 0.9797 - rmse: 0.3635 - val_accuracy: 0.6500 - val_loss: 0.9815 - val_rmse: 0.3615\n",
      "Epoch 93/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6751 - loss: 0.8543 - rmse: 0.3425\n",
      "Epoch 93: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6715 - loss: 0.8595 - rmse: 0.3435 - val_accuracy: 0.6500 - val_loss: 0.9414 - val_rmse: 0.3546\n",
      "Epoch 94/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6415 - loss: 0.9335 - rmse: 0.3556\n",
      "Epoch 94: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6432 - loss: 0.9297 - rmse: 0.3549 - val_accuracy: 0.7000 - val_loss: 0.9037 - val_rmse: 0.3504\n",
      "Epoch 95/1500\n",
      "\u001b[1m33/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6860 - loss: 0.7917 - rmse: 0.3317\n",
      "Epoch 95: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6869 - loss: 0.7942 - rmse: 0.3320 - val_accuracy: 0.7000 - val_loss: 0.8898 - val_rmse: 0.3448\n",
      "Epoch 96/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6661 - loss: 1.1420 - rmse: 0.3467\n",
      "Epoch 96: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6635 - loss: 1.1793 - rmse: 0.3485 - val_accuracy: 0.1500 - val_loss: 5.1666 - val_rmse: 0.6080\n",
      "Epoch 97/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2100 - loss: 3.1883 - rmse: 0.5029\n",
      "Epoch 97: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.2165 - loss: 3.0797 - rmse: 0.4987 - val_accuracy: 0.4000 - val_loss: 1.2660 - val_rmse: 0.4129\n",
      "Epoch 98/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3889 - loss: 1.2331 - rmse: 0.4086\n",
      "Epoch 98: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3882 - loss: 1.2346 - rmse: 0.4088 - val_accuracy: 0.5000 - val_loss: 1.2176 - val_rmse: 0.4024\n",
      "Epoch 99/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4010 - loss: 1.2339 - rmse: 0.4082\n",
      "Epoch 99: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4005 - loss: 1.2345 - rmse: 0.4083 - val_accuracy: 0.5500 - val_loss: 1.1889 - val_rmse: 0.3967\n",
      "Epoch 100/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3896 - loss: 1.2384 - rmse: 0.4133\n",
      "Epoch 100: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3903 - loss: 1.2389 - rmse: 0.4132 - val_accuracy: 0.6500 - val_loss: 1.1751 - val_rmse: 0.3940\n",
      "Epoch 101/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3504 - loss: 1.2909 - rmse: 0.4160\n",
      "Epoch 101: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3544 - loss: 1.2879 - rmse: 0.4156 - val_accuracy: 0.6500 - val_loss: 1.1745 - val_rmse: 0.3932\n",
      "Epoch 102/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4145 - loss: 1.2452 - rmse: 0.4121\n",
      "Epoch 102: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.4131 - loss: 1.2463 - rmse: 0.4122 - val_accuracy: 0.4000 - val_loss: 1.2279 - val_rmse: 0.4049\n",
      "Epoch 103/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4586 - loss: 1.2532 - rmse: 0.4120\n",
      "Epoch 103: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.4582 - loss: 1.2556 - rmse: 0.4124 - val_accuracy: 0.5500 - val_loss: 1.2653 - val_rmse: 0.4124\n",
      "Epoch 104/1500\n",
      "\u001b[1m33/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4295 - loss: 1.2950 - rmse: 0.4193\n",
      "Epoch 104: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4342 - loss: 1.2926 - rmse: 0.4189 - val_accuracy: 0.5500 - val_loss: 1.2276 - val_rmse: 0.4055\n",
      "Epoch 105/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4351 - loss: 1.2551 - rmse: 0.4126\n",
      "Epoch 105: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4385 - loss: 1.2541 - rmse: 0.4124 - val_accuracy: 0.6000 - val_loss: 1.2132 - val_rmse: 0.4029\n",
      "Epoch 106/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4740 - loss: 1.2365 - rmse: 0.4109\n",
      "Epoch 106: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.4739 - loss: 1.2362 - rmse: 0.4108 - val_accuracy: 0.6000 - val_loss: 1.2077 - val_rmse: 0.4014\n",
      "Epoch 107/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4054 - loss: 1.2350 - rmse: 0.4081\n",
      "Epoch 107: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.4066 - loss: 1.2347 - rmse: 0.4081 - val_accuracy: 0.6000 - val_loss: 1.2063 - val_rmse: 0.4006\n",
      "Epoch 108/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4993 - loss: 1.2375 - rmse: 0.4098\n",
      "Epoch 108: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4989 - loss: 1.2370 - rmse: 0.4097 - val_accuracy: 0.6000 - val_loss: 1.2140 - val_rmse: 0.4011\n",
      "Epoch 109/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4743 - loss: 1.2018 - rmse: 0.4033\n",
      "Epoch 109: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4745 - loss: 1.2023 - rmse: 0.4033 - val_accuracy: 0.6500 - val_loss: 1.2198 - val_rmse: 0.4016\n",
      "Epoch 110/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4185 - loss: 1.2294 - rmse: 0.4085\n",
      "Epoch 110: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4203 - loss: 1.2287 - rmse: 0.4084 - val_accuracy: 0.6000 - val_loss: 1.2231 - val_rmse: 0.4009\n",
      "Epoch 111/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4747 - loss: 1.2113 - rmse: 0.4047\n",
      "Epoch 111: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.4746 - loss: 1.2109 - rmse: 0.4046 - val_accuracy: 0.6000 - val_loss: 1.2285 - val_rmse: 0.4010\n",
      "Epoch 112/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4696 - loss: 1.1978 - rmse: 0.4036\n",
      "Epoch 112: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4705 - loss: 1.1969 - rmse: 0.4034 - val_accuracy: 0.6000 - val_loss: 1.2246 - val_rmse: 0.4002\n",
      "Epoch 113/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5087 - loss: 1.1670 - rmse: 0.3975\n",
      "Epoch 113: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5083 - loss: 1.1671 - rmse: 0.3975 - val_accuracy: 0.5500 - val_loss: 1.2274 - val_rmse: 0.3993\n",
      "Epoch 114/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5212 - loss: 1.1599 - rmse: 0.3962\n",
      "Epoch 114: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5222 - loss: 1.1597 - rmse: 0.3961 - val_accuracy: 0.5500 - val_loss: 1.2195 - val_rmse: 0.3983\n",
      "Epoch 115/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5773 - loss: 1.0888 - rmse: 0.3844\n",
      "Epoch 115: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5763 - loss: 1.0904 - rmse: 0.3847 - val_accuracy: 0.6000 - val_loss: 1.2138 - val_rmse: 0.3968\n",
      "Epoch 116/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4620 - loss: 1.1942 - rmse: 0.4035\n",
      "Epoch 116: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4641 - loss: 1.1924 - rmse: 0.4032 - val_accuracy: 0.6500 - val_loss: 1.1917 - val_rmse: 0.3927\n",
      "Epoch 117/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5598 - loss: 1.1367 - rmse: 0.3916\n",
      "Epoch 117: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5592 - loss: 1.1351 - rmse: 0.3914 - val_accuracy: 0.6000 - val_loss: 1.1857 - val_rmse: 0.3906\n",
      "Epoch 118/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5230 - loss: 1.1444 - rmse: 0.3914\n",
      "Epoch 118: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5248 - loss: 1.1416 - rmse: 0.3911 - val_accuracy: 0.6500 - val_loss: 1.1676 - val_rmse: 0.3858\n",
      "Epoch 119/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5806 - loss: 1.0785 - rmse: 0.3800\n",
      "Epoch 119: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5777 - loss: 1.0784 - rmse: 0.3802 - val_accuracy: 0.6000 - val_loss: 1.1256 - val_rmse: 0.3835\n",
      "Epoch 120/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5467 - loss: 1.1499 - rmse: 0.3924\n",
      "Epoch 120: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5493 - loss: 1.1457 - rmse: 0.3918 - val_accuracy: 0.6500 - val_loss: 1.1266 - val_rmse: 0.3794\n",
      "Epoch 121/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6131 - loss: 1.0229 - rmse: 0.3702\n",
      "Epoch 121: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6081 - loss: 1.0293 - rmse: 0.3715 - val_accuracy: 0.3500 - val_loss: 1.2882 - val_rmse: 0.4135\n",
      "Epoch 122/1500\n",
      "\u001b[1m33/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5315 - loss: 1.1421 - rmse: 0.3916\n",
      "Epoch 122: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5329 - loss: 1.1402 - rmse: 0.3914 - val_accuracy: 0.6000 - val_loss: 1.1057 - val_rmse: 0.3718\n",
      "Epoch 123/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4989 - loss: 1.1011 - rmse: 0.3892\n",
      "Epoch 123: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5016 - loss: 1.0990 - rmse: 0.3888 - val_accuracy: 0.5500 - val_loss: 1.1733 - val_rmse: 0.3837\n",
      "Epoch 124/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6369 - loss: 1.0122 - rmse: 0.3667\n",
      "Epoch 124: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6332 - loss: 1.0138 - rmse: 0.3671 - val_accuracy: 0.6500 - val_loss: 1.0891 - val_rmse: 0.3651\n",
      "Epoch 125/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5506 - loss: 0.9673 - rmse: 0.3621\n",
      "Epoch 125: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5491 - loss: 0.9695 - rmse: 0.3625 - val_accuracy: 0.6000 - val_loss: 1.1105 - val_rmse: 0.3697\n",
      "Epoch 126/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6123 - loss: 1.0381 - rmse: 0.3722\n",
      "Epoch 126: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6118 - loss: 1.0369 - rmse: 0.3721 - val_accuracy: 0.6000 - val_loss: 1.1434 - val_rmse: 0.3724\n",
      "Epoch 127/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6075 - loss: 0.9741 - rmse: 0.3639\n",
      "Epoch 127: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6051 - loss: 0.9771 - rmse: 0.3644 - val_accuracy: 0.5500 - val_loss: 1.1748 - val_rmse: 0.3820\n",
      "Epoch 128/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7040 - loss: 0.9200 - rmse: 0.3483\n",
      "Epoch 128: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6990 - loss: 0.9236 - rmse: 0.3492 - val_accuracy: 0.7500 - val_loss: 1.0508 - val_rmse: 0.3514\n",
      "Epoch 129/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5569 - loss: 1.0773 - rmse: 0.3819\n",
      "Epoch 129: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5586 - loss: 1.0750 - rmse: 0.3814 - val_accuracy: 0.6500 - val_loss: 1.0815 - val_rmse: 0.3597\n",
      "Epoch 130/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6147 - loss: 0.9332 - rmse: 0.3528\n",
      "Epoch 130: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6142 - loss: 0.9341 - rmse: 0.3530 - val_accuracy: 0.6500 - val_loss: 1.0756 - val_rmse: 0.3543\n",
      "Epoch 131/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6127 - loss: 0.9509 - rmse: 0.3570\n",
      "Epoch 131: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6133 - loss: 0.9509 - rmse: 0.3570 - val_accuracy: 0.7500 - val_loss: 1.0180 - val_rmse: 0.3417\n",
      "Epoch 132/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6706 - loss: 0.9327 - rmse: 0.3525\n",
      "Epoch 132: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6678 - loss: 0.9341 - rmse: 0.3529 - val_accuracy: 0.7000 - val_loss: 1.0606 - val_rmse: 0.3497\n",
      "Epoch 133/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5614 - loss: 0.9612 - rmse: 0.3576\n",
      "Epoch 133: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5637 - loss: 0.9602 - rmse: 0.3575 - val_accuracy: 0.5500 - val_loss: 1.1187 - val_rmse: 0.3644\n",
      "Epoch 134/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5797 - loss: 1.0359 - rmse: 0.3725\n",
      "Epoch 134: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5789 - loss: 1.0441 - rmse: 0.3731 - val_accuracy: 0.3500 - val_loss: 1.7895 - val_rmse: 0.4668\n",
      "Epoch 135/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5188 - loss: 1.3881 - rmse: 0.4134\n",
      "Epoch 135: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5191 - loss: 1.3840 - rmse: 0.4131 - val_accuracy: 0.5000 - val_loss: 1.3311 - val_rmse: 0.4200\n",
      "Epoch 136/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4098 - loss: 1.2810 - rmse: 0.4193\n",
      "Epoch 136: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.4110 - loss: 1.2800 - rmse: 0.4191 - val_accuracy: 0.5000 - val_loss: 1.2812 - val_rmse: 0.4128\n",
      "Epoch 137/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5342 - loss: 1.1399 - rmse: 0.3941\n",
      "Epoch 137: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5334 - loss: 1.1418 - rmse: 0.3944 - val_accuracy: 0.4500 - val_loss: 1.2206 - val_rmse: 0.4046\n",
      "Epoch 138/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5418 - loss: 1.2033 - rmse: 0.4031\n",
      "Epoch 138: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5448 - loss: 1.1990 - rmse: 0.4024 - val_accuracy: 0.4000 - val_loss: 1.2113 - val_rmse: 0.4056\n",
      "Epoch 139/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5120 - loss: 1.1649 - rmse: 0.3957\n",
      "Epoch 139: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5171 - loss: 1.1584 - rmse: 0.3947 - val_accuracy: 0.4000 - val_loss: 1.2049 - val_rmse: 0.4066\n",
      "Epoch 140/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6401 - loss: 1.0243 - rmse: 0.3714\n",
      "Epoch 140: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6371 - loss: 1.0259 - rmse: 0.3717 - val_accuracy: 0.4500 - val_loss: 1.1784 - val_rmse: 0.4028\n",
      "Epoch 141/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6305 - loss: 1.0428 - rmse: 0.3752\n",
      "Epoch 141: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6296 - loss: 1.0420 - rmse: 0.3751 - val_accuracy: 0.5000 - val_loss: 1.1458 - val_rmse: 0.3966\n",
      "Epoch 142/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5996 - loss: 1.0006 - rmse: 0.3703\n",
      "Epoch 142: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5987 - loss: 1.0008 - rmse: 0.3703 - val_accuracy: 0.5500 - val_loss: 1.1000 - val_rmse: 0.3887\n",
      "Epoch 143/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6935 - loss: 0.9026 - rmse: 0.3461\n",
      "Epoch 143: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6894 - loss: 0.9064 - rmse: 0.3470 - val_accuracy: 0.5000 - val_loss: 1.1204 - val_rmse: 0.3938\n",
      "Epoch 144/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6978 - loss: 0.8794 - rmse: 0.3456\n",
      "Epoch 144: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6946 - loss: 0.8840 - rmse: 0.3465 - val_accuracy: 0.5000 - val_loss: 1.1011 - val_rmse: 0.3914\n",
      "Epoch 145/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6665 - loss: 0.9161 - rmse: 0.3515\n",
      "Epoch 145: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6650 - loss: 0.9173 - rmse: 0.3518 - val_accuracy: 0.5000 - val_loss: 1.0904 - val_rmse: 0.3897\n",
      "Epoch 146/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6332 - loss: 0.8908 - rmse: 0.3451\n",
      "Epoch 146: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6317 - loss: 0.8948 - rmse: 0.3461 - val_accuracy: 0.5000 - val_loss: 1.0910 - val_rmse: 0.3905\n",
      "Epoch 147/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5833 - loss: 0.9470 - rmse: 0.3620\n",
      "Epoch 147: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5845 - loss: 0.9467 - rmse: 0.3620 - val_accuracy: 0.5000 - val_loss: 1.0954 - val_rmse: 0.3901\n",
      "Epoch 148/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6254 - loss: 0.9651 - rmse: 0.3628\n",
      "Epoch 148: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6266 - loss: 0.9609 - rmse: 0.3621 - val_accuracy: 0.4500 - val_loss: 1.0958 - val_rmse: 0.3903\n",
      "Epoch 149/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6619 - loss: 0.8636 - rmse: 0.3421\n",
      "Epoch 149: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6594 - loss: 0.8665 - rmse: 0.3429 - val_accuracy: 0.4500 - val_loss: 1.0793 - val_rmse: 0.3889\n",
      "Epoch 150/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6761 - loss: 0.8667 - rmse: 0.3445\n",
      "Epoch 150: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6741 - loss: 0.8681 - rmse: 0.3449 - val_accuracy: 0.5500 - val_loss: 1.0630 - val_rmse: 0.3848\n",
      "Epoch 151/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6348 - loss: 0.8805 - rmse: 0.3479\n",
      "Epoch 151: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6351 - loss: 0.8808 - rmse: 0.3479 - val_accuracy: 0.4500 - val_loss: 1.0938 - val_rmse: 0.3936\n",
      "Epoch 152/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6494 - loss: 0.8670 - rmse: 0.3454\n",
      "Epoch 152: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6493 - loss: 0.8673 - rmse: 0.3455 - val_accuracy: 0.5000 - val_loss: 1.1381 - val_rmse: 0.3964\n",
      "Epoch 153/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6027 - loss: 0.9436 - rmse: 0.3691\n",
      "Epoch 153: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6036 - loss: 0.9419 - rmse: 0.3685 - val_accuracy: 0.5000 - val_loss: 1.0633 - val_rmse: 0.3837\n",
      "Epoch 154/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6884 - loss: 0.8436 - rmse: 0.3403\n",
      "Epoch 154: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6862 - loss: 0.8451 - rmse: 0.3407 - val_accuracy: 0.5000 - val_loss: 1.0850 - val_rmse: 0.3877\n",
      "Epoch 155/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7093 - loss: 0.8210 - rmse: 0.3332\n",
      "Epoch 155: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7075 - loss: 0.8223 - rmse: 0.3337 - val_accuracy: 0.4500 - val_loss: 1.1063 - val_rmse: 0.3951\n",
      "Epoch 156/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6371 - loss: 0.8528 - rmse: 0.3402\n",
      "Epoch 156: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6374 - loss: 0.8523 - rmse: 0.3403 - val_accuracy: 0.4500 - val_loss: 1.1149 - val_rmse: 0.3924\n",
      "Epoch 157/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6824 - loss: 0.8638 - rmse: 0.3439\n",
      "Epoch 157: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6825 - loss: 0.8627 - rmse: 0.3437 - val_accuracy: 0.4500 - val_loss: 1.1212 - val_rmse: 0.3951\n",
      "Epoch 158/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7321 - loss: 0.7979 - rmse: 0.3262\n",
      "Epoch 158: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7305 - loss: 0.7989 - rmse: 0.3266 - val_accuracy: 0.4500 - val_loss: 1.1118 - val_rmse: 0.3934\n",
      "Epoch 159/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7652 - loss: 0.6746 - rmse: 0.2944\n",
      "Epoch 159: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7618 - loss: 0.6796 - rmse: 0.2957 - val_accuracy: 0.6000 - val_loss: 0.9556 - val_rmse: 0.3649\n",
      "Epoch 160/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6270 - loss: 0.8720 - rmse: 0.3466\n",
      "Epoch 160: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6268 - loss: 0.8723 - rmse: 0.3467 - val_accuracy: 0.6000 - val_loss: 0.9414 - val_rmse: 0.3626\n",
      "Epoch 161/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5500 - loss: 0.9026 - rmse: 0.3582\n",
      "Epoch 161: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5539 - loss: 0.8983 - rmse: 0.3570 - val_accuracy: 0.5500 - val_loss: 0.9078 - val_rmse: 0.3584\n",
      "Epoch 162/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6113 - loss: 0.8911 - rmse: 0.3509\n",
      "Epoch 162: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6119 - loss: 0.8896 - rmse: 0.3506 - val_accuracy: 0.5500 - val_loss: 0.9363 - val_rmse: 0.3644\n",
      "Epoch 163/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6662 - loss: 0.7739 - rmse: 0.3275\n",
      "Epoch 163: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6662 - loss: 0.7753 - rmse: 0.3277 - val_accuracy: 0.5000 - val_loss: 1.3553 - val_rmse: 0.4070\n",
      "Epoch 164/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6296 - loss: 0.9056 - rmse: 0.3546\n",
      "Epoch 164: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6298 - loss: 0.9051 - rmse: 0.3543 - val_accuracy: 0.5500 - val_loss: 0.9533 - val_rmse: 0.3640\n",
      "Epoch 165/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7445 - loss: 0.7313 - rmse: 0.3080\n",
      "Epoch 165: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7424 - loss: 0.7336 - rmse: 0.3088 - val_accuracy: 0.5500 - val_loss: 0.9829 - val_rmse: 0.3698\n",
      "Epoch 166/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6416 - loss: 0.7916 - rmse: 0.3351\n",
      "Epoch 166: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6434 - loss: 0.7915 - rmse: 0.3349 - val_accuracy: 0.5000 - val_loss: 1.0087 - val_rmse: 0.3714\n",
      "Epoch 167/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6573 - loss: 0.7654 - rmse: 0.3252\n",
      "Epoch 167: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6582 - loss: 0.7657 - rmse: 0.3253 - val_accuracy: 0.5000 - val_loss: 1.0248 - val_rmse: 0.3799\n",
      "Epoch 168/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7620 - loss: 0.7188 - rmse: 0.3102\n",
      "Epoch 168: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7581 - loss: 0.7222 - rmse: 0.3113 - val_accuracy: 0.5500 - val_loss: 0.9903 - val_rmse: 0.3754\n",
      "Epoch 169/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7141 - loss: 0.6893 - rmse: 0.3099\n",
      "Epoch 169: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7138 - loss: 0.6901 - rmse: 0.3100 - val_accuracy: 0.4500 - val_loss: 1.0476 - val_rmse: 0.3873\n",
      "Epoch 170/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4431 - loss: 1.5024 - rmse: 0.4219\n",
      "Epoch 170: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4371 - loss: 1.5048 - rmse: 0.4228 - val_accuracy: 0.5000 - val_loss: 1.2414 - val_rmse: 0.4083\n",
      "Epoch 171/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4221 - loss: 1.2830 - rmse: 0.4157\n",
      "Epoch 171: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4180 - loss: 1.2844 - rmse: 0.4162 - val_accuracy: 0.4000 - val_loss: 1.2880 - val_rmse: 0.4117\n",
      "Epoch 172/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3355 - loss: 1.3406 - rmse: 0.4267\n",
      "Epoch 172: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3379 - loss: 1.3385 - rmse: 0.4264 - val_accuracy: 0.5000 - val_loss: 1.2223 - val_rmse: 0.4024\n",
      "Epoch 173/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4107 - loss: 1.2634 - rmse: 0.4163\n",
      "Epoch 173: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4119 - loss: 1.2627 - rmse: 0.4162 - val_accuracy: 0.5000 - val_loss: 1.2286 - val_rmse: 0.4019\n",
      "Epoch 174/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4513 - loss: 1.2314 - rmse: 0.4108\n",
      "Epoch 174: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4509 - loss: 1.2312 - rmse: 0.4108 - val_accuracy: 0.6000 - val_loss: 1.2029 - val_rmse: 0.3975\n",
      "Epoch 175/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5606 - loss: 1.1220 - rmse: 0.3893\n",
      "Epoch 175: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5547 - loss: 1.1291 - rmse: 0.3906 - val_accuracy: 0.6000 - val_loss: 1.1949 - val_rmse: 0.3966\n",
      "Epoch 176/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4998 - loss: 1.1871 - rmse: 0.4023\n",
      "Epoch 176: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 1.1877 - rmse: 0.4024 - val_accuracy: 0.6000 - val_loss: 1.2156 - val_rmse: 0.3979\n",
      "Epoch 177/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3646 - loss: 1.2394 - rmse: 0.4116\n",
      "Epoch 177: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3678 - loss: 1.2381 - rmse: 0.4114 - val_accuracy: 0.6000 - val_loss: 1.1794 - val_rmse: 0.3927\n",
      "Epoch 178/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4505 - loss: 1.1882 - rmse: 0.4047\n",
      "Epoch 178: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.4513 - loss: 1.1882 - rmse: 0.4046 - val_accuracy: 0.5500 - val_loss: 1.1875 - val_rmse: 0.3956\n",
      "Epoch 179/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4967 - loss: 1.1576 - rmse: 0.3955\n",
      "Epoch 179: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4970 - loss: 1.1582 - rmse: 0.3957 - val_accuracy: 0.5500 - val_loss: 1.1732 - val_rmse: 0.3945\n",
      "Epoch 180/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5083 - loss: 1.1854 - rmse: 0.4017\n",
      "Epoch 180: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5104 - loss: 1.1828 - rmse: 0.4012 - val_accuracy: 0.4000 - val_loss: 1.1691 - val_rmse: 0.4003\n",
      "Epoch 181/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4867 - loss: 1.1568 - rmse: 0.3962\n",
      "Epoch 181: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4878 - loss: 1.1574 - rmse: 0.3964 - val_accuracy: 0.4500 - val_loss: 1.1210 - val_rmse: 0.3954\n",
      "Epoch 182/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5035 - loss: 1.1404 - rmse: 0.3958\n",
      "Epoch 182: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5066 - loss: 1.1392 - rmse: 0.3957 - val_accuracy: 0.6000 - val_loss: 1.1040 - val_rmse: 0.3834\n",
      "Epoch 183/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5943 - loss: 1.0903 - rmse: 0.3850\n",
      "Epoch 183: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5933 - loss: 1.0921 - rmse: 0.3854 - val_accuracy: 0.7500 - val_loss: 1.0247 - val_rmse: 0.3698\n",
      "Epoch 184/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5130 - loss: 1.1239 - rmse: 0.3923\n",
      "Epoch 184: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5155 - loss: 1.1233 - rmse: 0.3921 - val_accuracy: 0.7500 - val_loss: 1.0171 - val_rmse: 0.3677\n",
      "Epoch 185/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5466 - loss: 1.0651 - rmse: 0.3793\n",
      "Epoch 185: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5457 - loss: 1.0670 - rmse: 0.3797 - val_accuracy: 0.5000 - val_loss: 1.1182 - val_rmse: 0.3820\n",
      "Epoch 186/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5615 - loss: 1.1034 - rmse: 0.3844\n",
      "Epoch 186: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5615 - loss: 1.1032 - rmse: 0.3844 - val_accuracy: 0.7000 - val_loss: 1.0014 - val_rmse: 0.3668\n",
      "Epoch 187/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5696 - loss: 1.0783 - rmse: 0.3808\n",
      "Epoch 187: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5687 - loss: 1.0793 - rmse: 0.3810 - val_accuracy: 0.6500 - val_loss: 1.0493 - val_rmse: 0.3704\n",
      "Epoch 188/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5293 - loss: 1.0975 - rmse: 0.3888\n",
      "Epoch 188: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5306 - loss: 1.0969 - rmse: 0.3887 - val_accuracy: 0.7000 - val_loss: 1.0651 - val_rmse: 0.3737\n",
      "Epoch 189/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6188 - loss: 1.0166 - rmse: 0.3713\n",
      "Epoch 189: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6180 - loss: 1.0186 - rmse: 0.3717 - val_accuracy: 0.6500 - val_loss: 1.0430 - val_rmse: 0.3716\n",
      "Epoch 190/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5601 - loss: 1.0951 - rmse: 0.3874\n",
      "Epoch 190: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5625 - loss: 1.0925 - rmse: 0.3867 - val_accuracy: 0.6000 - val_loss: 1.0384 - val_rmse: 0.3717\n",
      "Epoch 191/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5925 - loss: 1.0314 - rmse: 0.3761\n",
      "Epoch 191: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5924 - loss: 1.0314 - rmse: 0.3761 - val_accuracy: 0.5500 - val_loss: 1.1383 - val_rmse: 0.3845\n",
      "Epoch 192/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4768 - loss: 1.1149 - rmse: 0.3883\n",
      "Epoch 192: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.4781 - loss: 1.1138 - rmse: 0.3881 - val_accuracy: 0.5500 - val_loss: 1.1054 - val_rmse: 0.3792\n",
      "Epoch 193/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6296 - loss: 0.9890 - rmse: 0.3638\n",
      "Epoch 193: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6295 - loss: 0.9896 - rmse: 0.3639 - val_accuracy: 0.7000 - val_loss: 0.9988 - val_rmse: 0.3602\n",
      "Epoch 194/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6809 - loss: 0.9124 - rmse: 0.3507\n",
      "Epoch 194: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6796 - loss: 0.9152 - rmse: 0.3512 - val_accuracy: 0.5000 - val_loss: 1.2074 - val_rmse: 0.4009\n",
      "Epoch 195/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5228 - loss: 1.2068 - rmse: 0.4024\n",
      "Epoch 195: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5212 - loss: 1.2069 - rmse: 0.4024 - val_accuracy: 0.4000 - val_loss: 1.3269 - val_rmse: 0.4102\n",
      "Epoch 196/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5608 - loss: 1.1192 - rmse: 0.3864\n",
      "Epoch 196: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5564 - loss: 1.1210 - rmse: 0.3868 - val_accuracy: 0.3000 - val_loss: 1.2966 - val_rmse: 0.4067\n",
      "Epoch 197/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5408 - loss: 1.0731 - rmse: 0.3774\n",
      "Epoch 197: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5375 - loss: 1.0758 - rmse: 0.3780 - val_accuracy: 0.4000 - val_loss: 1.2863 - val_rmse: 0.4067\n",
      "Epoch 198/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4955 - loss: 1.1611 - rmse: 0.3941\n",
      "Epoch 198: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.4968 - loss: 1.1590 - rmse: 0.3938 - val_accuracy: 0.3500 - val_loss: 1.2884 - val_rmse: 0.4082\n",
      "Epoch 199/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5960 - loss: 1.0653 - rmse: 0.3773\n",
      "Epoch 199: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5958 - loss: 1.0648 - rmse: 0.3772 - val_accuracy: 0.4500 - val_loss: 1.2684 - val_rmse: 0.4025\n",
      "Epoch 200/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5860 - loss: 1.0469 - rmse: 0.3753\n",
      "Epoch 200: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5876 - loss: 1.0447 - rmse: 0.3750 - val_accuracy: 0.4000 - val_loss: 1.2734 - val_rmse: 0.4029\n",
      "Epoch 201/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6830 - loss: 0.9694 - rmse: 0.3594\n",
      "Epoch 201: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6771 - loss: 0.9718 - rmse: 0.3600 - val_accuracy: 0.4000 - val_loss: 1.2847 - val_rmse: 0.4042\n",
      "Epoch 202/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6428 - loss: 0.9529 - rmse: 0.3560\n",
      "Epoch 202: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6405 - loss: 0.9557 - rmse: 0.3567 - val_accuracy: 0.5000 - val_loss: 1.2734 - val_rmse: 0.4005\n",
      "Epoch 203/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6220 - loss: 0.9432 - rmse: 0.3575\n",
      "Epoch 203: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6221 - loss: 0.9441 - rmse: 0.3576 - val_accuracy: 0.5000 - val_loss: 1.2890 - val_rmse: 0.4018\n",
      "Epoch 204/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6784 - loss: 0.8976 - rmse: 0.3461\n",
      "Epoch 204: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6773 - loss: 0.8995 - rmse: 0.3465 - val_accuracy: 0.6000 - val_loss: 1.2838 - val_rmse: 0.3973\n",
      "Epoch 205/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6771 - loss: 0.9216 - rmse: 0.3493\n",
      "Epoch 205: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6755 - loss: 0.9227 - rmse: 0.3495 - val_accuracy: 0.6500 - val_loss: 1.2709 - val_rmse: 0.3929\n",
      "Epoch 206/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6423 - loss: 0.9256 - rmse: 0.3516\n",
      "Epoch 206: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6422 - loss: 0.9262 - rmse: 0.3517 - val_accuracy: 0.5500 - val_loss: 1.2690 - val_rmse: 0.3947\n",
      "Epoch 207/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5807 - loss: 0.9587 - rmse: 0.3597\n",
      "Epoch 207: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5823 - loss: 0.9583 - rmse: 0.3595 - val_accuracy: 0.5500 - val_loss: 1.2511 - val_rmse: 0.3929\n",
      "Epoch 208/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5932 - loss: 0.9436 - rmse: 0.3552\n",
      "Epoch 208: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5957 - loss: 0.9426 - rmse: 0.3551 - val_accuracy: 0.6000 - val_loss: 1.2427 - val_rmse: 0.3918\n",
      "Epoch 209/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6712 - loss: 0.9018 - rmse: 0.3468\n",
      "Epoch 209: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6692 - loss: 0.9031 - rmse: 0.3471 - val_accuracy: 0.5500 - val_loss: 1.2492 - val_rmse: 0.3932\n",
      "Epoch 210/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6577 - loss: 0.8986 - rmse: 0.3478\n",
      "Epoch 210: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6574 - loss: 0.8989 - rmse: 0.3479 - val_accuracy: 0.5500 - val_loss: 1.2560 - val_rmse: 0.3929\n",
      "Epoch 211/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6694 - loss: 0.8982 - rmse: 0.3464\n",
      "Epoch 211: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6678 - loss: 0.8975 - rmse: 0.3464 - val_accuracy: 0.5500 - val_loss: 1.2444 - val_rmse: 0.3899\n",
      "Epoch 212/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6691 - loss: 0.8963 - rmse: 0.3488\n",
      "Epoch 212: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6675 - loss: 0.8965 - rmse: 0.3489 - val_accuracy: 0.5500 - val_loss: 1.2170 - val_rmse: 0.3881\n",
      "Epoch 213/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6484 - loss: 0.9117 - rmse: 0.3492\n",
      "Epoch 213: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6483 - loss: 0.9099 - rmse: 0.3489 - val_accuracy: 0.5000 - val_loss: 1.2114 - val_rmse: 0.3871\n",
      "Epoch 214/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6679 - loss: 0.8291 - rmse: 0.3359\n",
      "Epoch 214: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6682 - loss: 0.8307 - rmse: 0.3363 - val_accuracy: 0.5500 - val_loss: 1.2757 - val_rmse: 0.3958\n",
      "Epoch 215/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6270 - loss: 0.9365 - rmse: 0.3476\n",
      "Epoch 215: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6270 - loss: 0.9369 - rmse: 0.3478 - val_accuracy: 0.5000 - val_loss: 1.2348 - val_rmse: 0.3902\n",
      "Epoch 216/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7060 - loss: 0.8421 - rmse: 0.3308\n",
      "Epoch 216: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7059 - loss: 0.8428 - rmse: 0.3310 - val_accuracy: 0.5500 - val_loss: 1.2334 - val_rmse: 0.3881\n",
      "Epoch 217/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6849 - loss: 0.8446 - rmse: 0.3375\n",
      "Epoch 217: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6820 - loss: 0.8461 - rmse: 0.3377 - val_accuracy: 0.4500 - val_loss: 1.2516 - val_rmse: 0.3919\n",
      "Epoch 218/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6728 - loss: 0.8290 - rmse: 0.3322\n",
      "Epoch 218: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6728 - loss: 0.8287 - rmse: 0.3322 - val_accuracy: 0.6000 - val_loss: 1.1960 - val_rmse: 0.3769\n",
      "Epoch 219/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6431 - loss: 0.8145 - rmse: 0.3341\n",
      "Epoch 219: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6440 - loss: 0.8145 - rmse: 0.3340 - val_accuracy: 0.6000 - val_loss: 1.1909 - val_rmse: 0.3744\n",
      "Epoch 220/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6725 - loss: 0.8174 - rmse: 0.3315\n",
      "Epoch 220: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6731 - loss: 0.8170 - rmse: 0.3315 - val_accuracy: 0.5000 - val_loss: 1.1901 - val_rmse: 0.3769\n",
      "Epoch 221/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7006 - loss: 0.8190 - rmse: 0.3276\n",
      "Epoch 221: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6987 - loss: 0.8229 - rmse: 0.3285 - val_accuracy: 0.7000 - val_loss: 1.2373 - val_rmse: 0.3776\n",
      "Epoch 222/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7668 - loss: 0.7842 - rmse: 0.3156\n",
      "Epoch 222: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7597 - loss: 0.7915 - rmse: 0.3175 - val_accuracy: 0.5500 - val_loss: 1.1975 - val_rmse: 0.3777\n",
      "Epoch 223/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6199 - loss: 0.8561 - rmse: 0.3407\n",
      "Epoch 223: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6215 - loss: 0.8544 - rmse: 0.3402 - val_accuracy: 0.6000 - val_loss: 1.1733 - val_rmse: 0.3708\n",
      "Epoch 224/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5985 - loss: 0.8846 - rmse: 0.3487\n",
      "Epoch 224: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6006 - loss: 0.8826 - rmse: 0.3482 - val_accuracy: 0.6000 - val_loss: 1.1854 - val_rmse: 0.3718\n",
      "Epoch 225/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6093 - loss: 0.8308 - rmse: 0.3341\n",
      "Epoch 225: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6105 - loss: 0.8296 - rmse: 0.3338 - val_accuracy: 0.7000 - val_loss: 1.1289 - val_rmse: 0.3627\n",
      "Epoch 226/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7398 - loss: 0.6950 - rmse: 0.3002\n",
      "Epoch 226: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7377 - loss: 0.6983 - rmse: 0.3011 - val_accuracy: 0.6500 - val_loss: 1.1533 - val_rmse: 0.3638\n",
      "Epoch 227/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6773 - loss: 0.7974 - rmse: 0.3310\n",
      "Epoch 227: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6782 - loss: 0.7957 - rmse: 0.3305 - val_accuracy: 0.5500 - val_loss: 1.1659 - val_rmse: 0.3620\n",
      "Epoch 228/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6892 - loss: 0.8153 - rmse: 0.3281\n",
      "Epoch 228: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6898 - loss: 0.8139 - rmse: 0.3279 - val_accuracy: 0.7000 - val_loss: 1.1524 - val_rmse: 0.3549\n",
      "Epoch 229/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6855 - loss: 0.7566 - rmse: 0.3160\n",
      "Epoch 229: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6846 - loss: 0.7589 - rmse: 0.3165 - val_accuracy: 0.5500 - val_loss: 1.2719 - val_rmse: 0.3943\n",
      "Epoch 230/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6457 - loss: 0.9077 - rmse: 0.3444\n",
      "Epoch 230: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6464 - loss: 0.9050 - rmse: 0.3440 - val_accuracy: 0.5500 - val_loss: 1.2164 - val_rmse: 0.3830\n",
      "Epoch 231/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6480 - loss: 0.7983 - rmse: 0.3350\n",
      "Epoch 231: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6482 - loss: 0.7979 - rmse: 0.3348 - val_accuracy: 0.5500 - val_loss: 1.1806 - val_rmse: 0.3788\n",
      "Epoch 232/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7483 - loss: 0.7153 - rmse: 0.3068\n",
      "Epoch 232: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7472 - loss: 0.7160 - rmse: 0.3071 - val_accuracy: 0.5500 - val_loss: 1.2280 - val_rmse: 0.3847\n",
      "Epoch 233/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7235 - loss: 0.6924 - rmse: 0.3011\n",
      "Epoch 233: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7231 - loss: 0.6935 - rmse: 0.3014 - val_accuracy: 0.7500 - val_loss: 1.0893 - val_rmse: 0.3468\n",
      "Epoch 234/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7564 - loss: 0.6430 - rmse: 0.2935\n",
      "Epoch 234: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7513 - loss: 0.6523 - rmse: 0.2956 - val_accuracy: 0.5500 - val_loss: 1.0778 - val_rmse: 0.3561\n",
      "Epoch 235/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6540 - loss: 0.7978 - rmse: 0.3286\n",
      "Epoch 235: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6559 - loss: 0.7946 - rmse: 0.3280 - val_accuracy: 0.4500 - val_loss: 1.1687 - val_rmse: 0.3834\n",
      "Epoch 236/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7474 - loss: 0.7208 - rmse: 0.3090\n",
      "Epoch 236: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7464 - loss: 0.7201 - rmse: 0.3091 - val_accuracy: 0.6000 - val_loss: 1.1728 - val_rmse: 0.3766\n",
      "Epoch 237/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7052 - loss: 0.7257 - rmse: 0.3131\n",
      "Epoch 237: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7045 - loss: 0.7278 - rmse: 0.3137 - val_accuracy: 0.6500 - val_loss: 1.1987 - val_rmse: 0.3589\n",
      "Epoch 238/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6699 - loss: 0.8607 - rmse: 0.3424\n",
      "Epoch 238: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6707 - loss: 0.8581 - rmse: 0.3419 - val_accuracy: 0.5000 - val_loss: 1.2776 - val_rmse: 0.3590\n",
      "Epoch 239/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6157 - loss: 0.9006 - rmse: 0.3490\n",
      "Epoch 239: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6168 - loss: 0.8985 - rmse: 0.3487 - val_accuracy: 0.5500 - val_loss: 1.6515 - val_rmse: 0.4044\n",
      "Epoch 240/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6126 - loss: 0.9399 - rmse: 0.3622\n",
      "Epoch 240: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6120 - loss: 0.9431 - rmse: 0.3627 - val_accuracy: 0.6000 - val_loss: 0.9566 - val_rmse: 0.3689\n",
      "Epoch 241/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5691 - loss: 0.9772 - rmse: 0.3666\n",
      "Epoch 241: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5703 - loss: 0.9752 - rmse: 0.3663 - val_accuracy: 0.7000 - val_loss: 1.1934 - val_rmse: 0.3701\n",
      "Epoch 242/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6225 - loss: 0.9030 - rmse: 0.3510\n",
      "Epoch 242: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6271 - loss: 0.8963 - rmse: 0.3495 - val_accuracy: 0.7000 - val_loss: 1.2572 - val_rmse: 0.3558\n",
      "Epoch 243/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6949 - loss: 0.7822 - rmse: 0.3257\n",
      "Epoch 243: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6941 - loss: 0.7840 - rmse: 0.3260 - val_accuracy: 0.6000 - val_loss: 1.4213 - val_rmse: 0.3728\n",
      "Epoch 244/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6701 - loss: 0.8234 - rmse: 0.3306\n",
      "Epoch 244: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6732 - loss: 0.8164 - rmse: 0.3292 - val_accuracy: 0.6500 - val_loss: 1.3669 - val_rmse: 0.3745\n",
      "Epoch 245/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7760 - loss: 0.6502 - rmse: 0.2922\n",
      "Epoch 245: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7753 - loss: 0.6509 - rmse: 0.2923 - val_accuracy: 0.6000 - val_loss: 1.4380 - val_rmse: 0.3770\n",
      "Epoch 246/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7216 - loss: 0.7664 - rmse: 0.3187\n",
      "Epoch 246: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7217 - loss: 0.7641 - rmse: 0.3184 - val_accuracy: 0.6000 - val_loss: 1.3588 - val_rmse: 0.3684\n",
      "Epoch 247/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7997 - loss: 0.5712 - rmse: 0.2659\n",
      "Epoch 247: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7982 - loss: 0.5735 - rmse: 0.2667 - val_accuracy: 0.6000 - val_loss: 1.4898 - val_rmse: 0.3827\n",
      "Epoch 248/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7761 - loss: 0.6202 - rmse: 0.2908\n",
      "Epoch 248: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7762 - loss: 0.6200 - rmse: 0.2907 - val_accuracy: 0.6500 - val_loss: 1.3488 - val_rmse: 0.3578\n",
      "Epoch 249/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7793 - loss: 0.6693 - rmse: 0.2993\n",
      "Epoch 249: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7792 - loss: 0.6661 - rmse: 0.2987 - val_accuracy: 0.6500 - val_loss: 1.3967 - val_rmse: 0.3807\n",
      "Epoch 250/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6491 - loss: 0.8599 - rmse: 0.3321\n",
      "Epoch 250: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6452 - loss: 0.8853 - rmse: 0.3344 - val_accuracy: 0.3500 - val_loss: 1.5489 - val_rmse: 0.4582\n",
      "Epoch 251/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3990 - loss: 1.8767 - rmse: 0.4650\n",
      "Epoch 251: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3989 - loss: 1.8757 - rmse: 0.4650 - val_accuracy: 0.5000 - val_loss: 1.3507 - val_rmse: 0.4078\n",
      "Epoch 252/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4636 - loss: 1.4373 - rmse: 0.4321\n",
      "Epoch 252: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.4609 - loss: 1.4452 - rmse: 0.4330 - val_accuracy: 0.4000 - val_loss: 1.4314 - val_rmse: 0.4418\n",
      "Epoch 253/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3442 - loss: 2.2482 - rmse: 0.4900\n",
      "Epoch 253: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3439 - loss: 2.2499 - rmse: 0.4902 - val_accuracy: 0.4500 - val_loss: 1.8115 - val_rmse: 0.4427\n",
      "Epoch 254/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3063 - loss: 1.7203 - rmse: 0.4604\n",
      "Epoch 254: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3044 - loss: 1.7097 - rmse: 0.4598 - val_accuracy: 0.3500 - val_loss: 1.3865 - val_rmse: 0.4252\n",
      "Epoch 255/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2691 - loss: 1.3314 - rmse: 0.4257\n",
      "Epoch 255: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2707 - loss: 1.3315 - rmse: 0.4257 - val_accuracy: 0.3500 - val_loss: 1.3240 - val_rmse: 0.4155\n",
      "Epoch 256/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3913 - loss: 1.2774 - rmse: 0.4174\n",
      "Epoch 256: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3916 - loss: 1.2772 - rmse: 0.4174 - val_accuracy: 0.5000 - val_loss: 1.2986 - val_rmse: 0.4090\n",
      "Epoch 257/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4392 - loss: 1.1687 - rmse: 0.3966\n",
      "Epoch 257: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4380 - loss: 1.1722 - rmse: 0.3974 - val_accuracy: 0.4500 - val_loss: 1.2801 - val_rmse: 0.4054\n",
      "Epoch 258/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4446 - loss: 1.2396 - rmse: 0.4104\n",
      "Epoch 258: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4448 - loss: 1.2385 - rmse: 0.4102 - val_accuracy: 0.5000 - val_loss: 1.2407 - val_rmse: 0.4011\n",
      "Epoch 259/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5705 - loss: 1.1624 - rmse: 0.3980\n",
      "Epoch 259: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5694 - loss: 1.1629 - rmse: 0.3981 - val_accuracy: 0.5000 - val_loss: 1.2226 - val_rmse: 0.3987\n",
      "Epoch 260/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5707 - loss: 1.1283 - rmse: 0.3927\n",
      "Epoch 260: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5668 - loss: 1.1311 - rmse: 0.3932 - val_accuracy: 0.5500 - val_loss: 1.2008 - val_rmse: 0.3950\n",
      "Epoch 261/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5340 - loss: 1.1539 - rmse: 0.3987\n",
      "Epoch 261: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5342 - loss: 1.1535 - rmse: 0.3986 - val_accuracy: 0.5500 - val_loss: 1.2096 - val_rmse: 0.3962\n",
      "Epoch 262/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5674 - loss: 1.1203 - rmse: 0.3914\n",
      "Epoch 262: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5665 - loss: 1.1203 - rmse: 0.3915 - val_accuracy: 0.6000 - val_loss: 1.1951 - val_rmse: 0.3941\n",
      "Epoch 263/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6267 - loss: 1.0953 - rmse: 0.3860\n",
      "Epoch 263: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6185 - loss: 1.0986 - rmse: 0.3866 - val_accuracy: 0.5500 - val_loss: 1.1925 - val_rmse: 0.3947\n",
      "Epoch 264/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5732 - loss: 1.0842 - rmse: 0.3832\n",
      "Epoch 264: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5690 - loss: 1.0866 - rmse: 0.3837 - val_accuracy: 0.6000 - val_loss: 1.1783 - val_rmse: 0.3918\n",
      "Epoch 265/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5487 - loss: 1.0765 - rmse: 0.3849\n",
      "Epoch 265: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5483 - loss: 1.0773 - rmse: 0.3849 - val_accuracy: 0.6000 - val_loss: 1.1801 - val_rmse: 0.3919\n",
      "Epoch 266/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4752 - loss: 1.1402 - rmse: 0.3948\n",
      "Epoch 266: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.4757 - loss: 1.1398 - rmse: 0.3947 - val_accuracy: 0.5000 - val_loss: 1.2258 - val_rmse: 0.4019\n",
      "Epoch 267/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4222 - loss: 1.1985 - rmse: 0.4021\n",
      "Epoch 267: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4241 - loss: 1.1971 - rmse: 0.4019 - val_accuracy: 0.5500 - val_loss: 1.2184 - val_rmse: 0.3994\n",
      "Epoch 268/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5315 - loss: 1.1387 - rmse: 0.3913\n",
      "Epoch 268: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5298 - loss: 1.1398 - rmse: 0.3915 - val_accuracy: 0.5500 - val_loss: 1.2110 - val_rmse: 0.3979\n",
      "Epoch 269/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5351 - loss: 1.1315 - rmse: 0.3904\n",
      "Epoch 269: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5328 - loss: 1.1323 - rmse: 0.3906 - val_accuracy: 0.6000 - val_loss: 1.2109 - val_rmse: 0.3971\n",
      "Epoch 270/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4298 - loss: 1.1690 - rmse: 0.3977\n",
      "Epoch 270: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4328 - loss: 1.1679 - rmse: 0.3975 - val_accuracy: 0.6000 - val_loss: 1.2013 - val_rmse: 0.3947\n",
      "Epoch 271/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5609 - loss: 1.0891 - rmse: 0.3826\n",
      "Epoch 271: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5596 - loss: 1.0898 - rmse: 0.3828 - val_accuracy: 0.5500 - val_loss: 1.1975 - val_rmse: 0.3938\n",
      "Epoch 272/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5398 - loss: 1.0636 - rmse: 0.3789\n",
      "Epoch 272: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5399 - loss: 1.0648 - rmse: 0.3791 - val_accuracy: 0.6000 - val_loss: 1.1892 - val_rmse: 0.3923\n",
      "Epoch 273/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5223 - loss: 1.1697 - rmse: 0.3975\n",
      "Epoch 273: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5245 - loss: 1.1659 - rmse: 0.3969 - val_accuracy: 0.6000 - val_loss: 1.1864 - val_rmse: 0.3918\n",
      "Epoch 274/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5759 - loss: 1.0325 - rmse: 0.3728\n",
      "Epoch 274: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5748 - loss: 1.0358 - rmse: 0.3734 - val_accuracy: 0.5500 - val_loss: 1.1779 - val_rmse: 0.3905\n",
      "Epoch 275/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5469 - loss: 1.0887 - rmse: 0.3832\n",
      "Epoch 275: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5472 - loss: 1.0886 - rmse: 0.3832 - val_accuracy: 0.5500 - val_loss: 1.1814 - val_rmse: 0.3907\n",
      "Epoch 276/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5495 - loss: 1.0756 - rmse: 0.3813\n",
      "Epoch 276: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5491 - loss: 1.0758 - rmse: 0.3814 - val_accuracy: 0.5500 - val_loss: 1.1730 - val_rmse: 0.3890\n",
      "Epoch 277/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5340 - loss: 1.1026 - rmse: 0.3870\n",
      "Epoch 277: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5355 - loss: 1.1012 - rmse: 0.3867 - val_accuracy: 0.5500 - val_loss: 1.1773 - val_rmse: 0.3888\n",
      "Epoch 278/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5078 - loss: 1.1496 - rmse: 0.3937\n",
      "Epoch 278: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5125 - loss: 1.1432 - rmse: 0.3927 - val_accuracy: 0.6000 - val_loss: 1.1765 - val_rmse: 0.3888\n",
      "Epoch 279/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5607 - loss: 1.0442 - rmse: 0.3772\n",
      "Epoch 279: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5606 - loss: 1.0446 - rmse: 0.3773 - val_accuracy: 0.5500 - val_loss: 1.1752 - val_rmse: 0.3874\n",
      "Epoch 280/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5250 - loss: 1.0879 - rmse: 0.3832\n",
      "Epoch 280: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5263 - loss: 1.0859 - rmse: 0.3829 - val_accuracy: 0.6500 - val_loss: 1.1649 - val_rmse: 0.3861\n",
      "Epoch 281/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5951 - loss: 1.0082 - rmse: 0.3686\n",
      "Epoch 281: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5948 - loss: 1.0092 - rmse: 0.3688 - val_accuracy: 0.6000 - val_loss: 1.1634 - val_rmse: 0.3858\n",
      "Epoch 282/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6146 - loss: 1.0478 - rmse: 0.3760\n",
      "Epoch 282: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6134 - loss: 1.0475 - rmse: 0.3760 - val_accuracy: 0.6000 - val_loss: 1.1713 - val_rmse: 0.3872\n",
      "Epoch 283/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5493 - loss: 1.0583 - rmse: 0.3785\n",
      "Epoch 283: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5504 - loss: 1.0569 - rmse: 0.3782 - val_accuracy: 0.6000 - val_loss: 1.1617 - val_rmse: 0.3852\n",
      "Epoch 284/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4785 - loss: 1.1267 - rmse: 0.3883\n",
      "Epoch 284: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.4840 - loss: 1.1185 - rmse: 0.3871 - val_accuracy: 0.6000 - val_loss: 1.1642 - val_rmse: 0.3852\n",
      "Epoch 285/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5671 - loss: 1.0080 - rmse: 0.3687\n",
      "Epoch 285: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5673 - loss: 1.0081 - rmse: 0.3688 - val_accuracy: 0.7000 - val_loss: 1.1589 - val_rmse: 0.3843\n",
      "Epoch 286/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5793 - loss: 1.0399 - rmse: 0.3761\n",
      "Epoch 286: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5803 - loss: 1.0380 - rmse: 0.3757 - val_accuracy: 0.6500 - val_loss: 1.1502 - val_rmse: 0.3807\n",
      "Epoch 287/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6236 - loss: 0.9566 - rmse: 0.3569\n",
      "Epoch 287: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6220 - loss: 0.9577 - rmse: 0.3572 - val_accuracy: 0.6500 - val_loss: 1.1379 - val_rmse: 0.3773\n",
      "Epoch 288/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5408 - loss: 0.9958 - rmse: 0.3673\n",
      "Epoch 288: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5417 - loss: 0.9957 - rmse: 0.3673 - val_accuracy: 0.7500 - val_loss: 1.1276 - val_rmse: 0.3756\n",
      "Epoch 289/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5843 - loss: 0.9884 - rmse: 0.3672\n",
      "Epoch 289: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5852 - loss: 0.9881 - rmse: 0.3671 - val_accuracy: 0.6500 - val_loss: 1.1173 - val_rmse: 0.3741\n",
      "Epoch 290/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5939 - loss: 1.0040 - rmse: 0.3668\n",
      "Epoch 290: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5941 - loss: 1.0020 - rmse: 0.3665 - val_accuracy: 0.7500 - val_loss: 1.1077 - val_rmse: 0.3739\n",
      "Epoch 291/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6613 - loss: 0.9812 - rmse: 0.3606\n",
      "Epoch 291: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6605 - loss: 0.9803 - rmse: 0.3605 - val_accuracy: 0.7000 - val_loss: 1.0864 - val_rmse: 0.3717\n",
      "Epoch 292/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5856 - loss: 0.9848 - rmse: 0.3618\n",
      "Epoch 292: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5866 - loss: 0.9831 - rmse: 0.3616 - val_accuracy: 0.7000 - val_loss: 1.1074 - val_rmse: 0.3766\n",
      "Epoch 293/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6413 - loss: 0.9257 - rmse: 0.3514\n",
      "Epoch 293: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6388 - loss: 0.9272 - rmse: 0.3518 - val_accuracy: 0.7500 - val_loss: 1.0696 - val_rmse: 0.3677\n",
      "Epoch 294/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6529 - loss: 0.9581 - rmse: 0.3582\n",
      "Epoch 294: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6536 - loss: 0.9564 - rmse: 0.3579 - val_accuracy: 0.7000 - val_loss: 1.0802 - val_rmse: 0.3724\n",
      "Epoch 295/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6180 - loss: 0.9517 - rmse: 0.3569\n",
      "Epoch 295: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6193 - loss: 0.9509 - rmse: 0.3568 - val_accuracy: 0.7000 - val_loss: 1.0681 - val_rmse: 0.3702\n",
      "Epoch 296/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6184 - loss: 0.9709 - rmse: 0.3615\n",
      "Epoch 296: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6193 - loss: 0.9695 - rmse: 0.3612 - val_accuracy: 0.5000 - val_loss: 1.1269 - val_rmse: 0.3835\n",
      "Epoch 297/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5763 - loss: 0.9756 - rmse: 0.3625\n",
      "Epoch 297: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5804 - loss: 0.9721 - rmse: 0.3618 - val_accuracy: 0.5500 - val_loss: 1.1314 - val_rmse: 0.3840\n",
      "Epoch 298/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6540 - loss: 0.8823 - rmse: 0.3436\n",
      "Epoch 298: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6525 - loss: 0.8848 - rmse: 0.3441 - val_accuracy: 0.5500 - val_loss: 1.1278 - val_rmse: 0.3857\n",
      "Epoch 299/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6469 - loss: 0.8620 - rmse: 0.3406\n",
      "Epoch 299: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6469 - loss: 0.8634 - rmse: 0.3408 - val_accuracy: 0.4500 - val_loss: 1.1133 - val_rmse: 0.3812\n",
      "Epoch 300/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7215 - loss: 0.8197 - rmse: 0.3277\n",
      "Epoch 300: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7166 - loss: 0.8261 - rmse: 0.3291 - val_accuracy: 0.6500 - val_loss: 1.0960 - val_rmse: 0.3791\n",
      "Epoch 301/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6394 - loss: 0.9120 - rmse: 0.3485\n",
      "Epoch 301: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6401 - loss: 0.9115 - rmse: 0.3484 - val_accuracy: 0.6000 - val_loss: 1.0996 - val_rmse: 0.3789\n",
      "Epoch 302/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6287 - loss: 0.8774 - rmse: 0.3428\n",
      "Epoch 302: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6285 - loss: 0.8816 - rmse: 0.3437 - val_accuracy: 0.5500 - val_loss: 1.1277 - val_rmse: 0.3838\n",
      "Epoch 303/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6237 - loss: 0.9818 - rmse: 0.3609\n",
      "Epoch 303: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6242 - loss: 0.9801 - rmse: 0.3607 - val_accuracy: 0.6000 - val_loss: 1.1227 - val_rmse: 0.3837\n",
      "Epoch 304/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6484 - loss: 0.9508 - rmse: 0.3542\n",
      "Epoch 304: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6485 - loss: 0.9495 - rmse: 0.3540 - val_accuracy: 0.5000 - val_loss: 1.1365 - val_rmse: 0.3870\n",
      "Epoch 305/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6211 - loss: 0.9172 - rmse: 0.3537\n",
      "Epoch 305: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6212 - loss: 0.9183 - rmse: 0.3537 - val_accuracy: 0.5000 - val_loss: 1.1301 - val_rmse: 0.3864\n",
      "Epoch 306/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6829 - loss: 0.8805 - rmse: 0.3385\n",
      "Epoch 306: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6813 - loss: 0.8817 - rmse: 0.3388 - val_accuracy: 0.6000 - val_loss: 1.1379 - val_rmse: 0.3850\n",
      "Epoch 307/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5791 - loss: 0.9509 - rmse: 0.3621\n",
      "Epoch 307: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5822 - loss: 0.9485 - rmse: 0.3613 - val_accuracy: 0.6000 - val_loss: 1.0819 - val_rmse: 0.3680\n",
      "Epoch 308/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5642 - loss: 0.9511 - rmse: 0.3563\n",
      "Epoch 308: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5648 - loss: 0.9508 - rmse: 0.3563 - val_accuracy: 0.6500 - val_loss: 1.1291 - val_rmse: 0.3771\n",
      "Epoch 309/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5753 - loss: 0.9445 - rmse: 0.3552\n",
      "Epoch 309: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5742 - loss: 0.9456 - rmse: 0.3554 - val_accuracy: 0.6500 - val_loss: 1.2307 - val_rmse: 0.3803\n",
      "Epoch 310/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5586 - loss: 0.9956 - rmse: 0.3646\n",
      "Epoch 310: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5614 - loss: 0.9925 - rmse: 0.3639 - val_accuracy: 0.7000 - val_loss: 1.0637 - val_rmse: 0.3667\n",
      "Epoch 311/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6386 - loss: 0.8460 - rmse: 0.3367\n",
      "Epoch 311: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6390 - loss: 0.8473 - rmse: 0.3369 - val_accuracy: 0.5000 - val_loss: 1.1201 - val_rmse: 0.3804\n",
      "Epoch 312/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6789 - loss: 0.8599 - rmse: 0.3386\n",
      "Epoch 312: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6786 - loss: 0.8612 - rmse: 0.3388 - val_accuracy: 0.7000 - val_loss: 1.0764 - val_rmse: 0.3693\n",
      "Epoch 313/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6779 - loss: 0.8995 - rmse: 0.3445\n",
      "Epoch 313: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6781 - loss: 0.8983 - rmse: 0.3444 - val_accuracy: 0.6500 - val_loss: 1.0971 - val_rmse: 0.3784\n",
      "Epoch 314/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7146 - loss: 0.8495 - rmse: 0.3364\n",
      "Epoch 314: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7113 - loss: 0.8516 - rmse: 0.3368 - val_accuracy: 0.5000 - val_loss: 1.1344 - val_rmse: 0.3878\n",
      "Epoch 315/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6607 - loss: 0.8408 - rmse: 0.3334\n",
      "Epoch 315: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6584 - loss: 0.8441 - rmse: 0.3343 - val_accuracy: 0.6000 - val_loss: 1.0804 - val_rmse: 0.3749\n",
      "Epoch 316/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6891 - loss: 0.7964 - rmse: 0.3245\n",
      "Epoch 316: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6860 - loss: 0.8012 - rmse: 0.3254 - val_accuracy: 0.5500 - val_loss: 1.0792 - val_rmse: 0.3681\n",
      "Epoch 317/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6704 - loss: 0.8908 - rmse: 0.3385\n",
      "Epoch 317: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6685 - loss: 0.8906 - rmse: 0.3390 - val_accuracy: 0.6500 - val_loss: 1.0734 - val_rmse: 0.3665\n",
      "Epoch 318/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6051 - loss: 0.9584 - rmse: 0.3561\n",
      "Epoch 318: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6054 - loss: 0.9570 - rmse: 0.3559 - val_accuracy: 0.6500 - val_loss: 1.1581 - val_rmse: 0.3794\n",
      "Epoch 319/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6694 - loss: 0.7849 - rmse: 0.3225\n",
      "Epoch 319: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6682 - loss: 0.7870 - rmse: 0.3230 - val_accuracy: 0.6500 - val_loss: 1.1173 - val_rmse: 0.3730\n",
      "Epoch 320/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5945 - loss: 0.8415 - rmse: 0.3376\n",
      "Epoch 320: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5965 - loss: 0.8411 - rmse: 0.3374 - val_accuracy: 0.7000 - val_loss: 1.0202 - val_rmse: 0.3565\n",
      "Epoch 321/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6838 - loss: 0.7664 - rmse: 0.3198\n",
      "Epoch 321: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6818 - loss: 0.7704 - rmse: 0.3206 - val_accuracy: 0.6500 - val_loss: 1.1403 - val_rmse: 0.3753\n",
      "Epoch 322/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7254 - loss: 0.7522 - rmse: 0.3100\n",
      "Epoch 322: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7223 - loss: 0.7600 - rmse: 0.3120 - val_accuracy: 0.7000 - val_loss: 1.0884 - val_rmse: 0.3639\n",
      "Epoch 323/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7114 - loss: 0.7343 - rmse: 0.3150\n",
      "Epoch 323: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7107 - loss: 0.7360 - rmse: 0.3153 - val_accuracy: 0.6500 - val_loss: 1.0947 - val_rmse: 0.3688\n",
      "Epoch 324/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6547 - loss: 0.8829 - rmse: 0.3368\n",
      "Epoch 324: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6547 - loss: 0.8819 - rmse: 0.3368 - val_accuracy: 0.7000 - val_loss: 1.0751 - val_rmse: 0.3645\n",
      "Epoch 325/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6554 - loss: 0.7769 - rmse: 0.3204\n",
      "Epoch 325: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6557 - loss: 0.7784 - rmse: 0.3207 - val_accuracy: 0.6000 - val_loss: 1.1192 - val_rmse: 0.3677\n",
      "Epoch 326/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5933 - loss: 0.9069 - rmse: 0.3489\n",
      "Epoch 326: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5951 - loss: 0.9043 - rmse: 0.3483 - val_accuracy: 0.7000 - val_loss: 0.9638 - val_rmse: 0.3473\n",
      "Epoch 327/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6849 - loss: 0.8173 - rmse: 0.3271\n",
      "Epoch 327: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6854 - loss: 0.8169 - rmse: 0.3271 - val_accuracy: 0.7000 - val_loss: 1.0681 - val_rmse: 0.3611\n",
      "Epoch 328/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6876 - loss: 0.8023 - rmse: 0.3273\n",
      "Epoch 328: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6883 - loss: 0.8011 - rmse: 0.3269 - val_accuracy: 0.7000 - val_loss: 1.1123 - val_rmse: 0.3686\n",
      "Epoch 329/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7237 - loss: 0.7930 - rmse: 0.3232\n",
      "Epoch 329: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7202 - loss: 0.7936 - rmse: 0.3235 - val_accuracy: 0.7000 - val_loss: 1.0564 - val_rmse: 0.3560\n",
      "Epoch 330/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7094 - loss: 0.7292 - rmse: 0.3111\n",
      "Epoch 330: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7089 - loss: 0.7319 - rmse: 0.3117 - val_accuracy: 0.6000 - val_loss: 1.0386 - val_rmse: 0.3599\n",
      "Epoch 331/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7112 - loss: 0.7226 - rmse: 0.3078\n",
      "Epoch 331: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7096 - loss: 0.7291 - rmse: 0.3091 - val_accuracy: 0.7000 - val_loss: 0.9690 - val_rmse: 0.3548\n",
      "Epoch 332/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6822 - loss: 0.8240 - rmse: 0.3325\n",
      "Epoch 332: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6821 - loss: 0.8260 - rmse: 0.3327 - val_accuracy: 0.6000 - val_loss: 1.1449 - val_rmse: 0.3581\n",
      "Epoch 333/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7114 - loss: 0.8440 - rmse: 0.3325\n",
      "Epoch 333: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7124 - loss: 0.8397 - rmse: 0.3316 - val_accuracy: 0.7000 - val_loss: 1.0883 - val_rmse: 0.3568\n",
      "Epoch 334/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7638 - loss: 0.7060 - rmse: 0.3041\n",
      "Epoch 334: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7636 - loss: 0.7075 - rmse: 0.3044 - val_accuracy: 0.6000 - val_loss: 1.0973 - val_rmse: 0.3615\n",
      "Epoch 335/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7615 - loss: 0.7239 - rmse: 0.3106\n",
      "Epoch 335: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7590 - loss: 0.7259 - rmse: 0.3109 - val_accuracy: 0.6500 - val_loss: 1.1026 - val_rmse: 0.3545\n",
      "Epoch 336/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6260 - loss: 0.8938 - rmse: 0.3450\n",
      "Epoch 336: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6286 - loss: 0.8899 - rmse: 0.3441 - val_accuracy: 0.6000 - val_loss: 1.1343 - val_rmse: 0.3594\n",
      "Epoch 337/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6758 - loss: 0.7499 - rmse: 0.3171\n",
      "Epoch 337: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6769 - loss: 0.7500 - rmse: 0.3171 - val_accuracy: 0.7500 - val_loss: 1.0824 - val_rmse: 0.3441\n",
      "Epoch 338/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6988 - loss: 0.6986 - rmse: 0.3080\n",
      "Epoch 338: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6984 - loss: 0.7039 - rmse: 0.3091 - val_accuracy: 0.7000 - val_loss: 1.0600 - val_rmse: 0.3495\n",
      "Epoch 339/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8021 - loss: 0.7222 - rmse: 0.3091\n",
      "Epoch 339: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7985 - loss: 0.7219 - rmse: 0.3091 - val_accuracy: 0.6500 - val_loss: 1.0961 - val_rmse: 0.3659\n",
      "Epoch 340/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7173 - loss: 0.7458 - rmse: 0.3172\n",
      "Epoch 340: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7187 - loss: 0.7443 - rmse: 0.3168 - val_accuracy: 0.6500 - val_loss: 1.0079 - val_rmse: 0.3476\n",
      "Epoch 341/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7192 - loss: 0.7504 - rmse: 0.3105\n",
      "Epoch 341: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7173 - loss: 0.7522 - rmse: 0.3111 - val_accuracy: 0.5500 - val_loss: 1.1539 - val_rmse: 0.3629\n",
      "Epoch 342/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6929 - loss: 0.7913 - rmse: 0.3268\n",
      "Epoch 342: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6918 - loss: 0.7957 - rmse: 0.3276 - val_accuracy: 0.5000 - val_loss: 1.1082 - val_rmse: 0.3723\n",
      "Epoch 343/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6777 - loss: 0.9318 - rmse: 0.3492\n",
      "Epoch 343: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6752 - loss: 0.9380 - rmse: 0.3501 - val_accuracy: 0.6000 - val_loss: 0.8887 - val_rmse: 0.3469\n",
      "Epoch 344/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6702 - loss: 0.8998 - rmse: 0.3465\n",
      "Epoch 344: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.6718 - loss: 0.8969 - rmse: 0.3459 - val_accuracy: 0.5500 - val_loss: 0.9439 - val_rmse: 0.3589\n",
      "Epoch 345/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7788 - loss: 0.6886 - rmse: 0.2942\n",
      "Epoch 345: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7774 - loss: 0.6903 - rmse: 0.2948 - val_accuracy: 0.7000 - val_loss: 0.9807 - val_rmse: 0.3509\n",
      "Epoch 346/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6700 - loss: 0.7732 - rmse: 0.3218\n",
      "Epoch 346: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6724 - loss: 0.7717 - rmse: 0.3213 - val_accuracy: 0.6500 - val_loss: 0.8995 - val_rmse: 0.3420\n",
      "Epoch 347/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7495 - loss: 0.6641 - rmse: 0.2934\n",
      "Epoch 347: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7499 - loss: 0.6651 - rmse: 0.2937 - val_accuracy: 0.7000 - val_loss: 0.8613 - val_rmse: 0.3384\n",
      "Epoch 348/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7181 - loss: 0.6889 - rmse: 0.3030\n",
      "Epoch 348: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7194 - loss: 0.6886 - rmse: 0.3029 - val_accuracy: 0.7000 - val_loss: 0.8513 - val_rmse: 0.3327\n",
      "Epoch 349/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8034 - loss: 0.6478 - rmse: 0.2886\n",
      "Epoch 349: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8013 - loss: 0.6519 - rmse: 0.2897 - val_accuracy: 0.6000 - val_loss: 0.9268 - val_rmse: 0.3403\n",
      "Epoch 350/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7718 - loss: 0.6647 - rmse: 0.2959\n",
      "Epoch 350: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7709 - loss: 0.6662 - rmse: 0.2962 - val_accuracy: 0.7500 - val_loss: 0.8657 - val_rmse: 0.3326\n",
      "Epoch 351/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7450 - loss: 0.7090 - rmse: 0.3058\n",
      "Epoch 351: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7449 - loss: 0.7079 - rmse: 0.3056 - val_accuracy: 0.6500 - val_loss: 0.9228 - val_rmse: 0.3477\n",
      "Epoch 352/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7377 - loss: 0.7041 - rmse: 0.3029\n",
      "Epoch 352: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7377 - loss: 0.7036 - rmse: 0.3028 - val_accuracy: 0.6000 - val_loss: 0.8964 - val_rmse: 0.3435\n",
      "Epoch 353/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8141 - loss: 0.6383 - rmse: 0.2886\n",
      "Epoch 353: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8127 - loss: 0.6384 - rmse: 0.2884 - val_accuracy: 0.7000 - val_loss: 0.8404 - val_rmse: 0.3233\n",
      "Epoch 354/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8379 - loss: 0.5643 - rmse: 0.2652\n",
      "Epoch 354: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8368 - loss: 0.5661 - rmse: 0.2657 - val_accuracy: 0.7500 - val_loss: 0.8630 - val_rmse: 0.3328\n",
      "Epoch 355/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7860 - loss: 0.7125 - rmse: 0.2977\n",
      "Epoch 355: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7784 - loss: 0.7272 - rmse: 0.3012 - val_accuracy: 0.7000 - val_loss: 0.9419 - val_rmse: 0.3537\n",
      "Epoch 356/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7227 - loss: 0.7551 - rmse: 0.3111\n",
      "Epoch 356: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7186 - loss: 0.7591 - rmse: 0.3122 - val_accuracy: 0.5500 - val_loss: 0.9835 - val_rmse: 0.3520\n",
      "Epoch 357/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6435 - loss: 0.8653 - rmse: 0.3371\n",
      "Epoch 357: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6457 - loss: 0.8617 - rmse: 0.3364 - val_accuracy: 0.6000 - val_loss: 0.8574 - val_rmse: 0.3386\n",
      "Epoch 358/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6980 - loss: 0.6816 - rmse: 0.3060\n",
      "Epoch 358: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7005 - loss: 0.6820 - rmse: 0.3057 - val_accuracy: 0.6500 - val_loss: 0.8522 - val_rmse: 0.3335\n",
      "Epoch 359/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7863 - loss: 0.6191 - rmse: 0.2825\n",
      "Epoch 359: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7847 - loss: 0.6214 - rmse: 0.2833 - val_accuracy: 0.6500 - val_loss: 0.8513 - val_rmse: 0.3357\n",
      "Epoch 360/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8169 - loss: 0.6370 - rmse: 0.2846\n",
      "Epoch 360: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8164 - loss: 0.6349 - rmse: 0.2844 - val_accuracy: 0.6500 - val_loss: 0.9050 - val_rmse: 0.3398\n",
      "Epoch 361/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7734 - loss: 0.6475 - rmse: 0.2892\n",
      "Epoch 361: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7740 - loss: 0.6442 - rmse: 0.2884 - val_accuracy: 0.6000 - val_loss: 0.8559 - val_rmse: 0.3360\n",
      "Epoch 362/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8148 - loss: 0.5777 - rmse: 0.2681\n",
      "Epoch 362: val_loss did not improve from 0.80357\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8143 - loss: 0.5776 - rmse: 0.2684 - val_accuracy: 0.6000 - val_loss: 0.8733 - val_rmse: 0.3374\n",
      "Epoch 363/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7968 - loss: 0.6692 - rmse: 0.2915\n",
      "Epoch 363: val_loss improved from 0.80357 to 0.72543, saving model to best_rnn_model_weights.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7965 - loss: 0.6684 - rmse: 0.2915 - val_accuracy: 0.7000 - val_loss: 0.7254 - val_rmse: 0.3023\n",
      "Epoch 364/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7887 - loss: 0.6375 - rmse: 0.2842\n",
      "Epoch 364: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7866 - loss: 0.6411 - rmse: 0.2853 - val_accuracy: 0.7000 - val_loss: 0.9968 - val_rmse: 0.3373\n",
      "Epoch 365/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7956 - loss: 0.6855 - rmse: 0.3022\n",
      "Epoch 365: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7943 - loss: 0.6865 - rmse: 0.3025 - val_accuracy: 0.6000 - val_loss: 1.0967 - val_rmse: 0.3692\n",
      "Epoch 366/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7106 - loss: 0.7735 - rmse: 0.3250\n",
      "Epoch 366: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7105 - loss: 0.7749 - rmse: 0.3251 - val_accuracy: 0.6000 - val_loss: 0.9553 - val_rmse: 0.3579\n",
      "Epoch 367/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6993 - loss: 0.8037 - rmse: 0.3260\n",
      "Epoch 367: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7006 - loss: 0.8019 - rmse: 0.3257 - val_accuracy: 0.6500 - val_loss: 0.9303 - val_rmse: 0.3476\n",
      "Epoch 368/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7859 - loss: 0.6216 - rmse: 0.2875\n",
      "Epoch 368: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7846 - loss: 0.6235 - rmse: 0.2880 - val_accuracy: 0.6500 - val_loss: 0.8733 - val_rmse: 0.3402\n",
      "Epoch 369/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6925 - loss: 0.6869 - rmse: 0.3064\n",
      "Epoch 369: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6971 - loss: 0.6839 - rmse: 0.3053 - val_accuracy: 0.6000 - val_loss: 0.8305 - val_rmse: 0.3206\n",
      "Epoch 370/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8153 - loss: 0.5310 - rmse: 0.2581\n",
      "Epoch 370: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8137 - loss: 0.5347 - rmse: 0.2592 - val_accuracy: 0.7000 - val_loss: 0.9024 - val_rmse: 0.3191\n",
      "Epoch 371/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7599 - loss: 0.5692 - rmse: 0.2711\n",
      "Epoch 371: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7605 - loss: 0.5705 - rmse: 0.2715 - val_accuracy: 0.7500 - val_loss: 0.8160 - val_rmse: 0.3167\n",
      "Epoch 372/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7523 - loss: 0.6897 - rmse: 0.2997\n",
      "Epoch 372: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7506 - loss: 0.6906 - rmse: 0.2997 - val_accuracy: 0.6500 - val_loss: 1.2219 - val_rmse: 0.3663\n",
      "Epoch 373/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6813 - loss: 0.8145 - rmse: 0.3269\n",
      "Epoch 373: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6828 - loss: 0.8106 - rmse: 0.3261 - val_accuracy: 0.6000 - val_loss: 1.1344 - val_rmse: 0.3687\n",
      "Epoch 374/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7477 - loss: 0.6766 - rmse: 0.3017\n",
      "Epoch 374: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7487 - loss: 0.6734 - rmse: 0.3010 - val_accuracy: 0.7000 - val_loss: 1.1042 - val_rmse: 0.3476\n",
      "Epoch 375/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7752 - loss: 0.5981 - rmse: 0.2820\n",
      "Epoch 375: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7753 - loss: 0.5978 - rmse: 0.2820 - val_accuracy: 0.6500 - val_loss: 1.1589 - val_rmse: 0.3457\n",
      "Epoch 376/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7852 - loss: 0.6301 - rmse: 0.2875\n",
      "Epoch 376: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7859 - loss: 0.6275 - rmse: 0.2869 - val_accuracy: 0.6000 - val_loss: 1.1345 - val_rmse: 0.3635\n",
      "Epoch 377/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8098 - loss: 0.4850 - rmse: 0.2516\n",
      "Epoch 377: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8094 - loss: 0.4870 - rmse: 0.2521 - val_accuracy: 0.7000 - val_loss: 1.0180 - val_rmse: 0.3403\n",
      "Epoch 378/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8920 - loss: 0.4064 - rmse: 0.2204\n",
      "Epoch 378: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8873 - loss: 0.4135 - rmse: 0.2227 - val_accuracy: 0.6500 - val_loss: 0.9028 - val_rmse: 0.3336\n",
      "Epoch 379/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8339 - loss: 0.5256 - rmse: 0.2523\n",
      "Epoch 379: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8316 - loss: 0.5295 - rmse: 0.2534 - val_accuracy: 0.6000 - val_loss: 1.2098 - val_rmse: 0.3661\n",
      "Epoch 380/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8535 - loss: 0.5545 - rmse: 0.2554\n",
      "Epoch 380: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8518 - loss: 0.5548 - rmse: 0.2556 - val_accuracy: 0.6500 - val_loss: 0.9936 - val_rmse: 0.3493\n",
      "Epoch 381/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8094 - loss: 0.4975 - rmse: 0.2486\n",
      "Epoch 381: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8093 - loss: 0.4988 - rmse: 0.2490 - val_accuracy: 0.7000 - val_loss: 0.9362 - val_rmse: 0.3362\n",
      "Epoch 382/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8028 - loss: 0.5889 - rmse: 0.2717\n",
      "Epoch 382: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8013 - loss: 0.5919 - rmse: 0.2726 - val_accuracy: 0.6500 - val_loss: 0.9722 - val_rmse: 0.3529\n",
      "Epoch 383/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7934 - loss: 0.5747 - rmse: 0.2705\n",
      "Epoch 383: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7915 - loss: 0.5775 - rmse: 0.2715 - val_accuracy: 0.6500 - val_loss: 0.9643 - val_rmse: 0.3371\n",
      "Epoch 384/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7942 - loss: 0.5503 - rmse: 0.2704\n",
      "Epoch 384: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7949 - loss: 0.5501 - rmse: 0.2700 - val_accuracy: 0.6500 - val_loss: 0.9269 - val_rmse: 0.3088\n",
      "Epoch 385/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8143 - loss: 0.5851 - rmse: 0.2750\n",
      "Epoch 385: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8131 - loss: 0.5870 - rmse: 0.2755 - val_accuracy: 0.7000 - val_loss: 0.9698 - val_rmse: 0.3348\n",
      "Epoch 386/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7766 - loss: 0.5453 - rmse: 0.2657\n",
      "Epoch 386: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7771 - loss: 0.5484 - rmse: 0.2663 - val_accuracy: 0.6500 - val_loss: 0.8507 - val_rmse: 0.3336\n",
      "Epoch 387/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7318 - loss: 0.6408 - rmse: 0.2948\n",
      "Epoch 387: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7329 - loss: 0.6394 - rmse: 0.2944 - val_accuracy: 0.6500 - val_loss: 0.9320 - val_rmse: 0.3335\n",
      "Epoch 388/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7912 - loss: 0.5272 - rmse: 0.2594\n",
      "Epoch 388: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7909 - loss: 0.5279 - rmse: 0.2596 - val_accuracy: 0.7000 - val_loss: 0.8606 - val_rmse: 0.3108\n",
      "Epoch 389/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7745 - loss: 0.5704 - rmse: 0.2768\n",
      "Epoch 389: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7750 - loss: 0.5699 - rmse: 0.2767 - val_accuracy: 0.7500 - val_loss: 0.8277 - val_rmse: 0.3165\n",
      "Epoch 390/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8439 - loss: 0.4846 - rmse: 0.2394\n",
      "Epoch 390: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8427 - loss: 0.4866 - rmse: 0.2402 - val_accuracy: 0.7500 - val_loss: 0.9213 - val_rmse: 0.3361\n",
      "Epoch 391/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8647 - loss: 0.4407 - rmse: 0.2335\n",
      "Epoch 391: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8619 - loss: 0.4444 - rmse: 0.2348 - val_accuracy: 0.7000 - val_loss: 0.8690 - val_rmse: 0.3274\n",
      "Epoch 392/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7711 - loss: 0.5704 - rmse: 0.2724\n",
      "Epoch 392: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7756 - loss: 0.5643 - rmse: 0.2708 - val_accuracy: 0.6500 - val_loss: 1.0344 - val_rmse: 0.3327\n",
      "Epoch 393/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8176 - loss: 0.5750 - rmse: 0.2666\n",
      "Epoch 393: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8173 - loss: 0.5734 - rmse: 0.2664 - val_accuracy: 0.7000 - val_loss: 0.9396 - val_rmse: 0.3268\n",
      "Epoch 394/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8371 - loss: 0.4372 - rmse: 0.2344\n",
      "Epoch 394: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8366 - loss: 0.4383 - rmse: 0.2348 - val_accuracy: 0.6500 - val_loss: 1.1557 - val_rmse: 0.3550\n",
      "Epoch 395/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7808 - loss: 0.5173 - rmse: 0.2565\n",
      "Epoch 395: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7809 - loss: 0.5180 - rmse: 0.2567 - val_accuracy: 0.7000 - val_loss: 0.8311 - val_rmse: 0.3324\n",
      "Epoch 396/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7362 - loss: 0.6534 - rmse: 0.2947\n",
      "Epoch 396: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7353 - loss: 0.6563 - rmse: 0.2954 - val_accuracy: 0.6000 - val_loss: 1.4159 - val_rmse: 0.3696\n",
      "Epoch 397/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6820 - loss: 0.7909 - rmse: 0.3250\n",
      "Epoch 397: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6833 - loss: 0.7896 - rmse: 0.3246 - val_accuracy: 0.6500 - val_loss: 0.9928 - val_rmse: 0.3511\n",
      "Epoch 398/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7031 - loss: 0.7366 - rmse: 0.3120\n",
      "Epoch 398: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7019 - loss: 0.7370 - rmse: 0.3123 - val_accuracy: 0.6500 - val_loss: 1.0121 - val_rmse: 0.3539\n",
      "Epoch 399/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7780 - loss: 0.6126 - rmse: 0.2831\n",
      "Epoch 399: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7783 - loss: 0.6116 - rmse: 0.2829 - val_accuracy: 0.7000 - val_loss: 0.9961 - val_rmse: 0.3360\n",
      "Epoch 400/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8278 - loss: 0.5478 - rmse: 0.2637\n",
      "Epoch 400: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8274 - loss: 0.5474 - rmse: 0.2638 - val_accuracy: 0.7000 - val_loss: 0.9914 - val_rmse: 0.3309\n",
      "Epoch 401/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8705 - loss: 0.4179 - rmse: 0.2242\n",
      "Epoch 401: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8665 - loss: 0.4249 - rmse: 0.2267 - val_accuracy: 0.6500 - val_loss: 0.9556 - val_rmse: 0.3309\n",
      "Epoch 402/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7795 - loss: 0.5539 - rmse: 0.2677\n",
      "Epoch 402: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7828 - loss: 0.5487 - rmse: 0.2665 - val_accuracy: 0.7000 - val_loss: 1.2453 - val_rmse: 0.3297\n",
      "Epoch 403/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8632 - loss: 0.4442 - rmse: 0.2376\n",
      "Epoch 403: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8595 - loss: 0.4487 - rmse: 0.2390 - val_accuracy: 0.7000 - val_loss: 1.0415 - val_rmse: 0.3251\n",
      "Epoch 404/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8080 - loss: 0.4884 - rmse: 0.2536\n",
      "Epoch 404: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8082 - loss: 0.4890 - rmse: 0.2540 - val_accuracy: 0.7000 - val_loss: 1.0239 - val_rmse: 0.3284\n",
      "Epoch 405/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8555 - loss: 0.4346 - rmse: 0.2339\n",
      "Epoch 405: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8556 - loss: 0.4349 - rmse: 0.2341 - val_accuracy: 0.6500 - val_loss: 1.2032 - val_rmse: 0.3427\n",
      "Epoch 406/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8175 - loss: 0.5051 - rmse: 0.2593\n",
      "Epoch 406: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8185 - loss: 0.5036 - rmse: 0.2587 - val_accuracy: 0.6500 - val_loss: 1.1783 - val_rmse: 0.3655\n",
      "Epoch 407/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8555 - loss: 0.3854 - rmse: 0.2198\n",
      "Epoch 407: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8540 - loss: 0.3876 - rmse: 0.2208 - val_accuracy: 0.6000 - val_loss: 1.4784 - val_rmse: 0.3849\n",
      "Epoch 408/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8186 - loss: 0.4483 - rmse: 0.2322\n",
      "Epoch 408: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8168 - loss: 0.4516 - rmse: 0.2337 - val_accuracy: 0.5500 - val_loss: 1.2062 - val_rmse: 0.3862\n",
      "Epoch 409/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7868 - loss: 0.5332 - rmse: 0.2694\n",
      "Epoch 409: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7889 - loss: 0.5282 - rmse: 0.2678 - val_accuracy: 0.6000 - val_loss: 1.5708 - val_rmse: 0.3790\n",
      "Epoch 410/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8394 - loss: 0.3947 - rmse: 0.2215\n",
      "Epoch 410: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8388 - loss: 0.3964 - rmse: 0.2221 - val_accuracy: 0.6000 - val_loss: 1.3453 - val_rmse: 0.3848\n",
      "Epoch 411/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8718 - loss: 0.4148 - rmse: 0.2364\n",
      "Epoch 411: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8686 - loss: 0.4197 - rmse: 0.2376 - val_accuracy: 0.6000 - val_loss: 1.4163 - val_rmse: 0.3680\n",
      "Epoch 412/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7940 - loss: 0.5066 - rmse: 0.2618\n",
      "Epoch 412: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7961 - loss: 0.5044 - rmse: 0.2611 - val_accuracy: 0.6500 - val_loss: 1.2695 - val_rmse: 0.3560\n",
      "Epoch 413/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8735 - loss: 0.4636 - rmse: 0.2321\n",
      "Epoch 413: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8666 - loss: 0.5115 - rmse: 0.2376 - val_accuracy: 0.5500 - val_loss: 1.5990 - val_rmse: 0.4233\n",
      "Epoch 414/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5699 - loss: 1.5046 - rmse: 0.3862\n",
      "Epoch 414: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5704 - loss: 1.5028 - rmse: 0.3861 - val_accuracy: 0.6000 - val_loss: 1.4950 - val_rmse: 0.4022\n",
      "Epoch 415/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7028 - loss: 0.9104 - rmse: 0.3471\n",
      "Epoch 415: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7018 - loss: 0.9108 - rmse: 0.3471 - val_accuracy: 0.6000 - val_loss: 1.3234 - val_rmse: 0.4034\n",
      "Epoch 416/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6754 - loss: 0.8647 - rmse: 0.3422\n",
      "Epoch 416: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6763 - loss: 0.8646 - rmse: 0.3421 - val_accuracy: 0.6500 - val_loss: 1.1959 - val_rmse: 0.3867\n",
      "Epoch 417/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6980 - loss: 0.8988 - rmse: 0.3410\n",
      "Epoch 417: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7020 - loss: 0.8901 - rmse: 0.3396 - val_accuracy: 0.6500 - val_loss: 1.0836 - val_rmse: 0.3797\n",
      "Epoch 418/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6781 - loss: 0.8469 - rmse: 0.3389\n",
      "Epoch 418: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6812 - loss: 0.8430 - rmse: 0.3378 - val_accuracy: 0.6500 - val_loss: 1.0959 - val_rmse: 0.3863\n",
      "Epoch 419/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8246 - loss: 0.6308 - rmse: 0.2847\n",
      "Epoch 419: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8226 - loss: 0.6333 - rmse: 0.2852 - val_accuracy: 0.7000 - val_loss: 1.0744 - val_rmse: 0.3827\n",
      "Epoch 420/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7335 - loss: 0.6979 - rmse: 0.2968\n",
      "Epoch 420: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7337 - loss: 0.6980 - rmse: 0.2970 - val_accuracy: 0.7000 - val_loss: 1.0532 - val_rmse: 0.3750\n",
      "Epoch 421/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7235 - loss: 0.7081 - rmse: 0.2989\n",
      "Epoch 421: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7240 - loss: 0.7070 - rmse: 0.2988 - val_accuracy: 0.7000 - val_loss: 0.9654 - val_rmse: 0.3699\n",
      "Epoch 422/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7090 - loss: 0.7688 - rmse: 0.3101\n",
      "Epoch 422: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7103 - loss: 0.7657 - rmse: 0.3095 - val_accuracy: 0.7000 - val_loss: 0.9262 - val_rmse: 0.3649\n",
      "Epoch 423/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7575 - loss: 0.6403 - rmse: 0.2895\n",
      "Epoch 423: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7573 - loss: 0.6411 - rmse: 0.2897 - val_accuracy: 0.6500 - val_loss: 0.9834 - val_rmse: 0.3681\n",
      "Epoch 424/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7280 - loss: 0.6981 - rmse: 0.2959\n",
      "Epoch 424: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7280 - loss: 0.6972 - rmse: 0.2958 - val_accuracy: 0.6500 - val_loss: 0.8948 - val_rmse: 0.3518\n",
      "Epoch 425/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7715 - loss: 0.6028 - rmse: 0.2780\n",
      "Epoch 425: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7705 - loss: 0.6054 - rmse: 0.2787 - val_accuracy: 0.5500 - val_loss: 0.9646 - val_rmse: 0.3708\n",
      "Epoch 426/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8207 - loss: 0.4883 - rmse: 0.2430\n",
      "Epoch 426: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8165 - loss: 0.4964 - rmse: 0.2454 - val_accuracy: 0.6000 - val_loss: 0.9236 - val_rmse: 0.3627\n",
      "Epoch 427/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7623 - loss: 0.6173 - rmse: 0.2835\n",
      "Epoch 427: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7625 - loss: 0.6171 - rmse: 0.2835 - val_accuracy: 0.6500 - val_loss: 0.9128 - val_rmse: 0.3615\n",
      "Epoch 428/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7512 - loss: 0.5684 - rmse: 0.2712\n",
      "Epoch 428: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7517 - loss: 0.5690 - rmse: 0.2713 - val_accuracy: 0.5500 - val_loss: 0.9314 - val_rmse: 0.3689\n",
      "Epoch 429/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8335 - loss: 0.5282 - rmse: 0.2607\n",
      "Epoch 429: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8309 - loss: 0.5318 - rmse: 0.2616 - val_accuracy: 0.5500 - val_loss: 0.9400 - val_rmse: 0.3684\n",
      "Epoch 430/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7321 - loss: 0.5896 - rmse: 0.2794\n",
      "Epoch 430: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7337 - loss: 0.5888 - rmse: 0.2791 - val_accuracy: 0.6000 - val_loss: 0.9806 - val_rmse: 0.3677\n",
      "Epoch 431/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7426 - loss: 0.6472 - rmse: 0.2890\n",
      "Epoch 431: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7443 - loss: 0.6447 - rmse: 0.2884 - val_accuracy: 0.6000 - val_loss: 0.9868 - val_rmse: 0.3642\n",
      "Epoch 432/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7540 - loss: 0.5927 - rmse: 0.2802\n",
      "Epoch 432: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7544 - loss: 0.5920 - rmse: 0.2800 - val_accuracy: 0.6000 - val_loss: 0.9605 - val_rmse: 0.3603\n",
      "Epoch 433/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8002 - loss: 0.5338 - rmse: 0.2649\n",
      "Epoch 433: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8000 - loss: 0.5341 - rmse: 0.2651 - val_accuracy: 0.5000 - val_loss: 1.0462 - val_rmse: 0.3788\n",
      "Epoch 434/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7331 - loss: 0.6733 - rmse: 0.2969\n",
      "Epoch 434: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7343 - loss: 0.6701 - rmse: 0.2962 - val_accuracy: 0.5000 - val_loss: 1.0166 - val_rmse: 0.3669\n",
      "Epoch 435/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7692 - loss: 0.5477 - rmse: 0.2659\n",
      "Epoch 435: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7694 - loss: 0.5471 - rmse: 0.2658 - val_accuracy: 0.5500 - val_loss: 1.0019 - val_rmse: 0.3610\n",
      "Epoch 436/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8383 - loss: 0.4436 - rmse: 0.2389\n",
      "Epoch 436: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8365 - loss: 0.4475 - rmse: 0.2400 - val_accuracy: 0.5000 - val_loss: 1.1474 - val_rmse: 0.3874\n",
      "Epoch 437/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7465 - loss: 0.6100 - rmse: 0.2865\n",
      "Epoch 437: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7475 - loss: 0.6078 - rmse: 0.2858 - val_accuracy: 0.5500 - val_loss: 1.1011 - val_rmse: 0.3747\n",
      "Epoch 438/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7632 - loss: 0.5665 - rmse: 0.2772\n",
      "Epoch 438: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7665 - loss: 0.5623 - rmse: 0.2758 - val_accuracy: 0.5500 - val_loss: 1.1110 - val_rmse: 0.3788\n",
      "Epoch 439/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8425 - loss: 0.5035 - rmse: 0.2593\n",
      "Epoch 439: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8409 - loss: 0.5048 - rmse: 0.2595 - val_accuracy: 0.5500 - val_loss: 1.0750 - val_rmse: 0.3686\n",
      "Epoch 440/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8088 - loss: 0.5447 - rmse: 0.2593\n",
      "Epoch 440: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8085 - loss: 0.5436 - rmse: 0.2593 - val_accuracy: 0.6000 - val_loss: 1.0800 - val_rmse: 0.3708\n",
      "Epoch 441/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8482 - loss: 0.4394 - rmse: 0.2325\n",
      "Epoch 441: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8470 - loss: 0.4411 - rmse: 0.2332 - val_accuracy: 0.6000 - val_loss: 1.1299 - val_rmse: 0.3688\n",
      "Epoch 442/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7915 - loss: 0.4773 - rmse: 0.2545\n",
      "Epoch 442: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7911 - loss: 0.4787 - rmse: 0.2547 - val_accuracy: 0.7000 - val_loss: 1.1805 - val_rmse: 0.3497\n",
      "Epoch 443/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7888 - loss: 0.4911 - rmse: 0.2516\n",
      "Epoch 443: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7905 - loss: 0.4918 - rmse: 0.2519 - val_accuracy: 0.6000 - val_loss: 1.2733 - val_rmse: 0.3706\n",
      "Epoch 444/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8131 - loss: 0.5195 - rmse: 0.2614\n",
      "Epoch 444: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8142 - loss: 0.5187 - rmse: 0.2613 - val_accuracy: 0.6000 - val_loss: 1.1838 - val_rmse: 0.3874\n",
      "Epoch 445/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7807 - loss: 0.6071 - rmse: 0.2738\n",
      "Epoch 445: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7810 - loss: 0.6067 - rmse: 0.2738 - val_accuracy: 0.6500 - val_loss: 1.1372 - val_rmse: 0.3625\n",
      "Epoch 446/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7569 - loss: 0.5494 - rmse: 0.2735\n",
      "Epoch 446: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7579 - loss: 0.5483 - rmse: 0.2732 - val_accuracy: 0.6000 - val_loss: 1.1199 - val_rmse: 0.3548\n",
      "Epoch 447/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8687 - loss: 0.4493 - rmse: 0.2384\n",
      "Epoch 447: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8659 - loss: 0.4512 - rmse: 0.2393 - val_accuracy: 0.5000 - val_loss: 1.3074 - val_rmse: 0.3728\n",
      "Epoch 448/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8341 - loss: 0.4852 - rmse: 0.2584\n",
      "Epoch 448: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8344 - loss: 0.4844 - rmse: 0.2579 - val_accuracy: 0.5500 - val_loss: 1.2487 - val_rmse: 0.3684\n",
      "Epoch 449/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8064 - loss: 0.4495 - rmse: 0.2437\n",
      "Epoch 449: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8062 - loss: 0.4511 - rmse: 0.2441 - val_accuracy: 0.5500 - val_loss: 1.0991 - val_rmse: 0.3857\n",
      "Epoch 450/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7579 - loss: 0.6133 - rmse: 0.2814\n",
      "Epoch 450: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7575 - loss: 0.6124 - rmse: 0.2813 - val_accuracy: 0.5000 - val_loss: 1.1870 - val_rmse: 0.3918\n",
      "Epoch 451/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7712 - loss: 0.5462 - rmse: 0.2692\n",
      "Epoch 451: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7716 - loss: 0.5423 - rmse: 0.2684 - val_accuracy: 0.5000 - val_loss: 1.0288 - val_rmse: 0.3713\n",
      "Epoch 452/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8149 - loss: 0.4858 - rmse: 0.2547\n",
      "Epoch 452: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8154 - loss: 0.4843 - rmse: 0.2543 - val_accuracy: 0.5500 - val_loss: 1.1179 - val_rmse: 0.3695\n",
      "Epoch 453/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8061 - loss: 0.4585 - rmse: 0.2446\n",
      "Epoch 453: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8059 - loss: 0.4592 - rmse: 0.2448 - val_accuracy: 0.5500 - val_loss: 1.2932 - val_rmse: 0.3950\n",
      "Epoch 454/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8228 - loss: 0.4352 - rmse: 0.2373\n",
      "Epoch 454: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8229 - loss: 0.4354 - rmse: 0.2374 - val_accuracy: 0.5500 - val_loss: 1.1906 - val_rmse: 0.4012\n",
      "Epoch 455/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8869 - loss: 0.3832 - rmse: 0.2222\n",
      "Epoch 455: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8860 - loss: 0.3855 - rmse: 0.2230 - val_accuracy: 0.5500 - val_loss: 1.5492 - val_rmse: 0.4002\n",
      "Epoch 456/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8605 - loss: 0.4148 - rmse: 0.2291\n",
      "Epoch 456: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8594 - loss: 0.4163 - rmse: 0.2297 - val_accuracy: 0.4500 - val_loss: 1.4475 - val_rmse: 0.4067\n",
      "Epoch 457/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8022 - loss: 0.4738 - rmse: 0.2488\n",
      "Epoch 457: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8043 - loss: 0.4731 - rmse: 0.2486 - val_accuracy: 0.5500 - val_loss: 1.3551 - val_rmse: 0.4082\n",
      "Epoch 458/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8589 - loss: 0.4324 - rmse: 0.2322\n",
      "Epoch 458: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8584 - loss: 0.4330 - rmse: 0.2326 - val_accuracy: 0.6500 - val_loss: 1.1136 - val_rmse: 0.3387\n",
      "Epoch 459/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7524 - loss: 0.6391 - rmse: 0.2848\n",
      "Epoch 459: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7508 - loss: 0.6399 - rmse: 0.2854 - val_accuracy: 0.5000 - val_loss: 1.4483 - val_rmse: 0.4219\n",
      "Epoch 460/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7810 - loss: 0.6113 - rmse: 0.2793\n",
      "Epoch 460: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7786 - loss: 0.6128 - rmse: 0.2798 - val_accuracy: 0.5500 - val_loss: 1.7402 - val_rmse: 0.3999\n",
      "Epoch 461/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7990 - loss: 0.4972 - rmse: 0.2582\n",
      "Epoch 461: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7979 - loss: 0.4978 - rmse: 0.2584 - val_accuracy: 0.5500 - val_loss: 1.6807 - val_rmse: 0.4032\n",
      "Epoch 462/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7640 - loss: 0.5308 - rmse: 0.2689\n",
      "Epoch 462: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7647 - loss: 0.5297 - rmse: 0.2686 - val_accuracy: 0.5500 - val_loss: 1.5631 - val_rmse: 0.3928\n",
      "Epoch 463/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7852 - loss: 0.4582 - rmse: 0.2492\n",
      "Epoch 463: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.7859 - loss: 0.4581 - rmse: 0.2492 - val_accuracy: 0.5000 - val_loss: 1.6291 - val_rmse: 0.4033\n",
      "Epoch 464/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8283 - loss: 0.4890 - rmse: 0.2553\n",
      "Epoch 464: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.8291 - loss: 0.4854 - rmse: 0.2545 - val_accuracy: 0.6000 - val_loss: 1.6947 - val_rmse: 0.4093\n",
      "Epoch 465/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8401 - loss: 0.3911 - rmse: 0.2240\n",
      "Epoch 465: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8398 - loss: 0.3950 - rmse: 0.2253 - val_accuracy: 0.4500 - val_loss: 1.7223 - val_rmse: 0.4268\n",
      "Epoch 466/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8371 - loss: 0.4281 - rmse: 0.2406\n",
      "Epoch 466: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8390 - loss: 0.4261 - rmse: 0.2398 - val_accuracy: 0.5500 - val_loss: 1.7543 - val_rmse: 0.4118\n",
      "Epoch 467/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8726 - loss: 0.3798 - rmse: 0.2254\n",
      "Epoch 467: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8717 - loss: 0.3811 - rmse: 0.2258 - val_accuracy: 0.5000 - val_loss: 1.8050 - val_rmse: 0.4104\n",
      "Epoch 468/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8879 - loss: 0.3671 - rmse: 0.2140\n",
      "Epoch 468: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8868 - loss: 0.3684 - rmse: 0.2146 - val_accuracy: 0.4500 - val_loss: 1.7733 - val_rmse: 0.4201\n",
      "Epoch 469/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8836 - loss: 0.3346 - rmse: 0.2027\n",
      "Epoch 469: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8794 - loss: 0.3414 - rmse: 0.2056 - val_accuracy: 0.6000 - val_loss: 1.8841 - val_rmse: 0.4229\n",
      "Epoch 470/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8032 - loss: 0.4893 - rmse: 0.2540\n",
      "Epoch 470: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8027 - loss: 0.4916 - rmse: 0.2545 - val_accuracy: 0.5500 - val_loss: 1.6335 - val_rmse: 0.3957\n",
      "Epoch 471/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6645 - loss: 1.4240 - rmse: 0.3262\n",
      "Epoch 471: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6638 - loss: 1.4264 - rmse: 0.3266 - val_accuracy: 0.5000 - val_loss: 1.6295 - val_rmse: 0.4323\n",
      "Epoch 472/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6701 - loss: 1.0953 - rmse: 0.3692\n",
      "Epoch 472: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6680 - loss: 1.0941 - rmse: 0.3694 - val_accuracy: 0.6000 - val_loss: 1.4019 - val_rmse: 0.4117\n",
      "Epoch 473/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6495 - loss: 0.8174 - rmse: 0.3394\n",
      "Epoch 473: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6500 - loss: 0.8174 - rmse: 0.3391 - val_accuracy: 0.6000 - val_loss: 1.2583 - val_rmse: 0.3855\n",
      "Epoch 474/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5920 - loss: 0.9354 - rmse: 0.3538\n",
      "Epoch 474: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5935 - loss: 0.9325 - rmse: 0.3533 - val_accuracy: 0.6500 - val_loss: 1.1565 - val_rmse: 0.3665\n",
      "Epoch 475/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7078 - loss: 0.7264 - rmse: 0.3127\n",
      "Epoch 475: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7070 - loss: 0.7270 - rmse: 0.3129 - val_accuracy: 0.6000 - val_loss: 1.2662 - val_rmse: 0.3772\n",
      "Epoch 476/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7181 - loss: 0.6683 - rmse: 0.3020\n",
      "Epoch 476: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7179 - loss: 0.6693 - rmse: 0.3023 - val_accuracy: 0.5500 - val_loss: 1.2802 - val_rmse: 0.3801\n",
      "Epoch 477/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6837 - loss: 0.7279 - rmse: 0.3173\n",
      "Epoch 477: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6857 - loss: 0.7245 - rmse: 0.3166 - val_accuracy: 0.6000 - val_loss: 1.2320 - val_rmse: 0.3802\n",
      "Epoch 478/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7350 - loss: 0.6210 - rmse: 0.2930\n",
      "Epoch 478: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7339 - loss: 0.6232 - rmse: 0.2935 - val_accuracy: 0.5500 - val_loss: 1.2992 - val_rmse: 0.3878\n",
      "Epoch 479/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7767 - loss: 0.5411 - rmse: 0.2663\n",
      "Epoch 479: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7734 - loss: 0.5468 - rmse: 0.2681 - val_accuracy: 0.6000 - val_loss: 1.2634 - val_rmse: 0.3881\n",
      "Epoch 480/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6602 - loss: 0.7464 - rmse: 0.3221\n",
      "Epoch 480: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6643 - loss: 0.7401 - rmse: 0.3206 - val_accuracy: 0.5000 - val_loss: 1.2608 - val_rmse: 0.3840\n",
      "Epoch 481/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7384 - loss: 0.6279 - rmse: 0.2899\n",
      "Epoch 481: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7395 - loss: 0.6270 - rmse: 0.2897 - val_accuracy: 0.6000 - val_loss: 1.1563 - val_rmse: 0.3730\n",
      "Epoch 482/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7970 - loss: 0.5300 - rmse: 0.2659\n",
      "Epoch 482: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7941 - loss: 0.5325 - rmse: 0.2667 - val_accuracy: 0.5500 - val_loss: 1.2189 - val_rmse: 0.3769\n",
      "Epoch 483/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7877 - loss: 0.4976 - rmse: 0.2551\n",
      "Epoch 483: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7845 - loss: 0.5044 - rmse: 0.2573 - val_accuracy: 0.5500 - val_loss: 1.2679 - val_rmse: 0.3785\n",
      "Epoch 484/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8112 - loss: 0.5054 - rmse: 0.2609\n",
      "Epoch 484: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8094 - loss: 0.5069 - rmse: 0.2613 - val_accuracy: 0.5500 - val_loss: 1.3235 - val_rmse: 0.3840\n",
      "Epoch 485/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7953 - loss: 0.5097 - rmse: 0.2640\n",
      "Epoch 485: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7962 - loss: 0.5101 - rmse: 0.2641 - val_accuracy: 0.6500 - val_loss: 1.2578 - val_rmse: 0.3704\n",
      "Epoch 486/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8361 - loss: 0.4791 - rmse: 0.2537\n",
      "Epoch 486: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8356 - loss: 0.4800 - rmse: 0.2539 - val_accuracy: 0.5000 - val_loss: 1.1961 - val_rmse: 0.3737\n",
      "Epoch 487/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7646 - loss: 0.5515 - rmse: 0.2773\n",
      "Epoch 487: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7689 - loss: 0.5465 - rmse: 0.2757 - val_accuracy: 0.5500 - val_loss: 1.2455 - val_rmse: 0.3782\n",
      "Epoch 488/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8312 - loss: 0.4531 - rmse: 0.2447\n",
      "Epoch 488: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8306 - loss: 0.4551 - rmse: 0.2453 - val_accuracy: 0.5500 - val_loss: 1.1870 - val_rmse: 0.3741\n",
      "Epoch 489/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7514 - loss: 0.5207 - rmse: 0.2651\n",
      "Epoch 489: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7519 - loss: 0.5202 - rmse: 0.2650 - val_accuracy: 0.6000 - val_loss: 1.1231 - val_rmse: 0.3644\n",
      "Epoch 490/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8497 - loss: 0.4709 - rmse: 0.2517\n",
      "Epoch 490: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8492 - loss: 0.4707 - rmse: 0.2516 - val_accuracy: 0.5500 - val_loss: 1.1124 - val_rmse: 0.3728\n",
      "Epoch 491/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8340 - loss: 0.4686 - rmse: 0.2517\n",
      "Epoch 491: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8338 - loss: 0.4693 - rmse: 0.2518 - val_accuracy: 0.6000 - val_loss: 1.1106 - val_rmse: 0.3711\n",
      "Epoch 492/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8963 - loss: 0.3881 - rmse: 0.2203\n",
      "Epoch 492: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8945 - loss: 0.3906 - rmse: 0.2212 - val_accuracy: 0.6000 - val_loss: 1.0227 - val_rmse: 0.3656\n",
      "Epoch 493/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8797 - loss: 0.3596 - rmse: 0.2122\n",
      "Epoch 493: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8784 - loss: 0.3618 - rmse: 0.2130 - val_accuracy: 0.6000 - val_loss: 1.1378 - val_rmse: 0.3690\n",
      "Epoch 494/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8254 - loss: 0.4300 - rmse: 0.2380\n",
      "Epoch 494: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8256 - loss: 0.4301 - rmse: 0.2381 - val_accuracy: 0.5500 - val_loss: 1.1419 - val_rmse: 0.3790\n",
      "Epoch 495/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8609 - loss: 0.3849 - rmse: 0.2193\n",
      "Epoch 495: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8604 - loss: 0.3874 - rmse: 0.2205 - val_accuracy: 0.5500 - val_loss: 1.0744 - val_rmse: 0.3763\n",
      "Epoch 496/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8664 - loss: 0.4262 - rmse: 0.2372\n",
      "Epoch 496: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8663 - loss: 0.4257 - rmse: 0.2372 - val_accuracy: 0.5500 - val_loss: 1.1829 - val_rmse: 0.3847\n",
      "Epoch 497/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8545 - loss: 0.3901 - rmse: 0.2271\n",
      "Epoch 497: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8539 - loss: 0.3916 - rmse: 0.2275 - val_accuracy: 0.5500 - val_loss: 1.1305 - val_rmse: 0.3841\n",
      "Epoch 498/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8235 - loss: 0.4858 - rmse: 0.2553\n",
      "Epoch 498: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8241 - loss: 0.4834 - rmse: 0.2547 - val_accuracy: 0.5500 - val_loss: 1.1878 - val_rmse: 0.3802\n",
      "Epoch 499/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8679 - loss: 0.3488 - rmse: 0.2171\n",
      "Epoch 499: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8671 - loss: 0.3505 - rmse: 0.2176 - val_accuracy: 0.5500 - val_loss: 1.2640 - val_rmse: 0.3863\n",
      "Epoch 500/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8825 - loss: 0.3853 - rmse: 0.2221\n",
      "Epoch 500: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8807 - loss: 0.3869 - rmse: 0.2231 - val_accuracy: 0.5500 - val_loss: 1.2628 - val_rmse: 0.3826\n",
      "Epoch 501/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8933 - loss: 0.3554 - rmse: 0.2104\n",
      "Epoch 501: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8930 - loss: 0.3562 - rmse: 0.2108 - val_accuracy: 0.6500 - val_loss: 1.1464 - val_rmse: 0.3728\n",
      "Epoch 502/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8040 - loss: 0.5406 - rmse: 0.2685\n",
      "Epoch 502: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8070 - loss: 0.5323 - rmse: 0.2664 - val_accuracy: 0.5000 - val_loss: 1.2103 - val_rmse: 0.3923\n",
      "Epoch 503/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8698 - loss: 0.4350 - rmse: 0.2355\n",
      "Epoch 503: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8697 - loss: 0.4343 - rmse: 0.2353 - val_accuracy: 0.5500 - val_loss: 1.1271 - val_rmse: 0.3801\n",
      "Epoch 504/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8576 - loss: 0.4616 - rmse: 0.2427\n",
      "Epoch 504: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8577 - loss: 0.4602 - rmse: 0.2424 - val_accuracy: 0.6000 - val_loss: 1.1061 - val_rmse: 0.3747\n",
      "Epoch 505/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8812 - loss: 0.3877 - rmse: 0.2205\n",
      "Epoch 505: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8807 - loss: 0.3876 - rmse: 0.2206 - val_accuracy: 0.6000 - val_loss: 1.2161 - val_rmse: 0.3698\n",
      "Epoch 506/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8767 - loss: 0.3571 - rmse: 0.2104\n",
      "Epoch 506: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8759 - loss: 0.3583 - rmse: 0.2110 - val_accuracy: 0.5500 - val_loss: 1.3211 - val_rmse: 0.3964\n",
      "Epoch 507/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8718 - loss: 0.3336 - rmse: 0.2090\n",
      "Epoch 507: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8712 - loss: 0.3351 - rmse: 0.2096 - val_accuracy: 0.5500 - val_loss: 1.2820 - val_rmse: 0.3855\n",
      "Epoch 508/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8576 - loss: 0.3724 - rmse: 0.2218\n",
      "Epoch 508: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8570 - loss: 0.3733 - rmse: 0.2222 - val_accuracy: 0.6000 - val_loss: 1.2141 - val_rmse: 0.3739\n",
      "Epoch 509/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8230 - loss: 0.3922 - rmse: 0.2282\n",
      "Epoch 509: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8235 - loss: 0.3914 - rmse: 0.2282 - val_accuracy: 0.5500 - val_loss: 1.2666 - val_rmse: 0.3857\n",
      "Epoch 510/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8586 - loss: 0.3049 - rmse: 0.2010\n",
      "Epoch 510: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8582 - loss: 0.3085 - rmse: 0.2024 - val_accuracy: 0.6000 - val_loss: 1.1979 - val_rmse: 0.3765\n",
      "Epoch 511/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8097 - loss: 0.4777 - rmse: 0.2505\n",
      "Epoch 511: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8121 - loss: 0.4720 - rmse: 0.2491 - val_accuracy: 0.6500 - val_loss: 1.1485 - val_rmse: 0.3568\n",
      "Epoch 512/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8663 - loss: 0.3603 - rmse: 0.2200\n",
      "Epoch 512: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8658 - loss: 0.3616 - rmse: 0.2203 - val_accuracy: 0.6500 - val_loss: 1.1967 - val_rmse: 0.3797\n",
      "Epoch 513/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8277 - loss: 0.4318 - rmse: 0.2432\n",
      "Epoch 513: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8280 - loss: 0.4311 - rmse: 0.2431 - val_accuracy: 0.5500 - val_loss: 1.4383 - val_rmse: 0.4032\n",
      "Epoch 514/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8542 - loss: 0.3690 - rmse: 0.2228\n",
      "Epoch 514: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8553 - loss: 0.3674 - rmse: 0.2222 - val_accuracy: 0.6500 - val_loss: 1.2214 - val_rmse: 0.3653\n",
      "Epoch 515/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8471 - loss: 0.3672 - rmse: 0.2213\n",
      "Epoch 515: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8474 - loss: 0.3692 - rmse: 0.2218 - val_accuracy: 0.6500 - val_loss: 1.3199 - val_rmse: 0.3689\n",
      "Epoch 516/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8374 - loss: 0.4203 - rmse: 0.2377\n",
      "Epoch 516: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8396 - loss: 0.4154 - rmse: 0.2361 - val_accuracy: 0.6000 - val_loss: 1.3166 - val_rmse: 0.3742\n",
      "Epoch 517/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8970 - loss: 0.3252 - rmse: 0.2044\n",
      "Epoch 517: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8962 - loss: 0.3258 - rmse: 0.2047 - val_accuracy: 0.5500 - val_loss: 1.4744 - val_rmse: 0.3948\n",
      "Epoch 518/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8328 - loss: 0.4648 - rmse: 0.2477\n",
      "Epoch 518: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8325 - loss: 0.4673 - rmse: 0.2482 - val_accuracy: 0.6500 - val_loss: 1.1154 - val_rmse: 0.3546\n",
      "Epoch 519/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8556 - loss: 0.3974 - rmse: 0.2262\n",
      "Epoch 519: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8544 - loss: 0.3993 - rmse: 0.2270 - val_accuracy: 0.6000 - val_loss: 1.2042 - val_rmse: 0.3866\n",
      "Epoch 520/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8437 - loss: 0.3902 - rmse: 0.2252\n",
      "Epoch 520: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8436 - loss: 0.3906 - rmse: 0.2254 - val_accuracy: 0.6000 - val_loss: 1.1242 - val_rmse: 0.3787\n",
      "Epoch 521/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9317 - loss: 0.2695 - rmse: 0.1834\n",
      "Epoch 521: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9267 - loss: 0.2760 - rmse: 0.1862 - val_accuracy: 0.7000 - val_loss: 1.1901 - val_rmse: 0.3502\n",
      "Epoch 522/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7720 - loss: 0.5338 - rmse: 0.2650\n",
      "Epoch 522: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7749 - loss: 0.5302 - rmse: 0.2642 - val_accuracy: 0.6500 - val_loss: 1.3057 - val_rmse: 0.3807\n",
      "Epoch 523/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8858 - loss: 0.3403 - rmse: 0.2089\n",
      "Epoch 523: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8830 - loss: 0.3451 - rmse: 0.2107 - val_accuracy: 0.7000 - val_loss: 1.2548 - val_rmse: 0.3477\n",
      "Epoch 524/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7055 - loss: 0.8116 - rmse: 0.3239\n",
      "Epoch 524: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7060 - loss: 0.8135 - rmse: 0.3243 - val_accuracy: 0.6000 - val_loss: 1.2979 - val_rmse: 0.3882\n",
      "Epoch 525/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6846 - loss: 1.0579 - rmse: 0.3434\n",
      "Epoch 525: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6899 - loss: 1.0287 - rmse: 0.3398 - val_accuracy: 0.6000 - val_loss: 1.3465 - val_rmse: 0.3896\n",
      "Epoch 526/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7968 - loss: 0.4877 - rmse: 0.2559\n",
      "Epoch 526: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7999 - loss: 0.4826 - rmse: 0.2545 - val_accuracy: 0.6500 - val_loss: 1.2096 - val_rmse: 0.3605\n",
      "Epoch 527/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8753 - loss: 0.3957 - rmse: 0.2273\n",
      "Epoch 527: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8748 - loss: 0.3945 - rmse: 0.2273 - val_accuracy: 0.6000 - val_loss: 1.4172 - val_rmse: 0.3916\n",
      "Epoch 528/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8775 - loss: 0.3358 - rmse: 0.2121\n",
      "Epoch 528: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8786 - loss: 0.3360 - rmse: 0.2121 - val_accuracy: 0.6500 - val_loss: 1.3390 - val_rmse: 0.3648\n",
      "Epoch 529/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8562 - loss: 0.4142 - rmse: 0.2312\n",
      "Epoch 529: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8515 - loss: 0.4341 - rmse: 0.2352 - val_accuracy: 0.6500 - val_loss: 1.3501 - val_rmse: 0.3731\n",
      "Epoch 530/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6416 - loss: 1.0641 - rmse: 0.3612\n",
      "Epoch 530: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6422 - loss: 1.0602 - rmse: 0.3608 - val_accuracy: 0.7500 - val_loss: 0.8973 - val_rmse: 0.3492\n",
      "Epoch 531/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8326 - loss: 0.5952 - rmse: 0.2807\n",
      "Epoch 531: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8326 - loss: 0.5916 - rmse: 0.2797 - val_accuracy: 0.6500 - val_loss: 0.8705 - val_rmse: 0.3402\n",
      "Epoch 532/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8317 - loss: 0.4925 - rmse: 0.2565\n",
      "Epoch 532: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8323 - loss: 0.4909 - rmse: 0.2561 - val_accuracy: 0.7000 - val_loss: 0.9297 - val_rmse: 0.3467\n",
      "Epoch 533/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9054 - loss: 0.3213 - rmse: 0.1996\n",
      "Epoch 533: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9026 - loss: 0.3261 - rmse: 0.2016 - val_accuracy: 0.6500 - val_loss: 1.0215 - val_rmse: 0.3647\n",
      "Epoch 534/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8790 - loss: 0.3697 - rmse: 0.2218\n",
      "Epoch 534: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8780 - loss: 0.3702 - rmse: 0.2221 - val_accuracy: 0.6000 - val_loss: 1.1446 - val_rmse: 0.3646\n",
      "Epoch 535/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8516 - loss: 0.4167 - rmse: 0.2316\n",
      "Epoch 535: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8530 - loss: 0.4128 - rmse: 0.2306 - val_accuracy: 0.6000 - val_loss: 1.0878 - val_rmse: 0.3658\n",
      "Epoch 536/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8953 - loss: 0.3024 - rmse: 0.1935\n",
      "Epoch 536: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8942 - loss: 0.3044 - rmse: 0.1944 - val_accuracy: 0.6000 - val_loss: 1.3633 - val_rmse: 0.3709\n",
      "Epoch 537/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8622 - loss: 0.4067 - rmse: 0.2240\n",
      "Epoch 537: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8580 - loss: 0.4177 - rmse: 0.2272 - val_accuracy: 0.6000 - val_loss: 1.4671 - val_rmse: 0.3896\n",
      "Epoch 538/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7664 - loss: 0.6554 - rmse: 0.3007\n",
      "Epoch 538: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7696 - loss: 0.6476 - rmse: 0.2987 - val_accuracy: 0.6500 - val_loss: 1.2107 - val_rmse: 0.3652\n",
      "Epoch 539/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9033 - loss: 0.3488 - rmse: 0.2128\n",
      "Epoch 539: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9010 - loss: 0.3513 - rmse: 0.2139 - val_accuracy: 0.6500 - val_loss: 1.2211 - val_rmse: 0.3602\n",
      "Epoch 540/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8719 - loss: 0.4028 - rmse: 0.2310\n",
      "Epoch 540: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8725 - loss: 0.3991 - rmse: 0.2299 - val_accuracy: 0.6500 - val_loss: 1.2762 - val_rmse: 0.3682\n",
      "Epoch 541/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8463 - loss: 0.3723 - rmse: 0.2265\n",
      "Epoch 541: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8456 - loss: 0.3735 - rmse: 0.2269 - val_accuracy: 0.6500 - val_loss: 1.2243 - val_rmse: 0.3541\n",
      "Epoch 542/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7429 - loss: 0.6645 - rmse: 0.2994\n",
      "Epoch 542: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7426 - loss: 0.6659 - rmse: 0.2997 - val_accuracy: 0.5500 - val_loss: 1.2386 - val_rmse: 0.3911\n",
      "Epoch 543/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8131 - loss: 0.4428 - rmse: 0.2456\n",
      "Epoch 543: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8145 - loss: 0.4397 - rmse: 0.2447 - val_accuracy: 0.6000 - val_loss: 1.2124 - val_rmse: 0.3813\n",
      "Epoch 544/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8788 - loss: 0.3448 - rmse: 0.2137\n",
      "Epoch 544: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8793 - loss: 0.3441 - rmse: 0.2135 - val_accuracy: 0.5500 - val_loss: 1.2174 - val_rmse: 0.3793\n",
      "Epoch 545/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8276 - loss: 0.3978 - rmse: 0.2323\n",
      "Epoch 545: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8276 - loss: 0.4014 - rmse: 0.2332 - val_accuracy: 0.6500 - val_loss: 1.3236 - val_rmse: 0.3463\n",
      "Epoch 546/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8436 - loss: 0.3725 - rmse: 0.2253\n",
      "Epoch 546: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8437 - loss: 0.3729 - rmse: 0.2255 - val_accuracy: 0.6500 - val_loss: 1.2857 - val_rmse: 0.3605\n",
      "Epoch 547/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8214 - loss: 0.4223 - rmse: 0.2393\n",
      "Epoch 547: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8224 - loss: 0.4221 - rmse: 0.2392 - val_accuracy: 0.7000 - val_loss: 1.3735 - val_rmse: 0.3654\n",
      "Epoch 548/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8061 - loss: 0.4927 - rmse: 0.2578\n",
      "Epoch 548: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8048 - loss: 0.4925 - rmse: 0.2581 - val_accuracy: 0.6000 - val_loss: 1.8732 - val_rmse: 0.3876\n",
      "Epoch 549/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8576 - loss: 0.3316 - rmse: 0.2124\n",
      "Epoch 549: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8566 - loss: 0.3332 - rmse: 0.2129 - val_accuracy: 0.6500 - val_loss: 1.3743 - val_rmse: 0.3490\n",
      "Epoch 550/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8721 - loss: 0.3056 - rmse: 0.2019\n",
      "Epoch 550: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8711 - loss: 0.3092 - rmse: 0.2032 - val_accuracy: 0.6000 - val_loss: 1.2777 - val_rmse: 0.3831\n",
      "Epoch 551/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8518 - loss: 0.3549 - rmse: 0.2202\n",
      "Epoch 551: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8526 - loss: 0.3540 - rmse: 0.2198 - val_accuracy: 0.6500 - val_loss: 1.3607 - val_rmse: 0.3800\n",
      "Epoch 552/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8679 - loss: 0.3513 - rmse: 0.2161\n",
      "Epoch 552: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8690 - loss: 0.3496 - rmse: 0.2156 - val_accuracy: 0.6000 - val_loss: 1.7744 - val_rmse: 0.4115\n",
      "Epoch 553/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8787 - loss: 0.3012 - rmse: 0.2038\n",
      "Epoch 553: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8783 - loss: 0.3039 - rmse: 0.2047 - val_accuracy: 0.7000 - val_loss: 1.1579 - val_rmse: 0.3460\n",
      "Epoch 554/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8769 - loss: 0.3533 - rmse: 0.2182\n",
      "Epoch 554: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8783 - loss: 0.3497 - rmse: 0.2169 - val_accuracy: 0.6500 - val_loss: 1.7445 - val_rmse: 0.3665\n",
      "Epoch 555/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9308 - loss: 0.2280 - rmse: 0.1649\n",
      "Epoch 555: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9297 - loss: 0.2302 - rmse: 0.1659 - val_accuracy: 0.7000 - val_loss: 1.5509 - val_rmse: 0.3530\n",
      "Epoch 556/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8956 - loss: 0.3170 - rmse: 0.2015\n",
      "Epoch 556: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8960 - loss: 0.3170 - rmse: 0.2016 - val_accuracy: 0.6500 - val_loss: 1.4211 - val_rmse: 0.3612\n",
      "Epoch 557/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9245 - loss: 0.2240 - rmse: 0.1650\n",
      "Epoch 557: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9229 - loss: 0.2260 - rmse: 0.1662 - val_accuracy: 0.6500 - val_loss: 1.7071 - val_rmse: 0.3572\n",
      "Epoch 558/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9247 - loss: 0.2203 - rmse: 0.1622\n",
      "Epoch 558: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9235 - loss: 0.2229 - rmse: 0.1633 - val_accuracy: 0.6000 - val_loss: 1.2769 - val_rmse: 0.3751\n",
      "Epoch 559/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9201 - loss: 0.3106 - rmse: 0.2001\n",
      "Epoch 559: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9191 - loss: 0.3119 - rmse: 0.2008 - val_accuracy: 0.6000 - val_loss: 1.5895 - val_rmse: 0.4033\n",
      "Epoch 560/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8912 - loss: 0.3836 - rmse: 0.2299\n",
      "Epoch 560: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8917 - loss: 0.3827 - rmse: 0.2295 - val_accuracy: 0.6000 - val_loss: 1.2440 - val_rmse: 0.3868\n",
      "Epoch 561/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8926 - loss: 0.2551 - rmse: 0.1786\n",
      "Epoch 561: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8921 - loss: 0.2563 - rmse: 0.1794 - val_accuracy: 0.6500 - val_loss: 1.2292 - val_rmse: 0.3688\n",
      "Epoch 562/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8708 - loss: 0.3229 - rmse: 0.2100\n",
      "Epoch 562: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8703 - loss: 0.3245 - rmse: 0.2104 - val_accuracy: 0.6500 - val_loss: 1.4015 - val_rmse: 0.3741\n",
      "Epoch 563/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7747 - loss: 0.5120 - rmse: 0.2563\n",
      "Epoch 563: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7781 - loss: 0.5091 - rmse: 0.2556 - val_accuracy: 0.7000 - val_loss: 1.4514 - val_rmse: 0.3800\n",
      "Epoch 564/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8444 - loss: 0.3520 - rmse: 0.2158\n",
      "Epoch 564: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8447 - loss: 0.3521 - rmse: 0.2159 - val_accuracy: 0.7500 - val_loss: 1.2127 - val_rmse: 0.3503\n",
      "Epoch 565/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8804 - loss: 0.3284 - rmse: 0.2101\n",
      "Epoch 565: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8798 - loss: 0.3289 - rmse: 0.2102 - val_accuracy: 0.7000 - val_loss: 1.2768 - val_rmse: 0.3524\n",
      "Epoch 566/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8656 - loss: 0.3637 - rmse: 0.2041\n",
      "Epoch 566: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8646 - loss: 0.3673 - rmse: 0.2060 - val_accuracy: 0.6000 - val_loss: 1.2574 - val_rmse: 0.3706\n",
      "Epoch 567/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9070 - loss: 0.2874 - rmse: 0.1939\n",
      "Epoch 567: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9064 - loss: 0.2888 - rmse: 0.1946 - val_accuracy: 0.6500 - val_loss: 1.2877 - val_rmse: 0.3708\n",
      "Epoch 568/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9517 - loss: 0.2181 - rmse: 0.1587\n",
      "Epoch 568: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9498 - loss: 0.2204 - rmse: 0.1601 - val_accuracy: 0.6500 - val_loss: 1.2745 - val_rmse: 0.3730\n",
      "Epoch 569/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9035 - loss: 0.2925 - rmse: 0.1990\n",
      "Epoch 569: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9045 - loss: 0.2907 - rmse: 0.1982 - val_accuracy: 0.6500 - val_loss: 1.2956 - val_rmse: 0.3788\n",
      "Epoch 570/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8901 - loss: 0.2472 - rmse: 0.1792\n",
      "Epoch 570: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8908 - loss: 0.2471 - rmse: 0.1792 - val_accuracy: 0.6500 - val_loss: 1.3279 - val_rmse: 0.3619\n",
      "Epoch 571/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9492 - loss: 0.1577 - rmse: 0.1309\n",
      "Epoch 571: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9467 - loss: 0.1632 - rmse: 0.1339 - val_accuracy: 0.7000 - val_loss: 1.2626 - val_rmse: 0.3533\n",
      "Epoch 572/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8965 - loss: 0.3925 - rmse: 0.2167\n",
      "Epoch 572: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8967 - loss: 0.3910 - rmse: 0.2165 - val_accuracy: 0.6000 - val_loss: 1.4332 - val_rmse: 0.3653\n",
      "Epoch 573/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8523 - loss: 0.4059 - rmse: 0.2383\n",
      "Epoch 573: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8512 - loss: 0.4067 - rmse: 0.2387 - val_accuracy: 0.6000 - val_loss: 1.5904 - val_rmse: 0.3734\n",
      "Epoch 574/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8290 - loss: 0.4853 - rmse: 0.2571\n",
      "Epoch 574: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8315 - loss: 0.4795 - rmse: 0.2552 - val_accuracy: 0.6000 - val_loss: 1.7374 - val_rmse: 0.3768\n",
      "Epoch 575/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8606 - loss: 0.3481 - rmse: 0.2203\n",
      "Epoch 575: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8610 - loss: 0.3471 - rmse: 0.2200 - val_accuracy: 0.6500 - val_loss: 1.6895 - val_rmse: 0.3713\n",
      "Epoch 576/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9173 - loss: 0.2769 - rmse: 0.1907\n",
      "Epoch 576: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9165 - loss: 0.2762 - rmse: 0.1907 - val_accuracy: 0.6000 - val_loss: 1.5635 - val_rmse: 0.3896\n",
      "Epoch 577/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9146 - loss: 0.2355 - rmse: 0.1773\n",
      "Epoch 577: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9145 - loss: 0.2356 - rmse: 0.1774 - val_accuracy: 0.6500 - val_loss: 1.5457 - val_rmse: 0.3564\n",
      "Epoch 578/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9314 - loss: 0.2128 - rmse: 0.1636\n",
      "Epoch 578: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9303 - loss: 0.2146 - rmse: 0.1646 - val_accuracy: 0.7000 - val_loss: 1.4164 - val_rmse: 0.3689\n",
      "Epoch 579/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9023 - loss: 0.2393 - rmse: 0.1736\n",
      "Epoch 579: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9020 - loss: 0.2420 - rmse: 0.1745 - val_accuracy: 0.6500 - val_loss: 1.5623 - val_rmse: 0.3619\n",
      "Epoch 580/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8675 - loss: 0.3977 - rmse: 0.2209\n",
      "Epoch 580: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8683 - loss: 0.3938 - rmse: 0.2202 - val_accuracy: 0.7000 - val_loss: 1.2895 - val_rmse: 0.3752\n",
      "Epoch 581/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9116 - loss: 0.2340 - rmse: 0.1772\n",
      "Epoch 581: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9117 - loss: 0.2339 - rmse: 0.1772 - val_accuracy: 0.7000 - val_loss: 1.3392 - val_rmse: 0.3644\n",
      "Epoch 582/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9293 - loss: 0.1964 - rmse: 0.1558\n",
      "Epoch 582: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9288 - loss: 0.1974 - rmse: 0.1564 - val_accuracy: 0.6500 - val_loss: 1.6270 - val_rmse: 0.3829\n",
      "Epoch 583/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8991 - loss: 0.2230 - rmse: 0.1730\n",
      "Epoch 583: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9008 - loss: 0.2220 - rmse: 0.1726 - val_accuracy: 0.7000 - val_loss: 1.5647 - val_rmse: 0.3701\n",
      "Epoch 584/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8946 - loss: 0.2666 - rmse: 0.1875\n",
      "Epoch 584: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8955 - loss: 0.2654 - rmse: 0.1871 - val_accuracy: 0.7000 - val_loss: 1.5833 - val_rmse: 0.3735\n",
      "Epoch 585/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9490 - loss: 0.1552 - rmse: 0.1358\n",
      "Epoch 585: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9484 - loss: 0.1568 - rmse: 0.1369 - val_accuracy: 0.7000 - val_loss: 1.8299 - val_rmse: 0.3693\n",
      "Epoch 586/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9295 - loss: 0.2297 - rmse: 0.1724\n",
      "Epoch 586: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9295 - loss: 0.2298 - rmse: 0.1724 - val_accuracy: 0.6000 - val_loss: 1.6253 - val_rmse: 0.3930\n",
      "Epoch 587/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9071 - loss: 0.2577 - rmse: 0.1879\n",
      "Epoch 587: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9072 - loss: 0.2573 - rmse: 0.1877 - val_accuracy: 0.6500 - val_loss: 1.6851 - val_rmse: 0.3980\n",
      "Epoch 588/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9409 - loss: 0.2081 - rmse: 0.1650\n",
      "Epoch 588: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9394 - loss: 0.2109 - rmse: 0.1662 - val_accuracy: 0.7000 - val_loss: 1.7136 - val_rmse: 0.3527\n",
      "Epoch 589/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8708 - loss: 0.3789 - rmse: 0.2184\n",
      "Epoch 589: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8673 - loss: 0.3838 - rmse: 0.2204 - val_accuracy: 0.6500 - val_loss: 1.7286 - val_rmse: 0.3819\n",
      "Epoch 590/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8424 - loss: 0.4871 - rmse: 0.2513\n",
      "Epoch 590: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8445 - loss: 0.4814 - rmse: 0.2498 - val_accuracy: 0.6500 - val_loss: 1.9552 - val_rmse: 0.3809\n",
      "Epoch 591/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9374 - loss: 0.2575 - rmse: 0.1830\n",
      "Epoch 591: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9368 - loss: 0.2581 - rmse: 0.1833 - val_accuracy: 0.6000 - val_loss: 1.6703 - val_rmse: 0.3870\n",
      "Epoch 592/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8854 - loss: 0.2838 - rmse: 0.2012\n",
      "Epoch 592: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8867 - loss: 0.2805 - rmse: 0.1998 - val_accuracy: 0.6000 - val_loss: 1.7399 - val_rmse: 0.3813\n",
      "Epoch 593/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8943 - loss: 0.2821 - rmse: 0.1957\n",
      "Epoch 593: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8948 - loss: 0.2817 - rmse: 0.1957 - val_accuracy: 0.6500 - val_loss: 1.5939 - val_rmse: 0.3867\n",
      "Epoch 594/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8771 - loss: 0.3180 - rmse: 0.2039\n",
      "Epoch 594: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8745 - loss: 0.3258 - rmse: 0.2065 - val_accuracy: 0.5000 - val_loss: 1.9636 - val_rmse: 0.4214\n",
      "Epoch 595/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9023 - loss: 0.2934 - rmse: 0.1906\n",
      "Epoch 595: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8991 - loss: 0.2961 - rmse: 0.1922 - val_accuracy: 0.6000 - val_loss: 1.8512 - val_rmse: 0.3873\n",
      "Epoch 596/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8616 - loss: 0.3061 - rmse: 0.1914\n",
      "Epoch 596: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8592 - loss: 0.3149 - rmse: 0.1949 - val_accuracy: 0.5500 - val_loss: 1.2985 - val_rmse: 0.3817\n",
      "Epoch 597/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8732 - loss: 0.3448 - rmse: 0.2137\n",
      "Epoch 597: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8733 - loss: 0.3457 - rmse: 0.2145 - val_accuracy: 0.6500 - val_loss: 1.3845 - val_rmse: 0.3720\n",
      "Epoch 598/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9512 - loss: 0.1864 - rmse: 0.1501\n",
      "Epoch 598: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9469 - loss: 0.1962 - rmse: 0.1542 - val_accuracy: 0.6000 - val_loss: 1.4893 - val_rmse: 0.3764\n",
      "Epoch 599/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8906 - loss: 0.2977 - rmse: 0.1911\n",
      "Epoch 599: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8895 - loss: 0.3006 - rmse: 0.1927 - val_accuracy: 0.6500 - val_loss: 1.5452 - val_rmse: 0.3634\n",
      "Epoch 600/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9265 - loss: 0.2409 - rmse: 0.1778\n",
      "Epoch 600: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9256 - loss: 0.2407 - rmse: 0.1778 - val_accuracy: 0.6500 - val_loss: 1.4155 - val_rmse: 0.3740\n",
      "Epoch 601/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9356 - loss: 0.2039 - rmse: 0.1601\n",
      "Epoch 601: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9349 - loss: 0.2045 - rmse: 0.1604 - val_accuracy: 0.6500 - val_loss: 1.6182 - val_rmse: 0.3706\n",
      "Epoch 602/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8825 - loss: 0.3155 - rmse: 0.2086\n",
      "Epoch 602: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8814 - loss: 0.3172 - rmse: 0.2092 - val_accuracy: 0.5500 - val_loss: 2.6392 - val_rmse: 0.4345\n",
      "Epoch 603/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8938 - loss: 0.5158 - rmse: 0.2293\n",
      "Epoch 603: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8931 - loss: 0.5135 - rmse: 0.2292 - val_accuracy: 0.5500 - val_loss: 1.5803 - val_rmse: 0.3850\n",
      "Epoch 604/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8619 - loss: 0.3723 - rmse: 0.2200\n",
      "Epoch 604: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8622 - loss: 0.3730 - rmse: 0.2198 - val_accuracy: 0.6500 - val_loss: 1.4186 - val_rmse: 0.3912\n",
      "Epoch 605/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8616 - loss: 0.4038 - rmse: 0.2254\n",
      "Epoch 605: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8620 - loss: 0.4007 - rmse: 0.2251 - val_accuracy: 0.5500 - val_loss: 1.6534 - val_rmse: 0.4117\n",
      "Epoch 606/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9277 - loss: 0.2327 - rmse: 0.1733\n",
      "Epoch 606: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9275 - loss: 0.2325 - rmse: 0.1732 - val_accuracy: 0.6000 - val_loss: 1.5253 - val_rmse: 0.3955\n",
      "Epoch 607/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9146 - loss: 0.1981 - rmse: 0.1579\n",
      "Epoch 607: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9151 - loss: 0.1981 - rmse: 0.1579 - val_accuracy: 0.6000 - val_loss: 1.5959 - val_rmse: 0.4034\n",
      "Epoch 608/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9354 - loss: 0.1858 - rmse: 0.1513\n",
      "Epoch 608: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9351 - loss: 0.1863 - rmse: 0.1516 - val_accuracy: 0.6000 - val_loss: 1.5124 - val_rmse: 0.3929\n",
      "Epoch 609/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9253 - loss: 0.2196 - rmse: 0.1705\n",
      "Epoch 609: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9256 - loss: 0.2188 - rmse: 0.1703 - val_accuracy: 0.6000 - val_loss: 1.7405 - val_rmse: 0.4069\n",
      "Epoch 610/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9773 - loss: 0.1540 - rmse: 0.1309\n",
      "Epoch 610: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9766 - loss: 0.1548 - rmse: 0.1315 - val_accuracy: 0.6000 - val_loss: 1.7246 - val_rmse: 0.3980\n",
      "Epoch 611/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9248 - loss: 0.2479 - rmse: 0.1841\n",
      "Epoch 611: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9259 - loss: 0.2458 - rmse: 0.1832 - val_accuracy: 0.6500 - val_loss: 1.6686 - val_rmse: 0.3958\n",
      "Epoch 612/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9464 - loss: 0.2060 - rmse: 0.1601\n",
      "Epoch 612: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9463 - loss: 0.2058 - rmse: 0.1601 - val_accuracy: 0.6500 - val_loss: 1.7346 - val_rmse: 0.3879\n",
      "Epoch 613/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9408 - loss: 0.1839 - rmse: 0.1510\n",
      "Epoch 613: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9398 - loss: 0.1855 - rmse: 0.1521 - val_accuracy: 0.6000 - val_loss: 1.7818 - val_rmse: 0.3993\n",
      "Epoch 614/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9051 - loss: 0.2629 - rmse: 0.1878\n",
      "Epoch 614: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9065 - loss: 0.2607 - rmse: 0.1867 - val_accuracy: 0.6000 - val_loss: 1.5823 - val_rmse: 0.4053\n",
      "Epoch 615/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9601 - loss: 0.1799 - rmse: 0.1446\n",
      "Epoch 615: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9600 - loss: 0.1798 - rmse: 0.1447 - val_accuracy: 0.5500 - val_loss: 1.8707 - val_rmse: 0.4112\n",
      "Epoch 616/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9374 - loss: 0.1895 - rmse: 0.1522\n",
      "Epoch 616: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9385 - loss: 0.1883 - rmse: 0.1519 - val_accuracy: 0.6000 - val_loss: 1.6624 - val_rmse: 0.3980\n",
      "Epoch 617/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9345 - loss: 0.1638 - rmse: 0.1466\n",
      "Epoch 617: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9341 - loss: 0.1640 - rmse: 0.1468 - val_accuracy: 0.5500 - val_loss: 1.8554 - val_rmse: 0.4149\n",
      "Epoch 618/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9647 - loss: 0.1319 - rmse: 0.1191\n",
      "Epoch 618: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9636 - loss: 0.1344 - rmse: 0.1203 - val_accuracy: 0.7000 - val_loss: 1.7743 - val_rmse: 0.3765\n",
      "Epoch 619/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7550 - loss: 1.0137 - rmse: 0.2977\n",
      "Epoch 619: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7558 - loss: 1.0074 - rmse: 0.2973 - val_accuracy: 0.5000 - val_loss: 1.8273 - val_rmse: 0.4029\n",
      "Epoch 620/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8718 - loss: 0.3467 - rmse: 0.2207\n",
      "Epoch 620: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8721 - loss: 0.3459 - rmse: 0.2204 - val_accuracy: 0.5500 - val_loss: 1.9661 - val_rmse: 0.4170\n",
      "Epoch 621/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9449 - loss: 0.2061 - rmse: 0.1635\n",
      "Epoch 621: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9443 - loss: 0.2064 - rmse: 0.1637 - val_accuracy: 0.6500 - val_loss: 1.6633 - val_rmse: 0.3934\n",
      "Epoch 622/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9381 - loss: 0.1941 - rmse: 0.1500\n",
      "Epoch 622: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9376 - loss: 0.1951 - rmse: 0.1508 - val_accuracy: 0.6000 - val_loss: 1.7129 - val_rmse: 0.3967\n",
      "Epoch 623/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9073 - loss: 0.2135 - rmse: 0.1733\n",
      "Epoch 623: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9079 - loss: 0.2132 - rmse: 0.1730 - val_accuracy: 0.6500 - val_loss: 1.5492 - val_rmse: 0.3588\n",
      "Epoch 624/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8825 - loss: 0.2694 - rmse: 0.1864\n",
      "Epoch 624: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8824 - loss: 0.2702 - rmse: 0.1873 - val_accuracy: 0.6000 - val_loss: 1.8260 - val_rmse: 0.3959\n",
      "Epoch 625/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9216 - loss: 0.2492 - rmse: 0.1754\n",
      "Epoch 625: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9206 - loss: 0.2528 - rmse: 0.1765 - val_accuracy: 0.6000 - val_loss: 1.7290 - val_rmse: 0.3922\n",
      "Epoch 626/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8490 - loss: 0.3495 - rmse: 0.2215\n",
      "Epoch 626: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8493 - loss: 0.3494 - rmse: 0.2212 - val_accuracy: 0.6000 - val_loss: 1.5109 - val_rmse: 0.3876\n",
      "Epoch 627/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9717 - loss: 0.1822 - rmse: 0.1491\n",
      "Epoch 627: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9710 - loss: 0.1834 - rmse: 0.1498 - val_accuracy: 0.6500 - val_loss: 1.7662 - val_rmse: 0.3779\n",
      "Epoch 628/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9485 - loss: 0.1666 - rmse: 0.1400\n",
      "Epoch 628: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9479 - loss: 0.1695 - rmse: 0.1415 - val_accuracy: 0.5500 - val_loss: 1.6621 - val_rmse: 0.3881\n",
      "Epoch 629/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8579 - loss: 0.3298 - rmse: 0.2175\n",
      "Epoch 629: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8581 - loss: 0.3310 - rmse: 0.2179 - val_accuracy: 0.6500 - val_loss: 1.7853 - val_rmse: 0.3847\n",
      "Epoch 630/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9132 - loss: 0.2223 - rmse: 0.1709\n",
      "Epoch 630: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9131 - loss: 0.2236 - rmse: 0.1713 - val_accuracy: 0.6000 - val_loss: 1.6132 - val_rmse: 0.3914\n",
      "Epoch 631/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9357 - loss: 0.1534 - rmse: 0.1393\n",
      "Epoch 631: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9358 - loss: 0.1542 - rmse: 0.1397 - val_accuracy: 0.5500 - val_loss: 1.7278 - val_rmse: 0.4050\n",
      "Epoch 632/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9311 - loss: 0.1792 - rmse: 0.1469\n",
      "Epoch 632: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9314 - loss: 0.1785 - rmse: 0.1468 - val_accuracy: 0.5500 - val_loss: 1.7808 - val_rmse: 0.4108\n",
      "Epoch 633/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9693 - loss: 0.1155 - rmse: 0.1118\n",
      "Epoch 633: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9687 - loss: 0.1171 - rmse: 0.1130 - val_accuracy: 0.6000 - val_loss: 1.8137 - val_rmse: 0.4099\n",
      "Epoch 634/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9592 - loss: 0.1375 - rmse: 0.1303\n",
      "Epoch 634: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9597 - loss: 0.1384 - rmse: 0.1307 - val_accuracy: 0.5500 - val_loss: 1.7107 - val_rmse: 0.3923\n",
      "Epoch 635/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9108 - loss: 0.2340 - rmse: 0.1824\n",
      "Epoch 635: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9111 - loss: 0.2328 - rmse: 0.1818 - val_accuracy: 0.6000 - val_loss: 2.0147 - val_rmse: 0.4188\n",
      "Epoch 636/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6888 - loss: 0.6295 - rmse: 0.3032\n",
      "Epoch 636: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6911 - loss: 0.6261 - rmse: 0.3022 - val_accuracy: 0.6000 - val_loss: 1.6581 - val_rmse: 0.3809\n",
      "Epoch 637/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9122 - loss: 0.1929 - rmse: 0.1609\n",
      "Epoch 637: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9129 - loss: 0.1938 - rmse: 0.1612 - val_accuracy: 0.6000 - val_loss: 1.7510 - val_rmse: 0.3933\n",
      "Epoch 638/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9323 - loss: 0.1619 - rmse: 0.1407\n",
      "Epoch 638: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9323 - loss: 0.1624 - rmse: 0.1409 - val_accuracy: 0.6000 - val_loss: 1.8764 - val_rmse: 0.3905\n",
      "Epoch 639/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9674 - loss: 0.1470 - rmse: 0.1279\n",
      "Epoch 639: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9670 - loss: 0.1476 - rmse: 0.1283 - val_accuracy: 0.6000 - val_loss: 1.8481 - val_rmse: 0.3930\n",
      "Epoch 640/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9499 - loss: 0.1757 - rmse: 0.1437\n",
      "Epoch 640: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9512 - loss: 0.1743 - rmse: 0.1431 - val_accuracy: 0.6000 - val_loss: 2.1153 - val_rmse: 0.4097\n",
      "Epoch 641/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9651 - loss: 0.1699 - rmse: 0.1479\n",
      "Epoch 641: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9651 - loss: 0.1683 - rmse: 0.1472 - val_accuracy: 0.6500 - val_loss: 1.7221 - val_rmse: 0.3766\n",
      "Epoch 642/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9715 - loss: 0.1531 - rmse: 0.1353\n",
      "Epoch 642: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9710 - loss: 0.1536 - rmse: 0.1359 - val_accuracy: 0.7000 - val_loss: 1.7397 - val_rmse: 0.3647\n",
      "Epoch 643/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9879 - loss: 0.1120 - rmse: 0.1031\n",
      "Epoch 643: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9867 - loss: 0.1131 - rmse: 0.1043 - val_accuracy: 0.5000 - val_loss: 2.2052 - val_rmse: 0.4336\n",
      "Epoch 644/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9775 - loss: 0.1593 - rmse: 0.1376\n",
      "Epoch 644: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9776 - loss: 0.1585 - rmse: 0.1373 - val_accuracy: 0.7000 - val_loss: 1.8004 - val_rmse: 0.3870\n",
      "Epoch 645/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9957 - loss: 0.1148 - rmse: 0.1111\n",
      "Epoch 645: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9946 - loss: 0.1150 - rmse: 0.1116 - val_accuracy: 0.6500 - val_loss: 1.9995 - val_rmse: 0.3961\n",
      "Epoch 646/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8794 - loss: 0.5420 - rmse: 0.2191\n",
      "Epoch 646: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8754 - loss: 0.5528 - rmse: 0.2222 - val_accuracy: 0.5000 - val_loss: 2.5471 - val_rmse: 0.4383\n",
      "Epoch 647/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7926 - loss: 0.7184 - rmse: 0.2937\n",
      "Epoch 647: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7952 - loss: 0.7073 - rmse: 0.2915 - val_accuracy: 0.6000 - val_loss: 1.6011 - val_rmse: 0.3852\n",
      "Epoch 648/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9261 - loss: 0.2723 - rmse: 0.1954\n",
      "Epoch 648: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9264 - loss: 0.2709 - rmse: 0.1948 - val_accuracy: 0.6500 - val_loss: 1.4966 - val_rmse: 0.3794\n",
      "Epoch 649/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9571 - loss: 0.1738 - rmse: 0.1459\n",
      "Epoch 649: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9569 - loss: 0.1743 - rmse: 0.1463 - val_accuracy: 0.6000 - val_loss: 1.5478 - val_rmse: 0.3839\n",
      "Epoch 650/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9648 - loss: 0.1192 - rmse: 0.1144\n",
      "Epoch 650: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9645 - loss: 0.1201 - rmse: 0.1151 - val_accuracy: 0.5500 - val_loss: 1.7438 - val_rmse: 0.4083\n",
      "Epoch 651/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9429 - loss: 0.1549 - rmse: 0.1388\n",
      "Epoch 651: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9438 - loss: 0.1544 - rmse: 0.1386 - val_accuracy: 0.5500 - val_loss: 1.9598 - val_rmse: 0.4232\n",
      "Epoch 652/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9434 - loss: 0.2601 - rmse: 0.1896\n",
      "Epoch 652: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9420 - loss: 0.2618 - rmse: 0.1901 - val_accuracy: 0.7000 - val_loss: 1.3957 - val_rmse: 0.3418\n",
      "Epoch 653/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8766 - loss: 0.2882 - rmse: 0.1968\n",
      "Epoch 653: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8784 - loss: 0.2859 - rmse: 0.1960 - val_accuracy: 0.5500 - val_loss: 1.7859 - val_rmse: 0.4018\n",
      "Epoch 654/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9667 - loss: 0.1630 - rmse: 0.1384\n",
      "Epoch 654: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9663 - loss: 0.1635 - rmse: 0.1389 - val_accuracy: 0.5500 - val_loss: 1.7108 - val_rmse: 0.4040\n",
      "Epoch 655/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9674 - loss: 0.1177 - rmse: 0.1162\n",
      "Epoch 655: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9666 - loss: 0.1187 - rmse: 0.1169 - val_accuracy: 0.6000 - val_loss: 1.8062 - val_rmse: 0.3906\n",
      "Epoch 656/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9666 - loss: 0.1458 - rmse: 0.1307\n",
      "Epoch 656: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9661 - loss: 0.1458 - rmse: 0.1309 - val_accuracy: 0.5500 - val_loss: 1.9642 - val_rmse: 0.4187\n",
      "Epoch 657/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9665 - loss: 0.1278 - rmse: 0.1197\n",
      "Epoch 657: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9657 - loss: 0.1282 - rmse: 0.1202 - val_accuracy: 0.5500 - val_loss: 1.9940 - val_rmse: 0.4138\n",
      "Epoch 658/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9410 - loss: 0.2250 - rmse: 0.1759\n",
      "Epoch 658: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9435 - loss: 0.2187 - rmse: 0.1727 - val_accuracy: 0.5500 - val_loss: 2.1436 - val_rmse: 0.4305\n",
      "Epoch 659/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9803 - loss: 0.1048 - rmse: 0.1100\n",
      "Epoch 659: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9807 - loss: 0.1049 - rmse: 0.1100 - val_accuracy: 0.6000 - val_loss: 2.0847 - val_rmse: 0.4215\n",
      "Epoch 660/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9514 - loss: 0.1136 - rmse: 0.1127\n",
      "Epoch 660: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9512 - loss: 0.1143 - rmse: 0.1133 - val_accuracy: 0.6000 - val_loss: 2.4716 - val_rmse: 0.4245\n",
      "Epoch 661/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9183 - loss: 0.2017 - rmse: 0.1668\n",
      "Epoch 661: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9186 - loss: 0.2015 - rmse: 0.1667 - val_accuracy: 0.6000 - val_loss: 2.1894 - val_rmse: 0.4219\n",
      "Epoch 662/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9358 - loss: 0.2186 - rmse: 0.1594\n",
      "Epoch 662: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9351 - loss: 0.2201 - rmse: 0.1602 - val_accuracy: 0.5500 - val_loss: 1.8608 - val_rmse: 0.4057\n",
      "Epoch 663/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8605 - loss: 0.4068 - rmse: 0.2187\n",
      "Epoch 663: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8566 - loss: 0.4191 - rmse: 0.2226 - val_accuracy: 0.7500 - val_loss: 1.6047 - val_rmse: 0.3523\n",
      "Epoch 664/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8589 - loss: 0.4071 - rmse: 0.2377\n",
      "Epoch 664: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8579 - loss: 0.4089 - rmse: 0.2377 - val_accuracy: 0.6500 - val_loss: 1.8309 - val_rmse: 0.4000\n",
      "Epoch 665/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7859 - loss: 0.5954 - rmse: 0.2886\n",
      "Epoch 665: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7866 - loss: 0.5927 - rmse: 0.2881 - val_accuracy: 0.6000 - val_loss: 1.9894 - val_rmse: 0.3948\n",
      "Epoch 666/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8860 - loss: 0.3683 - rmse: 0.2236\n",
      "Epoch 666: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8863 - loss: 0.3676 - rmse: 0.2233 - val_accuracy: 0.6000 - val_loss: 1.5372 - val_rmse: 0.3892\n",
      "Epoch 667/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9138 - loss: 0.2182 - rmse: 0.1708\n",
      "Epoch 667: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9135 - loss: 0.2183 - rmse: 0.1710 - val_accuracy: 0.6000 - val_loss: 1.9470 - val_rmse: 0.4082\n",
      "Epoch 668/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9263 - loss: 0.2182 - rmse: 0.1699\n",
      "Epoch 668: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9256 - loss: 0.2184 - rmse: 0.1702 - val_accuracy: 0.6500 - val_loss: 1.8107 - val_rmse: 0.4021\n",
      "Epoch 669/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9744 - loss: 0.1607 - rmse: 0.1356\n",
      "Epoch 669: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9739 - loss: 0.1606 - rmse: 0.1357 - val_accuracy: 0.6500 - val_loss: 1.7463 - val_rmse: 0.3887\n",
      "Epoch 670/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9788 - loss: 0.1202 - rmse: 0.1191\n",
      "Epoch 670: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9781 - loss: 0.1212 - rmse: 0.1199 - val_accuracy: 0.6000 - val_loss: 1.7572 - val_rmse: 0.4161\n",
      "Epoch 671/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8516 - loss: 0.2974 - rmse: 0.2037\n",
      "Epoch 671: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8514 - loss: 0.3004 - rmse: 0.2049 - val_accuracy: 0.6500 - val_loss: 1.6094 - val_rmse: 0.3836\n",
      "Epoch 672/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9396 - loss: 0.2314 - rmse: 0.1686\n",
      "Epoch 672: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9354 - loss: 0.2408 - rmse: 0.1725 - val_accuracy: 0.6500 - val_loss: 1.3532 - val_rmse: 0.3558\n",
      "Epoch 673/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8408 - loss: 0.4799 - rmse: 0.2412\n",
      "Epoch 673: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8391 - loss: 0.4854 - rmse: 0.2428 - val_accuracy: 0.5000 - val_loss: 2.0698 - val_rmse: 0.4451\n",
      "Epoch 674/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6566 - loss: 4.5412 - rmse: 0.3820\n",
      "Epoch 674: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6459 - loss: 4.7766 - rmse: 0.3879 - val_accuracy: 0.2500 - val_loss: 14.8210 - val_rmse: 0.5823\n",
      "Epoch 675/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3159 - loss: 10.8436 - rmse: 0.5674\n",
      "Epoch 675: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3165 - loss: 10.7444 - rmse: 0.5672 - val_accuracy: 0.3500 - val_loss: 4.1096 - val_rmse: 0.5471\n",
      "Epoch 676/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3936 - loss: 3.9547 - rmse: 0.5194\n",
      "Epoch 676: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3949 - loss: 3.9874 - rmse: 0.5188 - val_accuracy: 0.5500 - val_loss: 3.4448 - val_rmse: 0.4424\n",
      "Epoch 677/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3598 - loss: 4.2966 - rmse: 0.5068\n",
      "Epoch 677: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3591 - loss: 4.2959 - rmse: 0.5071 - val_accuracy: 0.5000 - val_loss: 2.2621 - val_rmse: 0.4498\n",
      "Epoch 678/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2957 - loss: 6.1973 - rmse: 0.5419\n",
      "Epoch 678: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.2963 - loss: 6.1308 - rmse: 0.5414 - val_accuracy: 0.5000 - val_loss: 3.2983 - val_rmse: 0.4537\n",
      "Epoch 679/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3450 - loss: 3.3477 - rmse: 0.4922\n",
      "Epoch 679: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.3479 - loss: 3.3095 - rmse: 0.4911 - val_accuracy: 0.2500 - val_loss: 2.4915 - val_rmse: 0.4818\n",
      "Epoch 680/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2600 - loss: 4.3476 - rmse: 0.5306\n",
      "Epoch 680: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.2655 - loss: 4.3039 - rmse: 0.5288 - val_accuracy: 0.4500 - val_loss: 1.7342 - val_rmse: 0.4275\n",
      "Epoch 681/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3445 - loss: 2.6998 - rmse: 0.4780\n",
      "Epoch 681: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3451 - loss: 2.7035 - rmse: 0.4782 - val_accuracy: 0.5000 - val_loss: 2.3750 - val_rmse: 0.4275\n",
      "Epoch 682/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3346 - loss: 2.9034 - rmse: 0.4916\n",
      "Epoch 682: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3380 - loss: 2.8700 - rmse: 0.4901 - val_accuracy: 0.3000 - val_loss: 2.3484 - val_rmse: 0.4940\n",
      "Epoch 683/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4806 - loss: 2.4433 - rmse: 0.4512\n",
      "Epoch 683: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4738 - loss: 2.4434 - rmse: 0.4525 - val_accuracy: 0.5500 - val_loss: 2.0588 - val_rmse: 0.4097\n",
      "Epoch 684/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4362 - loss: 2.2913 - rmse: 0.4694\n",
      "Epoch 684: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4342 - loss: 2.3133 - rmse: 0.4698 - val_accuracy: 0.3000 - val_loss: 4.9754 - val_rmse: 0.4819\n",
      "Epoch 685/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1784 - loss: 3.4786 - rmse: 0.5382\n",
      "Epoch 685: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1790 - loss: 3.4787 - rmse: 0.5380 - val_accuracy: 0.3000 - val_loss: 3.4918 - val_rmse: 0.4865\n",
      "Epoch 686/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2851 - loss: 3.6934 - rmse: 0.5088\n",
      "Epoch 686: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.2864 - loss: 3.6727 - rmse: 0.5081 - val_accuracy: 0.5000 - val_loss: 1.7126 - val_rmse: 0.4591\n",
      "Epoch 687/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4661 - loss: 1.7224 - rmse: 0.4345\n",
      "Epoch 687: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4655 - loss: 1.7258 - rmse: 0.4350 - val_accuracy: 0.5000 - val_loss: 1.4422 - val_rmse: 0.4240\n",
      "Epoch 688/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4755 - loss: 1.8517 - rmse: 0.4385\n",
      "Epoch 688: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4750 - loss: 1.8444 - rmse: 0.4384 - val_accuracy: 0.3000 - val_loss: 2.9717 - val_rmse: 0.5204\n",
      "Epoch 689/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2259 - loss: 3.1196 - rmse: 0.5206\n",
      "Epoch 689: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.2270 - loss: 3.1117 - rmse: 0.5204 - val_accuracy: 0.4500 - val_loss: 1.5030 - val_rmse: 0.4424\n",
      "Epoch 690/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5129 - loss: 1.6721 - rmse: 0.4180\n",
      "Epoch 690: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5092 - loss: 1.6844 - rmse: 0.4192 - val_accuracy: 0.4000 - val_loss: 2.0827 - val_rmse: 0.4421\n",
      "Epoch 691/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2197 - loss: 2.4255 - rmse: 0.5157\n",
      "Epoch 691: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.2220 - loss: 2.4162 - rmse: 0.5148 - val_accuracy: 0.3500 - val_loss: 2.2483 - val_rmse: 0.4752\n",
      "Epoch 692/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3597 - loss: 1.8216 - rmse: 0.4627\n",
      "Epoch 692: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3568 - loss: 1.8351 - rmse: 0.4640 - val_accuracy: 0.3000 - val_loss: 1.9376 - val_rmse: 0.4698\n",
      "Epoch 693/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4398 - loss: 1.7251 - rmse: 0.4395\n",
      "Epoch 693: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4349 - loss: 1.7303 - rmse: 0.4411 - val_accuracy: 0.5000 - val_loss: 1.4806 - val_rmse: 0.4129\n",
      "Epoch 694/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.3894 - loss: 1.5326 - rmse: 0.4424\n",
      "Epoch 694: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.3946 - loss: 1.5295 - rmse: 0.4417 - val_accuracy: 0.4500 - val_loss: 1.4455 - val_rmse: 0.4030\n",
      "Epoch 695/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4895 - loss: 1.4097 - rmse: 0.4245\n",
      "Epoch 695: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4903 - loss: 1.4093 - rmse: 0.4245 - val_accuracy: 0.4500 - val_loss: 1.6426 - val_rmse: 0.4355\n",
      "Epoch 696/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4820 - loss: 1.4731 - rmse: 0.4234\n",
      "Epoch 696: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4827 - loss: 1.4705 - rmse: 0.4231 - val_accuracy: 0.5500 - val_loss: 1.3686 - val_rmse: 0.4036\n",
      "Epoch 697/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5403 - loss: 1.3976 - rmse: 0.4135\n",
      "Epoch 697: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5397 - loss: 1.3971 - rmse: 0.4135 - val_accuracy: 0.3500 - val_loss: 1.2563 - val_rmse: 0.4191\n",
      "Epoch 698/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3952 - loss: 1.7452 - rmse: 0.4557\n",
      "Epoch 698: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3964 - loss: 1.7419 - rmse: 0.4553 - val_accuracy: 0.5000 - val_loss: 1.1408 - val_rmse: 0.3902\n",
      "Epoch 699/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4241 - loss: 1.4009 - rmse: 0.4264\n",
      "Epoch 699: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.4244 - loss: 1.4023 - rmse: 0.4265 - val_accuracy: 0.2500 - val_loss: 1.4186 - val_rmse: 0.4333\n",
      "Epoch 700/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4145 - loss: 1.3406 - rmse: 0.4294\n",
      "Epoch 700: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.4128 - loss: 1.3535 - rmse: 0.4305 - val_accuracy: 0.3500 - val_loss: 2.2528 - val_rmse: 0.4733\n",
      "Epoch 701/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3559 - loss: 1.7246 - rmse: 0.4588\n",
      "Epoch 701: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3594 - loss: 1.7118 - rmse: 0.4576 - val_accuracy: 0.5500 - val_loss: 1.5098 - val_rmse: 0.4199\n",
      "Epoch 702/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4653 - loss: 1.4173 - rmse: 0.4179\n",
      "Epoch 702: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4623 - loss: 1.4314 - rmse: 0.4190 - val_accuracy: 0.4000 - val_loss: 1.7690 - val_rmse: 0.4583\n",
      "Epoch 703/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3382 - loss: 1.4944 - rmse: 0.4515\n",
      "Epoch 703: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3386 - loss: 1.4972 - rmse: 0.4512 - val_accuracy: 0.2500 - val_loss: 2.3033 - val_rmse: 0.4787\n",
      "Epoch 704/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2672 - loss: 2.3491 - rmse: 0.4903\n",
      "Epoch 704: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.2742 - loss: 2.3016 - rmse: 0.4871 - val_accuracy: 0.4000 - val_loss: 1.3347 - val_rmse: 0.4212\n",
      "Epoch 705/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3403 - loss: 1.4979 - rmse: 0.4406\n",
      "Epoch 705: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3409 - loss: 1.4984 - rmse: 0.4406 - val_accuracy: 0.4000 - val_loss: 1.4831 - val_rmse: 0.4383\n",
      "Epoch 706/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2647 - loss: 1.7996 - rmse: 0.4680\n",
      "Epoch 706: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.2673 - loss: 1.7922 - rmse: 0.4672 - val_accuracy: 0.4500 - val_loss: 1.0659 - val_rmse: 0.3804\n",
      "Epoch 707/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4146 - loss: 1.2646 - rmse: 0.4127\n",
      "Epoch 707: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4173 - loss: 1.2660 - rmse: 0.4125 - val_accuracy: 0.6000 - val_loss: 1.0490 - val_rmse: 0.3756\n",
      "Epoch 708/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4950 - loss: 1.3184 - rmse: 0.4047\n",
      "Epoch 708: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4872 - loss: 1.3315 - rmse: 0.4064 - val_accuracy: 0.5000 - val_loss: 1.1194 - val_rmse: 0.3911\n",
      "Epoch 709/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4539 - loss: 1.2557 - rmse: 0.4039\n",
      "Epoch 709: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4526 - loss: 1.2583 - rmse: 0.4045 - val_accuracy: 0.6500 - val_loss: 1.0050 - val_rmse: 0.3819\n",
      "Epoch 710/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4413 - loss: 1.4468 - rmse: 0.4302\n",
      "Epoch 710: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4368 - loss: 1.4446 - rmse: 0.4305 - val_accuracy: 0.3000 - val_loss: 1.1389 - val_rmse: 0.4192\n",
      "Epoch 711/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3413 - loss: 1.6047 - rmse: 0.4532\n",
      "Epoch 711: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3420 - loss: 1.6029 - rmse: 0.4529 - val_accuracy: 0.4000 - val_loss: 1.2782 - val_rmse: 0.4155\n",
      "Epoch 712/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4534 - loss: 1.1803 - rmse: 0.4025\n",
      "Epoch 712: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4544 - loss: 1.1828 - rmse: 0.4027 - val_accuracy: 0.4500 - val_loss: 1.1423 - val_rmse: 0.3958\n",
      "Epoch 713/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5211 - loss: 1.1207 - rmse: 0.3936\n",
      "Epoch 713: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5234 - loss: 1.1201 - rmse: 0.3931 - val_accuracy: 0.5000 - val_loss: 1.0730 - val_rmse: 0.3832\n",
      "Epoch 714/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5855 - loss: 1.1469 - rmse: 0.3775\n",
      "Epoch 714: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5861 - loss: 1.1462 - rmse: 0.3777 - val_accuracy: 0.5500 - val_loss: 1.0936 - val_rmse: 0.3903\n",
      "Epoch 715/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6433 - loss: 1.0729 - rmse: 0.3771\n",
      "Epoch 715: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6423 - loss: 1.0702 - rmse: 0.3768 - val_accuracy: 0.5000 - val_loss: 1.0434 - val_rmse: 0.3813\n",
      "Epoch 716/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6334 - loss: 1.0275 - rmse: 0.3673\n",
      "Epoch 716: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6323 - loss: 1.0282 - rmse: 0.3675 - val_accuracy: 0.5500 - val_loss: 1.0697 - val_rmse: 0.3803\n",
      "Epoch 717/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6068 - loss: 1.0424 - rmse: 0.3780\n",
      "Epoch 717: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6037 - loss: 1.0464 - rmse: 0.3784 - val_accuracy: 0.5500 - val_loss: 1.1775 - val_rmse: 0.3877\n",
      "Epoch 718/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5028 - loss: 1.2247 - rmse: 0.3950\n",
      "Epoch 718: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5067 - loss: 1.2192 - rmse: 0.3943 - val_accuracy: 0.6000 - val_loss: 1.1634 - val_rmse: 0.3819\n",
      "Epoch 719/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5514 - loss: 1.3178 - rmse: 0.3997\n",
      "Epoch 719: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5519 - loss: 1.3149 - rmse: 0.3995 - val_accuracy: 0.4500 - val_loss: 1.2851 - val_rmse: 0.4133\n",
      "Epoch 720/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5912 - loss: 1.1642 - rmse: 0.3795\n",
      "Epoch 720: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5908 - loss: 1.1625 - rmse: 0.3795 - val_accuracy: 0.5000 - val_loss: 1.0213 - val_rmse: 0.3745\n",
      "Epoch 721/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5947 - loss: 1.0211 - rmse: 0.3724\n",
      "Epoch 721: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5955 - loss: 1.0200 - rmse: 0.3721 - val_accuracy: 0.5500 - val_loss: 1.0418 - val_rmse: 0.3744\n",
      "Epoch 722/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6543 - loss: 0.9419 - rmse: 0.3521\n",
      "Epoch 722: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6481 - loss: 0.9550 - rmse: 0.3541 - val_accuracy: 0.5000 - val_loss: 1.1414 - val_rmse: 0.3935\n",
      "Epoch 723/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6248 - loss: 0.9670 - rmse: 0.3616\n",
      "Epoch 723: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6252 - loss: 0.9664 - rmse: 0.3614 - val_accuracy: 0.5000 - val_loss: 1.0163 - val_rmse: 0.3734\n",
      "Epoch 724/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5848 - loss: 0.9530 - rmse: 0.3584\n",
      "Epoch 724: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5881 - loss: 0.9501 - rmse: 0.3579 - val_accuracy: 0.5000 - val_loss: 1.1259 - val_rmse: 0.3969\n",
      "Epoch 725/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6903 - loss: 0.8946 - rmse: 0.3400\n",
      "Epoch 725: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6870 - loss: 0.9018 - rmse: 0.3414 - val_accuracy: 0.4500 - val_loss: 1.2193 - val_rmse: 0.4184\n",
      "Epoch 726/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5604 - loss: 1.1517 - rmse: 0.3876\n",
      "Epoch 726: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5510 - loss: 1.1743 - rmse: 0.3905 - val_accuracy: 0.2500 - val_loss: 2.3539 - val_rmse: 0.4787\n",
      "Epoch 727/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4107 - loss: 1.6116 - rmse: 0.4351\n",
      "Epoch 727: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4122 - loss: 1.6039 - rmse: 0.4345 - val_accuracy: 0.5000 - val_loss: 1.2757 - val_rmse: 0.4147\n",
      "Epoch 728/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5291 - loss: 1.2256 - rmse: 0.3955\n",
      "Epoch 728: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5270 - loss: 1.2294 - rmse: 0.3959 - val_accuracy: 0.4000 - val_loss: 1.2564 - val_rmse: 0.4195\n",
      "Epoch 729/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5550 - loss: 1.0816 - rmse: 0.3754\n",
      "Epoch 729: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5549 - loss: 1.0810 - rmse: 0.3754 - val_accuracy: 0.5000 - val_loss: 1.1847 - val_rmse: 0.3977\n",
      "Epoch 730/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6344 - loss: 0.9196 - rmse: 0.3496\n",
      "Epoch 730: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6322 - loss: 0.9254 - rmse: 0.3509 - val_accuracy: 0.5500 - val_loss: 1.0528 - val_rmse: 0.3746\n",
      "Epoch 731/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5849 - loss: 1.0752 - rmse: 0.3733\n",
      "Epoch 731: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5845 - loss: 1.0770 - rmse: 0.3736 - val_accuracy: 0.5000 - val_loss: 1.0508 - val_rmse: 0.3819\n",
      "Epoch 732/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6191 - loss: 1.1010 - rmse: 0.3632\n",
      "Epoch 732: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6157 - loss: 1.1083 - rmse: 0.3643 - val_accuracy: 0.4000 - val_loss: 1.1334 - val_rmse: 0.3974\n",
      "Epoch 733/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4565 - loss: 1.2335 - rmse: 0.4061\n",
      "Epoch 733: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4569 - loss: 1.2356 - rmse: 0.4062 - val_accuracy: 0.5000 - val_loss: 1.0816 - val_rmse: 0.3977\n",
      "Epoch 734/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4037 - loss: 1.5084 - rmse: 0.4440\n",
      "Epoch 734: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4077 - loss: 1.5019 - rmse: 0.4427 - val_accuracy: 0.4000 - val_loss: 1.2108 - val_rmse: 0.4052\n",
      "Epoch 735/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4773 - loss: 1.3963 - rmse: 0.4214\n",
      "Epoch 735: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.4814 - loss: 1.3855 - rmse: 0.4201 - val_accuracy: 0.4500 - val_loss: 1.2101 - val_rmse: 0.4086\n",
      "Epoch 736/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5379 - loss: 1.2362 - rmse: 0.4079\n",
      "Epoch 736: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5334 - loss: 1.2393 - rmse: 0.4084 - val_accuracy: 0.4000 - val_loss: 1.1011 - val_rmse: 0.3998\n",
      "Epoch 737/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4663 - loss: 1.4355 - rmse: 0.4220\n",
      "Epoch 737: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4646 - loss: 1.4376 - rmse: 0.4225 - val_accuracy: 0.4500 - val_loss: 1.0589 - val_rmse: 0.3898\n",
      "Epoch 738/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4344 - loss: 1.2034 - rmse: 0.4057\n",
      "Epoch 738: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4391 - loss: 1.2010 - rmse: 0.4051 - val_accuracy: 0.6000 - val_loss: 0.9352 - val_rmse: 0.3605\n",
      "Epoch 739/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6605 - loss: 1.1095 - rmse: 0.3728\n",
      "Epoch 739: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6599 - loss: 1.1084 - rmse: 0.3728 - val_accuracy: 0.6000 - val_loss: 0.8979 - val_rmse: 0.3597\n",
      "Epoch 740/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6754 - loss: 0.9879 - rmse: 0.3636\n",
      "Epoch 740: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6723 - loss: 0.9917 - rmse: 0.3643 - val_accuracy: 0.6000 - val_loss: 0.9098 - val_rmse: 0.3592\n",
      "Epoch 741/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5421 - loss: 1.1736 - rmse: 0.3990\n",
      "Epoch 741: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5428 - loss: 1.1721 - rmse: 0.3987 - val_accuracy: 0.4500 - val_loss: 1.1885 - val_rmse: 0.4130\n",
      "Epoch 742/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5706 - loss: 1.0721 - rmse: 0.3768\n",
      "Epoch 742: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5741 - loss: 1.0703 - rmse: 0.3765 - val_accuracy: 0.4000 - val_loss: 1.1212 - val_rmse: 0.4045\n",
      "Epoch 743/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5144 - loss: 1.2227 - rmse: 0.4000\n",
      "Epoch 743: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5136 - loss: 1.2218 - rmse: 0.4001 - val_accuracy: 0.5500 - val_loss: 0.8885 - val_rmse: 0.3512\n",
      "Epoch 744/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6102 - loss: 1.0511 - rmse: 0.3740\n",
      "Epoch 744: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.6108 - loss: 1.0496 - rmse: 0.3737 - val_accuracy: 0.5500 - val_loss: 1.0623 - val_rmse: 0.3894\n",
      "Epoch 745/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6983 - loss: 0.9745 - rmse: 0.3589\n",
      "Epoch 745: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6958 - loss: 0.9752 - rmse: 0.3590 - val_accuracy: 0.6000 - val_loss: 0.8753 - val_rmse: 0.3468\n",
      "Epoch 746/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6487 - loss: 0.9262 - rmse: 0.3511\n",
      "Epoch 746: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6463 - loss: 0.9290 - rmse: 0.3516 - val_accuracy: 0.6500 - val_loss: 0.8557 - val_rmse: 0.3476\n",
      "Epoch 747/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6422 - loss: 1.0197 - rmse: 0.3540\n",
      "Epoch 747: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6429 - loss: 1.0174 - rmse: 0.3539 - val_accuracy: 0.6500 - val_loss: 0.8354 - val_rmse: 0.3427\n",
      "Epoch 748/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6522 - loss: 0.9341 - rmse: 0.3485\n",
      "Epoch 748: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6522 - loss: 0.9326 - rmse: 0.3482 - val_accuracy: 0.6000 - val_loss: 0.9457 - val_rmse: 0.3662\n",
      "Epoch 749/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5719 - loss: 1.1199 - rmse: 0.3828\n",
      "Epoch 749: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5736 - loss: 1.1195 - rmse: 0.3828 - val_accuracy: 0.6500 - val_loss: 0.9189 - val_rmse: 0.3595\n",
      "Epoch 750/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7530 - loss: 0.8074 - rmse: 0.3261\n",
      "Epoch 750: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7513 - loss: 0.8101 - rmse: 0.3266 - val_accuracy: 0.6500 - val_loss: 0.8947 - val_rmse: 0.3552\n",
      "Epoch 751/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7085 - loss: 0.7753 - rmse: 0.3249\n",
      "Epoch 751: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7070 - loss: 0.7806 - rmse: 0.3257 - val_accuracy: 0.6500 - val_loss: 0.9011 - val_rmse: 0.3565\n",
      "Epoch 752/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6629 - loss: 0.7812 - rmse: 0.3223\n",
      "Epoch 752: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6628 - loss: 0.7853 - rmse: 0.3230 - val_accuracy: 0.6500 - val_loss: 0.8458 - val_rmse: 0.3440\n",
      "Epoch 753/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5842 - loss: 1.0761 - rmse: 0.3705\n",
      "Epoch 753: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5910 - loss: 1.0605 - rmse: 0.3680 - val_accuracy: 0.5500 - val_loss: 0.9732 - val_rmse: 0.3734\n",
      "Epoch 754/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7141 - loss: 0.7869 - rmse: 0.3188\n",
      "Epoch 754: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7097 - loss: 0.7964 - rmse: 0.3210 - val_accuracy: 0.4500 - val_loss: 1.2902 - val_rmse: 0.4202\n",
      "Epoch 755/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6489 - loss: 0.8859 - rmse: 0.3424\n",
      "Epoch 755: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6510 - loss: 0.8844 - rmse: 0.3421 - val_accuracy: 0.6000 - val_loss: 0.9676 - val_rmse: 0.3739\n",
      "Epoch 756/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6143 - loss: 0.9891 - rmse: 0.3557\n",
      "Epoch 756: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.6133 - loss: 0.9915 - rmse: 0.3563 - val_accuracy: 0.4000 - val_loss: 1.5259 - val_rmse: 0.4417\n",
      "Epoch 757/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5430 - loss: 1.0880 - rmse: 0.3799\n",
      "Epoch 757: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5450 - loss: 1.0862 - rmse: 0.3796 - val_accuracy: 0.6000 - val_loss: 0.8992 - val_rmse: 0.3596\n",
      "Epoch 758/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6174 - loss: 0.9291 - rmse: 0.3490\n",
      "Epoch 758: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6164 - loss: 0.9335 - rmse: 0.3499 - val_accuracy: 0.4500 - val_loss: 1.2682 - val_rmse: 0.4210\n",
      "Epoch 759/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6151 - loss: 1.0581 - rmse: 0.3719\n",
      "Epoch 759: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6106 - loss: 1.0675 - rmse: 0.3738 - val_accuracy: 0.5000 - val_loss: 1.0290 - val_rmse: 0.3826\n",
      "Epoch 760/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5540 - loss: 1.0236 - rmse: 0.3750\n",
      "Epoch 760: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5589 - loss: 1.0227 - rmse: 0.3745 - val_accuracy: 0.5000 - val_loss: 0.9952 - val_rmse: 0.3741\n",
      "Epoch 761/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6688 - loss: 0.9061 - rmse: 0.3469\n",
      "Epoch 761: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6664 - loss: 0.9109 - rmse: 0.3479 - val_accuracy: 0.6000 - val_loss: 0.9528 - val_rmse: 0.3656\n",
      "Epoch 762/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6349 - loss: 0.8707 - rmse: 0.3401\n",
      "Epoch 762: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6341 - loss: 0.8733 - rmse: 0.3406 - val_accuracy: 0.5500 - val_loss: 1.1297 - val_rmse: 0.3939\n",
      "Epoch 763/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6335 - loss: 0.9002 - rmse: 0.3439\n",
      "Epoch 763: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6378 - loss: 0.8968 - rmse: 0.3431 - val_accuracy: 0.6500 - val_loss: 0.9000 - val_rmse: 0.3593\n",
      "Epoch 764/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7036 - loss: 0.9150 - rmse: 0.3392\n",
      "Epoch 764: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7011 - loss: 0.9130 - rmse: 0.3393 - val_accuracy: 0.6500 - val_loss: 0.9016 - val_rmse: 0.3581\n",
      "Epoch 765/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6082 - loss: 0.8760 - rmse: 0.3453\n",
      "Epoch 765: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6094 - loss: 0.8747 - rmse: 0.3450 - val_accuracy: 0.6500 - val_loss: 0.8841 - val_rmse: 0.3537\n",
      "Epoch 766/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6217 - loss: 0.9156 - rmse: 0.3520\n",
      "Epoch 766: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6237 - loss: 0.9136 - rmse: 0.3513 - val_accuracy: 0.4500 - val_loss: 1.2850 - val_rmse: 0.4270\n",
      "Epoch 767/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5193 - loss: 1.2130 - rmse: 0.3935\n",
      "Epoch 767: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5179 - loss: 1.2193 - rmse: 0.3942 - val_accuracy: 0.5500 - val_loss: 0.9581 - val_rmse: 0.3645\n",
      "Epoch 768/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5212 - loss: 1.1684 - rmse: 0.3990\n",
      "Epoch 768: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5217 - loss: 1.1676 - rmse: 0.3989 - val_accuracy: 0.5500 - val_loss: 1.0949 - val_rmse: 0.3826\n",
      "Epoch 769/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5616 - loss: 1.0615 - rmse: 0.3785\n",
      "Epoch 769: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5602 - loss: 1.0630 - rmse: 0.3784 - val_accuracy: 0.4500 - val_loss: 1.0434 - val_rmse: 0.3857\n",
      "Epoch 770/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5320 - loss: 1.1814 - rmse: 0.4000\n",
      "Epoch 770: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5296 - loss: 1.1842 - rmse: 0.4004 - val_accuracy: 0.4500 - val_loss: 1.0471 - val_rmse: 0.3951\n",
      "Epoch 771/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6593 - loss: 0.9965 - rmse: 0.3557\n",
      "Epoch 771: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.6574 - loss: 0.9978 - rmse: 0.3561 - val_accuracy: 0.5500 - val_loss: 1.0214 - val_rmse: 0.3847\n",
      "Epoch 772/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4717 - loss: 1.1429 - rmse: 0.3971\n",
      "Epoch 772: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4666 - loss: 1.1555 - rmse: 0.3990 - val_accuracy: 0.4000 - val_loss: 1.3615 - val_rmse: 0.4371\n",
      "Epoch 773/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3691 - loss: 1.5529 - rmse: 0.4373\n",
      "Epoch 773: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3708 - loss: 1.5435 - rmse: 0.4368 - val_accuracy: 0.2500 - val_loss: 1.5200 - val_rmse: 0.4433\n",
      "Epoch 774/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4592 - loss: 1.2743 - rmse: 0.4132\n",
      "Epoch 774: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4583 - loss: 1.2746 - rmse: 0.4132 - val_accuracy: 0.5500 - val_loss: 1.2187 - val_rmse: 0.4015\n",
      "Epoch 775/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3984 - loss: 1.5495 - rmse: 0.4532\n",
      "Epoch 775: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3976 - loss: 1.5435 - rmse: 0.4522 - val_accuracy: 0.4000 - val_loss: 1.4119 - val_rmse: 0.4272\n",
      "Epoch 776/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4164 - loss: 1.4291 - rmse: 0.4234\n",
      "Epoch 776: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4191 - loss: 1.4258 - rmse: 0.4230 - val_accuracy: 0.6000 - val_loss: 1.1911 - val_rmse: 0.3713\n",
      "Epoch 777/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6019 - loss: 1.1615 - rmse: 0.3805\n",
      "Epoch 777: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5980 - loss: 1.1673 - rmse: 0.3819 - val_accuracy: 0.6000 - val_loss: 1.0975 - val_rmse: 0.3671\n",
      "Epoch 778/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5157 - loss: 1.1802 - rmse: 0.3945\n",
      "Epoch 778: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5182 - loss: 1.1795 - rmse: 0.3941 - val_accuracy: 0.6000 - val_loss: 1.0815 - val_rmse: 0.3666\n",
      "Epoch 779/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5651 - loss: 1.2450 - rmse: 0.3955\n",
      "Epoch 779: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5642 - loss: 1.2428 - rmse: 0.3955 - val_accuracy: 0.6000 - val_loss: 0.9621 - val_rmse: 0.3596\n",
      "Epoch 780/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5312 - loss: 1.2156 - rmse: 0.3940\n",
      "Epoch 780: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5332 - loss: 1.2093 - rmse: 0.3933 - val_accuracy: 0.7000 - val_loss: 1.0414 - val_rmse: 0.3556\n",
      "Epoch 781/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6009 - loss: 1.0928 - rmse: 0.3795\n",
      "Epoch 781: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6011 - loss: 1.0938 - rmse: 0.3796 - val_accuracy: 0.7500 - val_loss: 0.9921 - val_rmse: 0.3573\n",
      "Epoch 782/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5316 - loss: 1.1334 - rmse: 0.3916\n",
      "Epoch 782: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5336 - loss: 1.1366 - rmse: 0.3917 - val_accuracy: 0.4000 - val_loss: 1.3259 - val_rmse: 0.4329\n",
      "Epoch 783/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4166 - loss: 1.3660 - rmse: 0.4268\n",
      "Epoch 783: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4176 - loss: 1.3644 - rmse: 0.4266 - val_accuracy: 0.6000 - val_loss: 1.1254 - val_rmse: 0.3775\n",
      "Epoch 784/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5567 - loss: 1.1671 - rmse: 0.3955\n",
      "Epoch 784: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5548 - loss: 1.1693 - rmse: 0.3958 - val_accuracy: 0.6000 - val_loss: 1.1418 - val_rmse: 0.3802\n",
      "Epoch 785/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4768 - loss: 1.3413 - rmse: 0.4196\n",
      "Epoch 785: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4778 - loss: 1.3426 - rmse: 0.4197 - val_accuracy: 0.4500 - val_loss: 2.1291 - val_rmse: 0.4866\n",
      "Epoch 786/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5081 - loss: 1.4071 - rmse: 0.4104\n",
      "Epoch 786: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5046 - loss: 1.4058 - rmse: 0.4109 - val_accuracy: 0.5500 - val_loss: 1.5004 - val_rmse: 0.4186\n",
      "Epoch 787/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5039 - loss: 1.1699 - rmse: 0.3896\n",
      "Epoch 787: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5037 - loss: 1.1738 - rmse: 0.3903 - val_accuracy: 0.7000 - val_loss: 1.0501 - val_rmse: 0.3644\n",
      "Epoch 788/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5649 - loss: 1.1509 - rmse: 0.3909\n",
      "Epoch 788: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5656 - loss: 1.1506 - rmse: 0.3910 - val_accuracy: 0.7500 - val_loss: 0.9834 - val_rmse: 0.3554\n",
      "Epoch 789/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5322 - loss: 1.2605 - rmse: 0.4042\n",
      "Epoch 789: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5248 - loss: 1.2706 - rmse: 0.4058 - val_accuracy: 0.4000 - val_loss: 1.5391 - val_rmse: 0.4425\n",
      "Epoch 790/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4704 - loss: 1.2404 - rmse: 0.4034\n",
      "Epoch 790: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4703 - loss: 1.2470 - rmse: 0.4041 - val_accuracy: 0.3500 - val_loss: 1.6152 - val_rmse: 0.4607\n",
      "Epoch 791/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3244 - loss: 4.4779 - rmse: 0.4929\n",
      "Epoch 791: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3200 - loss: 4.7690 - rmse: 0.4965 - val_accuracy: 0.1500 - val_loss: 8.3629 - val_rmse: 0.6158\n",
      "Epoch 792/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2065 - loss: 6.1627 - rmse: 0.5734\n",
      "Epoch 792: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.2108 - loss: 6.0511 - rmse: 0.5707 - val_accuracy: 0.5500 - val_loss: 1.9225 - val_rmse: 0.4400\n",
      "Epoch 793/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3685 - loss: 2.4460 - rmse: 0.4736\n",
      "Epoch 793: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3707 - loss: 2.4433 - rmse: 0.4739 - val_accuracy: 0.4000 - val_loss: 3.3311 - val_rmse: 0.4695\n",
      "Epoch 794/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3406 - loss: 2.7110 - rmse: 0.4724\n",
      "Epoch 794: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3413 - loss: 2.7098 - rmse: 0.4724 - val_accuracy: 0.3500 - val_loss: 2.4944 - val_rmse: 0.4458\n",
      "Epoch 795/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2915 - loss: 2.0460 - rmse: 0.4502\n",
      "Epoch 795: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.2930 - loss: 2.0548 - rmse: 0.4506 - val_accuracy: 0.3500 - val_loss: 2.2740 - val_rmse: 0.4354\n",
      "Epoch 796/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4121 - loss: 2.3971 - rmse: 0.4567\n",
      "Epoch 796: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.4117 - loss: 2.3866 - rmse: 0.4565 - val_accuracy: 0.5500 - val_loss: 1.7114 - val_rmse: 0.4042\n",
      "Epoch 797/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3126 - loss: 1.8771 - rmse: 0.4574\n",
      "Epoch 797: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.3137 - loss: 1.8759 - rmse: 0.4572 - val_accuracy: 0.6000 - val_loss: 1.6689 - val_rmse: 0.4052\n",
      "Epoch 798/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3802 - loss: 1.9050 - rmse: 0.4505\n",
      "Epoch 798: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3776 - loss: 2.0030 - rmse: 0.4526 - val_accuracy: 0.2500 - val_loss: 16.3041 - val_rmse: 0.6124\n",
      "Epoch 799/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2295 - loss: 8.3298 - rmse: 0.5931\n",
      "Epoch 799: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.2297 - loss: 8.3018 - rmse: 0.5928 - val_accuracy: 0.2000 - val_loss: 4.6604 - val_rmse: 0.5499\n",
      "Epoch 800/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2868 - loss: 3.8751 - rmse: 0.5344\n",
      "Epoch 800: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.2885 - loss: 3.8676 - rmse: 0.5339 - val_accuracy: 0.2500 - val_loss: 3.7109 - val_rmse: 0.5358\n",
      "Epoch 801/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.3993 - loss: 3.2402 - rmse: 0.4815\n",
      "Epoch 801: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.3990 - loss: 3.2359 - rmse: 0.4814 - val_accuracy: 0.3500 - val_loss: 3.2400 - val_rmse: 0.5267\n",
      "Epoch 802/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3320 - loss: 2.0660 - rmse: 0.5005\n",
      "Epoch 802: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3204 - loss: 2.0734 - rmse: 0.5021 - val_accuracy: 0.2000 - val_loss: 1.4981 - val_rmse: 0.4590\n",
      "Epoch 803/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2378 - loss: 1.7512 - rmse: 0.4498\n",
      "Epoch 803: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.2414 - loss: 1.8016 - rmse: 0.4515 - val_accuracy: 0.2000 - val_loss: 2.8407 - val_rmse: 0.5047\n",
      "Epoch 804/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3148 - loss: 2.1233 - rmse: 0.4484\n",
      "Epoch 804: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3177 - loss: 2.1282 - rmse: 0.4484 - val_accuracy: 0.0500 - val_loss: 3.4866 - val_rmse: 0.5728\n",
      "Epoch 805/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3908 - loss: 2.4458 - rmse: 0.4755\n",
      "Epoch 805: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3917 - loss: 2.4456 - rmse: 0.4753 - val_accuracy: 0.5000 - val_loss: 2.2323 - val_rmse: 0.4407\n",
      "Epoch 806/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4465 - loss: 2.2657 - rmse: 0.4589\n",
      "Epoch 806: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4436 - loss: 2.2751 - rmse: 0.4600 - val_accuracy: 0.1500 - val_loss: 2.9129 - val_rmse: 0.5374\n",
      "Epoch 807/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3306 - loss: 1.8272 - rmse: 0.4545\n",
      "Epoch 807: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.3293 - loss: 1.8331 - rmse: 0.4550 - val_accuracy: 0.4000 - val_loss: 2.6730 - val_rmse: 0.4667\n",
      "Epoch 808/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.3520 - loss: 1.9480 - rmse: 0.4677\n",
      "Epoch 808: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.3521 - loss: 1.9443 - rmse: 0.4673 - val_accuracy: 0.2000 - val_loss: 2.8792 - val_rmse: 0.5389\n",
      "Epoch 809/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1672 - loss: 3.2082 - rmse: 0.5573\n",
      "Epoch 809: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.1683 - loss: 3.1981 - rmse: 0.5568 - val_accuracy: 0.1500 - val_loss: 2.3064 - val_rmse: 0.5336\n",
      "Epoch 810/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2314 - loss: 1.8717 - rmse: 0.4917\n",
      "Epoch 810: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.2336 - loss: 1.8683 - rmse: 0.4912 - val_accuracy: 0.3000 - val_loss: 1.9411 - val_rmse: 0.4822\n",
      "Epoch 811/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4120 - loss: 1.4602 - rmse: 0.4425\n",
      "Epoch 811: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4112 - loss: 1.4677 - rmse: 0.4428 - val_accuracy: 0.2500 - val_loss: 1.9617 - val_rmse: 0.4816\n",
      "Epoch 812/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4290 - loss: 1.3899 - rmse: 0.4307\n",
      "Epoch 812: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4265 - loss: 1.3924 - rmse: 0.4313 - val_accuracy: 0.2500 - val_loss: 1.7603 - val_rmse: 0.4620\n",
      "Epoch 813/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5072 - loss: 1.2118 - rmse: 0.4059\n",
      "Epoch 813: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5016 - loss: 1.2200 - rmse: 0.4072 - val_accuracy: 0.3000 - val_loss: 1.6212 - val_rmse: 0.4497\n",
      "Epoch 814/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4168 - loss: 1.3542 - rmse: 0.4217\n",
      "Epoch 814: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4159 - loss: 1.3533 - rmse: 0.4218 - val_accuracy: 0.2000 - val_loss: 1.6200 - val_rmse: 0.4723\n",
      "Epoch 815/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3087 - loss: 1.5386 - rmse: 0.4651\n",
      "Epoch 815: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.3077 - loss: 1.5341 - rmse: 0.4644 - val_accuracy: 0.1500 - val_loss: 1.4920 - val_rmse: 0.4586\n",
      "Epoch 816/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.3091 - loss: 1.3689 - rmse: 0.4429\n",
      "Epoch 816: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.3098 - loss: 1.3704 - rmse: 0.4429 - val_accuracy: 0.2500 - val_loss: 1.6024 - val_rmse: 0.4562\n",
      "Epoch 817/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1674 - loss: 1.7400 - rmse: 0.4642\n",
      "Epoch 817: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.1700 - loss: 1.7433 - rmse: 0.4644 - val_accuracy: 0.3000 - val_loss: 1.5270 - val_rmse: 0.4432\n",
      "Epoch 818/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3568 - loss: 1.4409 - rmse: 0.4350\n",
      "Epoch 818: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.3570 - loss: 1.4562 - rmse: 0.4356 - val_accuracy: 0.3000 - val_loss: 3.5143 - val_rmse: 0.5184\n",
      "Epoch 819/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2599 - loss: 2.8587 - rmse: 0.5128\n",
      "Epoch 819: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.2613 - loss: 2.8471 - rmse: 0.5124 - val_accuracy: 0.3500 - val_loss: 2.3047 - val_rmse: 0.4890\n",
      "Epoch 820/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3635 - loss: 1.8850 - rmse: 0.4612\n",
      "Epoch 820: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3588 - loss: 1.8795 - rmse: 0.4613 - val_accuracy: 0.2500 - val_loss: 1.3210 - val_rmse: 0.4230\n",
      "Epoch 821/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4036 - loss: 1.2883 - rmse: 0.4160\n",
      "Epoch 821: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.4051 - loss: 1.2875 - rmse: 0.4158 - val_accuracy: 0.1000 - val_loss: 1.7569 - val_rmse: 0.4803\n",
      "Epoch 822/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.3014 - loss: 1.9748 - rmse: 0.4856\n",
      "Epoch 822: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.3023 - loss: 1.9746 - rmse: 0.4854 - val_accuracy: 0.3000 - val_loss: 1.6290 - val_rmse: 0.4497\n",
      "Epoch 823/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4307 - loss: 1.3803 - rmse: 0.4193\n",
      "Epoch 823: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4322 - loss: 1.3785 - rmse: 0.4191 - val_accuracy: 0.6000 - val_loss: 1.0995 - val_rmse: 0.3834\n",
      "Epoch 824/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3909 - loss: 1.6777 - rmse: 0.4391\n",
      "Epoch 824: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3866 - loss: 1.6935 - rmse: 0.4404 - val_accuracy: 0.1000 - val_loss: 2.6761 - val_rmse: 0.5178\n",
      "Epoch 825/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2852 - loss: 1.9079 - rmse: 0.4611\n",
      "Epoch 825: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.2848 - loss: 1.9056 - rmse: 0.4611 - val_accuracy: 0.1000 - val_loss: 2.5652 - val_rmse: 0.5166\n",
      "Epoch 826/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3238 - loss: 2.3606 - rmse: 0.4864\n",
      "Epoch 826: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3220 - loss: 2.3878 - rmse: 0.4875 - val_accuracy: 0.2000 - val_loss: 1.6258 - val_rmse: 0.4884\n",
      "Epoch 827/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2925 - loss: 2.5402 - rmse: 0.4929\n",
      "Epoch 827: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2943 - loss: 2.5295 - rmse: 0.4928 - val_accuracy: 0.4000 - val_loss: 3.1366 - val_rmse: 0.4988\n",
      "Epoch 828/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4897 - loss: 2.7190 - rmse: 0.4454\n",
      "Epoch 828: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4839 - loss: 2.7001 - rmse: 0.4464 - val_accuracy: 0.4000 - val_loss: 1.7111 - val_rmse: 0.4395\n",
      "Epoch 829/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.3033 - loss: 1.7577 - rmse: 0.4698\n",
      "Epoch 829: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.3053 - loss: 1.7523 - rmse: 0.4685 - val_accuracy: 0.4000 - val_loss: 1.6443 - val_rmse: 0.4256\n",
      "Epoch 830/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3469 - loss: 2.4443 - rmse: 0.4659\n",
      "Epoch 830: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.3454 - loss: 2.4711 - rmse: 0.4670 - val_accuracy: 0.3500 - val_loss: 3.4834 - val_rmse: 0.5535\n",
      "Epoch 831/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3524 - loss: 3.9812 - rmse: 0.5032\n",
      "Epoch 831: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.3521 - loss: 3.9815 - rmse: 0.5030 - val_accuracy: 0.1500 - val_loss: 3.7758 - val_rmse: 0.5430\n",
      "Epoch 832/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3389 - loss: 3.5559 - rmse: 0.4920\n",
      "Epoch 832: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3374 - loss: 3.5566 - rmse: 0.4925 - val_accuracy: 0.1500 - val_loss: 2.3254 - val_rmse: 0.5499\n",
      "Epoch 833/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3324 - loss: 1.8598 - rmse: 0.4696\n",
      "Epoch 833: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3339 - loss: 1.8545 - rmse: 0.4691 - val_accuracy: 0.6000 - val_loss: 1.4933 - val_rmse: 0.4206\n",
      "Epoch 834/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4678 - loss: 1.3434 - rmse: 0.4149\n",
      "Epoch 834: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.4659 - loss: 1.3473 - rmse: 0.4154 - val_accuracy: 0.4000 - val_loss: 1.4853 - val_rmse: 0.4309\n",
      "Epoch 835/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3854 - loss: 1.4053 - rmse: 0.4232\n",
      "Epoch 835: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3867 - loss: 1.4032 - rmse: 0.4231 - val_accuracy: 0.3500 - val_loss: 1.4362 - val_rmse: 0.4290\n",
      "Epoch 836/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5415 - loss: 1.2363 - rmse: 0.4051\n",
      "Epoch 836: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5349 - loss: 1.2451 - rmse: 0.4059 - val_accuracy: 0.3000 - val_loss: 1.4152 - val_rmse: 0.4324\n",
      "Epoch 837/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3911 - loss: 1.3721 - rmse: 0.4160\n",
      "Epoch 837: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3929 - loss: 1.3689 - rmse: 0.4159 - val_accuracy: 0.4000 - val_loss: 1.3634 - val_rmse: 0.4286\n",
      "Epoch 838/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4211 - loss: 1.3540 - rmse: 0.4168\n",
      "Epoch 838: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4227 - loss: 1.3506 - rmse: 0.4167 - val_accuracy: 0.5000 - val_loss: 1.3476 - val_rmse: 0.4265\n",
      "Epoch 839/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4198 - loss: 1.2308 - rmse: 0.4108\n",
      "Epoch 839: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4176 - loss: 1.2327 - rmse: 0.4108 - val_accuracy: 0.3000 - val_loss: 1.3157 - val_rmse: 0.4280\n",
      "Epoch 840/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4421 - loss: 1.2864 - rmse: 0.4121\n",
      "Epoch 840: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4437 - loss: 1.2826 - rmse: 0.4118 - val_accuracy: 0.4000 - val_loss: 1.2844 - val_rmse: 0.4242\n",
      "Epoch 841/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4695 - loss: 1.1498 - rmse: 0.4028\n",
      "Epoch 841: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4651 - loss: 1.1531 - rmse: 0.4031 - val_accuracy: 0.3500 - val_loss: 1.2625 - val_rmse: 0.4219\n",
      "Epoch 842/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4812 - loss: 1.2100 - rmse: 0.4013\n",
      "Epoch 842: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.4811 - loss: 1.2084 - rmse: 0.4012 - val_accuracy: 0.3000 - val_loss: 1.2430 - val_rmse: 0.4179\n",
      "Epoch 843/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5561 - loss: 1.0542 - rmse: 0.3831\n",
      "Epoch 843: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5510 - loss: 1.0596 - rmse: 0.3838 - val_accuracy: 0.4500 - val_loss: 1.2368 - val_rmse: 0.4167\n",
      "Epoch 844/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5518 - loss: 1.0965 - rmse: 0.3882\n",
      "Epoch 844: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.5515 - loss: 1.0972 - rmse: 0.3883 - val_accuracy: 0.3500 - val_loss: 1.2229 - val_rmse: 0.4135\n",
      "Epoch 845/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5416 - loss: 1.0712 - rmse: 0.3848\n",
      "Epoch 845: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.5400 - loss: 1.0742 - rmse: 0.3852 - val_accuracy: 0.5000 - val_loss: 1.2268 - val_rmse: 0.4133\n",
      "Epoch 846/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4960 - loss: 1.1451 - rmse: 0.3961\n",
      "Epoch 846: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4963 - loss: 1.1418 - rmse: 0.3955 - val_accuracy: 0.4000 - val_loss: 1.2129 - val_rmse: 0.4104\n",
      "Epoch 847/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5594 - loss: 1.0297 - rmse: 0.3783\n",
      "Epoch 847: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5578 - loss: 1.0354 - rmse: 0.3791 - val_accuracy: 0.4500 - val_loss: 1.2096 - val_rmse: 0.4095\n",
      "Epoch 848/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5012 - loss: 1.0762 - rmse: 0.3846\n",
      "Epoch 848: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5023 - loss: 1.0765 - rmse: 0.3847 - val_accuracy: 0.4500 - val_loss: 1.1966 - val_rmse: 0.4074\n",
      "Epoch 849/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5836 - loss: 0.9908 - rmse: 0.3706\n",
      "Epoch 849: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5785 - loss: 0.9986 - rmse: 0.3717 - val_accuracy: 0.5000 - val_loss: 1.1928 - val_rmse: 0.4066\n",
      "Epoch 850/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6422 - loss: 1.0409 - rmse: 0.3769\n",
      "Epoch 850: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6369 - loss: 1.0444 - rmse: 0.3777 - val_accuracy: 0.5000 - val_loss: 1.1791 - val_rmse: 0.4043\n",
      "Epoch 851/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5736 - loss: 1.0286 - rmse: 0.3757\n",
      "Epoch 851: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5708 - loss: 1.0335 - rmse: 0.3765 - val_accuracy: 0.4500 - val_loss: 1.1750 - val_rmse: 0.4037\n",
      "Epoch 852/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6181 - loss: 1.0284 - rmse: 0.3754\n",
      "Epoch 852: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6119 - loss: 1.0322 - rmse: 0.3760 - val_accuracy: 0.5500 - val_loss: 1.1616 - val_rmse: 0.4015\n",
      "Epoch 853/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5582 - loss: 1.0520 - rmse: 0.3818\n",
      "Epoch 853: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5599 - loss: 1.0528 - rmse: 0.3819 - val_accuracy: 0.5000 - val_loss: 1.1747 - val_rmse: 0.4035\n",
      "Epoch 854/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5500 - loss: 1.1196 - rmse: 0.3924\n",
      "Epoch 854: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5496 - loss: 1.1167 - rmse: 0.3918 - val_accuracy: 0.5000 - val_loss: 1.1720 - val_rmse: 0.4028\n",
      "Epoch 855/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4920 - loss: 1.1469 - rmse: 0.3971\n",
      "Epoch 855: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4933 - loss: 1.1447 - rmse: 0.3967 - val_accuracy: 0.5000 - val_loss: 1.1606 - val_rmse: 0.4007\n",
      "Epoch 856/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4602 - loss: 1.1547 - rmse: 0.3991\n",
      "Epoch 856: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4697 - loss: 1.1470 - rmse: 0.3977 - val_accuracy: 0.5000 - val_loss: 1.1583 - val_rmse: 0.4003\n",
      "Epoch 857/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5374 - loss: 1.0947 - rmse: 0.3830\n",
      "Epoch 857: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5380 - loss: 1.0926 - rmse: 0.3829 - val_accuracy: 0.5000 - val_loss: 1.1512 - val_rmse: 0.3995\n",
      "Epoch 858/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6029 - loss: 1.0240 - rmse: 0.3760\n",
      "Epoch 858: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6020 - loss: 1.0249 - rmse: 0.3761 - val_accuracy: 0.5500 - val_loss: 1.1707 - val_rmse: 0.4021\n",
      "Epoch 859/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6022 - loss: 1.0015 - rmse: 0.3769\n",
      "Epoch 859: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6008 - loss: 1.0039 - rmse: 0.3770 - val_accuracy: 0.5000 - val_loss: 1.1471 - val_rmse: 0.3984\n",
      "Epoch 860/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5383 - loss: 1.0282 - rmse: 0.3798\n",
      "Epoch 860: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5391 - loss: 1.0288 - rmse: 0.3798 - val_accuracy: 0.5000 - val_loss: 1.1424 - val_rmse: 0.3978\n",
      "Epoch 861/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6555 - loss: 0.9720 - rmse: 0.3626\n",
      "Epoch 861: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6505 - loss: 0.9762 - rmse: 0.3635 - val_accuracy: 0.5500 - val_loss: 1.1432 - val_rmse: 0.3984\n",
      "Epoch 862/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5456 - loss: 0.9821 - rmse: 0.3705\n",
      "Epoch 862: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5458 - loss: 0.9855 - rmse: 0.3710 - val_accuracy: 0.4500 - val_loss: 1.1433 - val_rmse: 0.3973\n",
      "Epoch 863/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5391 - loss: 1.0227 - rmse: 0.3751\n",
      "Epoch 863: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5390 - loss: 1.0231 - rmse: 0.3752 - val_accuracy: 0.5000 - val_loss: 1.1423 - val_rmse: 0.3978\n",
      "Epoch 864/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6372 - loss: 1.0183 - rmse: 0.3707\n",
      "Epoch 864: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6321 - loss: 1.0201 - rmse: 0.3713 - val_accuracy: 0.5500 - val_loss: 1.1445 - val_rmse: 0.3982\n",
      "Epoch 865/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5890 - loss: 1.0212 - rmse: 0.3766\n",
      "Epoch 865: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5892 - loss: 1.0216 - rmse: 0.3766 - val_accuracy: 0.5000 - val_loss: 1.1434 - val_rmse: 0.3977\n",
      "Epoch 866/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4923 - loss: 1.0853 - rmse: 0.3892\n",
      "Epoch 866: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4963 - loss: 1.0819 - rmse: 0.3884 - val_accuracy: 0.5000 - val_loss: 1.1417 - val_rmse: 0.3972\n",
      "Epoch 867/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5495 - loss: 1.0721 - rmse: 0.3840\n",
      "Epoch 867: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5498 - loss: 1.0699 - rmse: 0.3836 - val_accuracy: 0.5500 - val_loss: 1.1402 - val_rmse: 0.3975\n",
      "Epoch 868/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6243 - loss: 1.0567 - rmse: 0.3804\n",
      "Epoch 868: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.6218 - loss: 1.0556 - rmse: 0.3803 - val_accuracy: 0.5000 - val_loss: 1.1410 - val_rmse: 0.3977\n",
      "Epoch 869/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5760 - loss: 1.0485 - rmse: 0.3809\n",
      "Epoch 869: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5783 - loss: 1.0474 - rmse: 0.3807 - val_accuracy: 0.5000 - val_loss: 1.1369 - val_rmse: 0.3961\n",
      "Epoch 870/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5551 - loss: 1.0070 - rmse: 0.3753\n",
      "Epoch 870: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5557 - loss: 1.0075 - rmse: 0.3753 - val_accuracy: 0.5500 - val_loss: 1.1507 - val_rmse: 0.3987\n",
      "Epoch 871/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5767 - loss: 0.9931 - rmse: 0.3694\n",
      "Epoch 871: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5757 - loss: 0.9943 - rmse: 0.3696 - val_accuracy: 0.4500 - val_loss: 1.1295 - val_rmse: 0.3950\n",
      "Epoch 872/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5163 - loss: 1.0859 - rmse: 0.3851\n",
      "Epoch 872: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5175 - loss: 1.0914 - rmse: 0.3859 - val_accuracy: 0.4000 - val_loss: 1.2580 - val_rmse: 0.4120\n",
      "Epoch 873/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5255 - loss: 1.2231 - rmse: 0.3925\n",
      "Epoch 873: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5264 - loss: 1.2220 - rmse: 0.3927 - val_accuracy: 0.5500 - val_loss: 1.2314 - val_rmse: 0.4072\n",
      "Epoch 874/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5509 - loss: 1.1239 - rmse: 0.3871\n",
      "Epoch 874: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5510 - loss: 1.1250 - rmse: 0.3872 - val_accuracy: 0.6000 - val_loss: 1.2262 - val_rmse: 0.4071\n",
      "Epoch 875/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6576 - loss: 1.0032 - rmse: 0.3659\n",
      "Epoch 875: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6553 - loss: 1.0068 - rmse: 0.3664 - val_accuracy: 0.6000 - val_loss: 1.2167 - val_rmse: 0.4055\n",
      "Epoch 876/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5841 - loss: 1.0949 - rmse: 0.3876\n",
      "Epoch 876: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5864 - loss: 1.0961 - rmse: 0.3875 - val_accuracy: 0.5000 - val_loss: 1.2098 - val_rmse: 0.4039\n",
      "Epoch 877/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5544 - loss: 1.1973 - rmse: 0.3933\n",
      "Epoch 877: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5579 - loss: 1.1899 - rmse: 0.3925 - val_accuracy: 0.6000 - val_loss: 1.1878 - val_rmse: 0.4005\n",
      "Epoch 878/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5575 - loss: 1.1597 - rmse: 0.3927\n",
      "Epoch 878: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5600 - loss: 1.1575 - rmse: 0.3922 - val_accuracy: 0.6000 - val_loss: 1.1620 - val_rmse: 0.3966\n",
      "Epoch 879/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6696 - loss: 1.0182 - rmse: 0.3702\n",
      "Epoch 879: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6672 - loss: 1.0214 - rmse: 0.3706 - val_accuracy: 0.6000 - val_loss: 1.1705 - val_rmse: 0.3972\n",
      "Epoch 880/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5455 - loss: 1.2039 - rmse: 0.3995\n",
      "Epoch 880: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5498 - loss: 1.1965 - rmse: 0.3983 - val_accuracy: 0.6000 - val_loss: 1.1650 - val_rmse: 0.3942\n",
      "Epoch 881/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6398 - loss: 1.0457 - rmse: 0.3718\n",
      "Epoch 881: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.6401 - loss: 1.0458 - rmse: 0.3718 - val_accuracy: 0.6500 - val_loss: 1.1366 - val_rmse: 0.3879\n",
      "Epoch 882/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6574 - loss: 1.0271 - rmse: 0.3664\n",
      "Epoch 882: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6562 - loss: 1.0279 - rmse: 0.3666 - val_accuracy: 0.6500 - val_loss: 1.1361 - val_rmse: 0.3884\n",
      "Epoch 883/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6189 - loss: 0.9847 - rmse: 0.3676\n",
      "Epoch 883: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6181 - loss: 0.9863 - rmse: 0.3677 - val_accuracy: 0.6000 - val_loss: 1.1156 - val_rmse: 0.3848\n",
      "Epoch 884/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6880 - loss: 1.0399 - rmse: 0.3720\n",
      "Epoch 884: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6857 - loss: 1.0398 - rmse: 0.3720 - val_accuracy: 0.6000 - val_loss: 1.1101 - val_rmse: 0.3831\n",
      "Epoch 885/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6634 - loss: 1.0147 - rmse: 0.3667\n",
      "Epoch 885: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6594 - loss: 1.0164 - rmse: 0.3670 - val_accuracy: 0.6500 - val_loss: 1.1072 - val_rmse: 0.3843\n",
      "Epoch 886/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6479 - loss: 1.0402 - rmse: 0.3729\n",
      "Epoch 886: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6475 - loss: 1.0398 - rmse: 0.3728 - val_accuracy: 0.6000 - val_loss: 1.1100 - val_rmse: 0.3843\n",
      "Epoch 887/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6738 - loss: 0.9432 - rmse: 0.3550\n",
      "Epoch 887: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6719 - loss: 0.9457 - rmse: 0.3555 - val_accuracy: 0.6500 - val_loss: 1.1014 - val_rmse: 0.3819\n",
      "Epoch 888/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6295 - loss: 0.9571 - rmse: 0.3588\n",
      "Epoch 888: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6279 - loss: 0.9620 - rmse: 0.3596 - val_accuracy: 0.6000 - val_loss: 1.1052 - val_rmse: 0.3824\n",
      "Epoch 889/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6754 - loss: 1.0355 - rmse: 0.3768\n",
      "Epoch 889: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6738 - loss: 1.0358 - rmse: 0.3766 - val_accuracy: 0.6000 - val_loss: 1.0883 - val_rmse: 0.3796\n",
      "Epoch 890/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6277 - loss: 0.9764 - rmse: 0.3570\n",
      "Epoch 890: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6273 - loss: 0.9772 - rmse: 0.3572 - val_accuracy: 0.6000 - val_loss: 1.0958 - val_rmse: 0.3808\n",
      "Epoch 891/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6737 - loss: 0.9312 - rmse: 0.3543\n",
      "Epoch 891: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6706 - loss: 0.9384 - rmse: 0.3556 - val_accuracy: 0.6500 - val_loss: 1.0801 - val_rmse: 0.3775\n",
      "Epoch 892/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6557 - loss: 0.9955 - rmse: 0.3660\n",
      "Epoch 892: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6535 - loss: 0.9973 - rmse: 0.3664 - val_accuracy: 0.6500 - val_loss: 1.0962 - val_rmse: 0.3804\n",
      "Epoch 893/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6415 - loss: 1.0781 - rmse: 0.3760\n",
      "Epoch 893: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6409 - loss: 1.0763 - rmse: 0.3758 - val_accuracy: 0.6500 - val_loss: 1.0724 - val_rmse: 0.3774\n",
      "Epoch 894/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6532 - loss: 0.9846 - rmse: 0.3627\n",
      "Epoch 894: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6515 - loss: 0.9855 - rmse: 0.3631 - val_accuracy: 0.6500 - val_loss: 1.0754 - val_rmse: 0.3776\n",
      "Epoch 895/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5755 - loss: 1.0044 - rmse: 0.3691\n",
      "Epoch 895: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5789 - loss: 1.0058 - rmse: 0.3693 - val_accuracy: 0.6000 - val_loss: 1.0977 - val_rmse: 0.3818\n",
      "Epoch 896/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6079 - loss: 0.9442 - rmse: 0.3548\n",
      "Epoch 896: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6069 - loss: 0.9478 - rmse: 0.3556 - val_accuracy: 0.6500 - val_loss: 1.0662 - val_rmse: 0.3764\n",
      "Epoch 897/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6914 - loss: 0.9835 - rmse: 0.3609\n",
      "Epoch 897: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6865 - loss: 0.9861 - rmse: 0.3617 - val_accuracy: 0.6500 - val_loss: 1.0550 - val_rmse: 0.3738\n",
      "Epoch 898/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5799 - loss: 0.9766 - rmse: 0.3642\n",
      "Epoch 898: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5810 - loss: 0.9774 - rmse: 0.3643 - val_accuracy: 0.6000 - val_loss: 1.0925 - val_rmse: 0.3807\n",
      "Epoch 899/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6519 - loss: 0.9347 - rmse: 0.3526\n",
      "Epoch 899: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6510 - loss: 0.9363 - rmse: 0.3530 - val_accuracy: 0.6500 - val_loss: 1.0780 - val_rmse: 0.3780\n",
      "Epoch 900/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6593 - loss: 1.0902 - rmse: 0.3811\n",
      "Epoch 900: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6580 - loss: 1.0981 - rmse: 0.3817 - val_accuracy: 0.3000 - val_loss: 3.9114 - val_rmse: 0.5144\n",
      "Epoch 901/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3207 - loss: 3.2250 - rmse: 0.4953\n",
      "Epoch 901: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3233 - loss: 3.1728 - rmse: 0.4938 - val_accuracy: 0.4500 - val_loss: 1.3443 - val_rmse: 0.4279\n",
      "Epoch 902/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5115 - loss: 1.2110 - rmse: 0.4064\n",
      "Epoch 902: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5129 - loss: 1.2080 - rmse: 0.4059 - val_accuracy: 0.5500 - val_loss: 1.2784 - val_rmse: 0.4199\n",
      "Epoch 903/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6212 - loss: 1.0185 - rmse: 0.3718\n",
      "Epoch 903: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6214 - loss: 1.0187 - rmse: 0.3718 - val_accuracy: 0.5500 - val_loss: 1.2673 - val_rmse: 0.4205\n",
      "Epoch 904/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6012 - loss: 1.0910 - rmse: 0.3807\n",
      "Epoch 904: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5998 - loss: 1.0874 - rmse: 0.3803 - val_accuracy: 0.5500 - val_loss: 1.2796 - val_rmse: 0.4220\n",
      "Epoch 905/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6483 - loss: 0.9544 - rmse: 0.3585\n",
      "Epoch 905: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6477 - loss: 0.9555 - rmse: 0.3587 - val_accuracy: 0.5500 - val_loss: 1.2866 - val_rmse: 0.4233\n",
      "Epoch 906/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6655 - loss: 1.0319 - rmse: 0.3744\n",
      "Epoch 906: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6636 - loss: 1.0310 - rmse: 0.3742 - val_accuracy: 0.5500 - val_loss: 1.2885 - val_rmse: 0.4224\n",
      "Epoch 907/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6641 - loss: 0.9765 - rmse: 0.3621\n",
      "Epoch 907: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6624 - loss: 0.9770 - rmse: 0.3622 - val_accuracy: 0.5500 - val_loss: 1.3064 - val_rmse: 0.4249\n",
      "Epoch 908/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6214 - loss: 0.9383 - rmse: 0.3596\n",
      "Epoch 908: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.6201 - loss: 0.9407 - rmse: 0.3600 - val_accuracy: 0.5500 - val_loss: 1.3214 - val_rmse: 0.4254\n",
      "Epoch 909/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6051 - loss: 0.9493 - rmse: 0.3586\n",
      "Epoch 909: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6056 - loss: 0.9494 - rmse: 0.3587 - val_accuracy: 0.5500 - val_loss: 1.3128 - val_rmse: 0.4263\n",
      "Epoch 910/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6218 - loss: 0.9814 - rmse: 0.3644\n",
      "Epoch 910: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6217 - loss: 0.9813 - rmse: 0.3644 - val_accuracy: 0.5500 - val_loss: 1.3067 - val_rmse: 0.4245\n",
      "Epoch 911/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7107 - loss: 0.8912 - rmse: 0.3468\n",
      "Epoch 911: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7015 - loss: 0.8988 - rmse: 0.3484 - val_accuracy: 0.5000 - val_loss: 1.3133 - val_rmse: 0.4260\n",
      "Epoch 912/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6101 - loss: 0.9763 - rmse: 0.3703\n",
      "Epoch 912: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6131 - loss: 0.9755 - rmse: 0.3700 - val_accuracy: 0.5500 - val_loss: 1.2939 - val_rmse: 0.4230\n",
      "Epoch 913/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6049 - loss: 0.9847 - rmse: 0.3641\n",
      "Epoch 913: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6056 - loss: 0.9833 - rmse: 0.3640 - val_accuracy: 0.5500 - val_loss: 1.3033 - val_rmse: 0.4233\n",
      "Epoch 914/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6248 - loss: 1.0648 - rmse: 0.3758\n",
      "Epoch 914: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6241 - loss: 1.0614 - rmse: 0.3756 - val_accuracy: 0.5500 - val_loss: 1.2833 - val_rmse: 0.4230\n",
      "Epoch 915/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6880 - loss: 0.8709 - rmse: 0.3440\n",
      "Epoch 915: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6822 - loss: 0.8822 - rmse: 0.3461 - val_accuracy: 0.5500 - val_loss: 1.2627 - val_rmse: 0.4206\n",
      "Epoch 916/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6042 - loss: 1.0660 - rmse: 0.3794\n",
      "Epoch 916: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6035 - loss: 1.0660 - rmse: 0.3794 - val_accuracy: 0.6500 - val_loss: 0.9884 - val_rmse: 0.3645\n",
      "Epoch 917/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6113 - loss: 0.9814 - rmse: 0.3663\n",
      "Epoch 917: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6119 - loss: 0.9822 - rmse: 0.3665 - val_accuracy: 0.6500 - val_loss: 0.9799 - val_rmse: 0.3667\n",
      "Epoch 918/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5791 - loss: 0.9924 - rmse: 0.3717\n",
      "Epoch 918: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5790 - loss: 0.9932 - rmse: 0.3719 - val_accuracy: 0.7000 - val_loss: 0.9537 - val_rmse: 0.3597\n",
      "Epoch 919/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6842 - loss: 0.9823 - rmse: 0.3691\n",
      "Epoch 919: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6822 - loss: 0.9840 - rmse: 0.3695 - val_accuracy: 0.7000 - val_loss: 0.9551 - val_rmse: 0.3595\n",
      "Epoch 920/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6811 - loss: 0.8773 - rmse: 0.3478\n",
      "Epoch 920: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6792 - loss: 0.8802 - rmse: 0.3484 - val_accuracy: 0.7500 - val_loss: 0.9753 - val_rmse: 0.3631\n",
      "Epoch 921/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5830 - loss: 0.9819 - rmse: 0.3709\n",
      "Epoch 921: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5847 - loss: 0.9820 - rmse: 0.3709 - val_accuracy: 0.6500 - val_loss: 0.9636 - val_rmse: 0.3615\n",
      "Epoch 922/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5750 - loss: 1.0447 - rmse: 0.3796\n",
      "Epoch 922: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5762 - loss: 1.0419 - rmse: 0.3791 - val_accuracy: 0.7000 - val_loss: 0.9469 - val_rmse: 0.3587\n",
      "Epoch 923/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5705 - loss: 1.0538 - rmse: 0.3828\n",
      "Epoch 923: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5712 - loss: 1.0511 - rmse: 0.3823 - val_accuracy: 0.6500 - val_loss: 0.9716 - val_rmse: 0.3633\n",
      "Epoch 924/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6305 - loss: 1.0100 - rmse: 0.3724\n",
      "Epoch 924: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6304 - loss: 1.0113 - rmse: 0.3728 - val_accuracy: 0.5500 - val_loss: 1.2490 - val_rmse: 0.4202\n",
      "Epoch 925/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5546 - loss: 1.1778 - rmse: 0.3976\n",
      "Epoch 925: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5550 - loss: 1.1791 - rmse: 0.3976 - val_accuracy: 0.6000 - val_loss: 1.1155 - val_rmse: 0.3975\n",
      "Epoch 926/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5792 - loss: 1.2220 - rmse: 0.4048\n",
      "Epoch 926: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5778 - loss: 1.2241 - rmse: 0.4047 - val_accuracy: 0.4000 - val_loss: 1.1933 - val_rmse: 0.4047\n",
      "Epoch 927/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3295 - loss: 1.6756 - rmse: 0.4495\n",
      "Epoch 927: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3298 - loss: 1.6798 - rmse: 0.4498 - val_accuracy: 0.3500 - val_loss: 2.0774 - val_rmse: 0.4650\n",
      "Epoch 928/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2603 - loss: 2.4040 - rmse: 0.4883\n",
      "Epoch 928: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.2605 - loss: 2.3976 - rmse: 0.4884 - val_accuracy: 0.2500 - val_loss: 3.2864 - val_rmse: 0.4865\n",
      "Epoch 929/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2937 - loss: 2.8505 - rmse: 0.4978\n",
      "Epoch 929: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.2902 - loss: 2.8429 - rmse: 0.4981 - val_accuracy: 0.2500 - val_loss: 1.7915 - val_rmse: 0.4500\n",
      "Epoch 930/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3109 - loss: 1.7897 - rmse: 0.4649\n",
      "Epoch 930: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.3106 - loss: 1.7910 - rmse: 0.4652 - val_accuracy: 0.3500 - val_loss: 1.5056 - val_rmse: 0.4514\n",
      "Epoch 931/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3655 - loss: 1.5024 - rmse: 0.4513\n",
      "Epoch 931: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.3619 - loss: 1.5065 - rmse: 0.4515 - val_accuracy: 0.1500 - val_loss: 1.8214 - val_rmse: 0.4960\n",
      "Epoch 932/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2320 - loss: 1.6271 - rmse: 0.4656\n",
      "Epoch 932: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.2315 - loss: 1.6294 - rmse: 0.4659 - val_accuracy: 0.3500 - val_loss: 1.5776 - val_rmse: 0.4559\n",
      "Epoch 933/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2136 - loss: 1.8210 - rmse: 0.4812\n",
      "Epoch 933: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.2148 - loss: 1.8182 - rmse: 0.4810 - val_accuracy: 0.2000 - val_loss: 1.5878 - val_rmse: 0.4649\n",
      "Epoch 934/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3256 - loss: 1.5422 - rmse: 0.4496\n",
      "Epoch 934: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3253 - loss: 1.5454 - rmse: 0.4500 - val_accuracy: 0.6000 - val_loss: 1.2904 - val_rmse: 0.4036\n",
      "Epoch 935/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4714 - loss: 1.1220 - rmse: 0.3942\n",
      "Epoch 935: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.4701 - loss: 1.1248 - rmse: 0.3947 - val_accuracy: 0.6000 - val_loss: 1.2090 - val_rmse: 0.3910\n",
      "Epoch 936/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.3798 - loss: 1.3156 - rmse: 0.4193\n",
      "Epoch 936: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.3767 - loss: 1.3309 - rmse: 0.4211 - val_accuracy: 0.3500 - val_loss: 1.1739 - val_rmse: 0.4062\n",
      "Epoch 937/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2296 - loss: 1.5856 - rmse: 0.4569\n",
      "Epoch 937: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.2297 - loss: 1.5872 - rmse: 0.4571 - val_accuracy: 0.4000 - val_loss: 1.5344 - val_rmse: 0.4502\n",
      "Epoch 938/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.3283 - loss: 1.6064 - rmse: 0.4506\n",
      "Epoch 938: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.3308 - loss: 1.5992 - rmse: 0.4497 - val_accuracy: 0.6000 - val_loss: 1.0639 - val_rmse: 0.3776\n",
      "Epoch 939/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5500 - loss: 1.0772 - rmse: 0.3847\n",
      "Epoch 939: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5507 - loss: 1.0796 - rmse: 0.3854 - val_accuracy: 0.6000 - val_loss: 1.0882 - val_rmse: 0.3808\n",
      "Epoch 940/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5498 - loss: 1.1551 - rmse: 0.3899\n",
      "Epoch 940: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5504 - loss: 1.1537 - rmse: 0.3898 - val_accuracy: 0.6000 - val_loss: 1.0756 - val_rmse: 0.3778\n",
      "Epoch 941/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6026 - loss: 1.0568 - rmse: 0.3739\n",
      "Epoch 941: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6000 - loss: 1.0638 - rmse: 0.3750 - val_accuracy: 0.2000 - val_loss: 1.7017 - val_rmse: 0.4797\n",
      "Epoch 942/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2553 - loss: 1.6011 - rmse: 0.4596\n",
      "Epoch 942: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.2545 - loss: 1.6080 - rmse: 0.4607 - val_accuracy: 0.4000 - val_loss: 1.4990 - val_rmse: 0.4369\n",
      "Epoch 943/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4024 - loss: 1.3735 - rmse: 0.4273\n",
      "Epoch 943: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3998 - loss: 1.3788 - rmse: 0.4280 - val_accuracy: 0.0500 - val_loss: 1.8915 - val_rmse: 0.5049\n",
      "Epoch 944/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2451 - loss: 1.6343 - rmse: 0.4607\n",
      "Epoch 944: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.2477 - loss: 1.6297 - rmse: 0.4601 - val_accuracy: 0.2000 - val_loss: 1.5828 - val_rmse: 0.4591\n",
      "Epoch 945/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2834 - loss: 1.4423 - rmse: 0.4407\n",
      "Epoch 945: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.2849 - loss: 1.4409 - rmse: 0.4404 - val_accuracy: 0.4000 - val_loss: 1.3438 - val_rmse: 0.4276\n",
      "Epoch 946/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4126 - loss: 1.3643 - rmse: 0.4297\n",
      "Epoch 946: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4106 - loss: 1.3676 - rmse: 0.4301 - val_accuracy: 0.2500 - val_loss: 1.6249 - val_rmse: 0.4683\n",
      "Epoch 947/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2876 - loss: 1.6268 - rmse: 0.4545\n",
      "Epoch 947: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.2900 - loss: 1.6279 - rmse: 0.4545 - val_accuracy: 0.3000 - val_loss: 1.4214 - val_rmse: 0.4408\n",
      "Epoch 948/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3596 - loss: 1.4676 - rmse: 0.4328\n",
      "Epoch 948: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3597 - loss: 1.4670 - rmse: 0.4328 - val_accuracy: 0.4500 - val_loss: 1.4348 - val_rmse: 0.4365\n",
      "Epoch 949/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2870 - loss: 1.4864 - rmse: 0.4443\n",
      "Epoch 949: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.2880 - loss: 1.4864 - rmse: 0.4444 - val_accuracy: 0.4000 - val_loss: 1.3935 - val_rmse: 0.4292\n",
      "Epoch 950/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3607 - loss: 1.3234 - rmse: 0.4224\n",
      "Epoch 950: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.3578 - loss: 1.3265 - rmse: 0.4230 - val_accuracy: 0.3000 - val_loss: 1.5033 - val_rmse: 0.4485\n",
      "Epoch 951/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2764 - loss: 1.4715 - rmse: 0.4409\n",
      "Epoch 951: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.2780 - loss: 1.4684 - rmse: 0.4405 - val_accuracy: 0.4000 - val_loss: 1.1469 - val_rmse: 0.3922\n",
      "Epoch 952/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4742 - loss: 1.1990 - rmse: 0.4088\n",
      "Epoch 952: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4732 - loss: 1.2006 - rmse: 0.4091 - val_accuracy: 0.2500 - val_loss: 1.3660 - val_rmse: 0.4319\n",
      "Epoch 953/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4745 - loss: 1.1539 - rmse: 0.3968\n",
      "Epoch 953: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4688 - loss: 1.1592 - rmse: 0.3980 - val_accuracy: 0.5500 - val_loss: 1.0661 - val_rmse: 0.3772\n",
      "Epoch 954/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3798 - loss: 1.3094 - rmse: 0.4264\n",
      "Epoch 954: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3784 - loss: 1.3095 - rmse: 0.4265 - val_accuracy: 0.5000 - val_loss: 1.1796 - val_rmse: 0.4035\n",
      "Epoch 955/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4434 - loss: 1.2435 - rmse: 0.4162\n",
      "Epoch 955: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4408 - loss: 1.2445 - rmse: 0.4162 - val_accuracy: 0.3500 - val_loss: 1.1810 - val_rmse: 0.4097\n",
      "Epoch 956/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3672 - loss: 1.3202 - rmse: 0.4229\n",
      "Epoch 956: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3665 - loss: 1.3216 - rmse: 0.4231 - val_accuracy: 0.3000 - val_loss: 1.5714 - val_rmse: 0.4583\n",
      "Epoch 957/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3735 - loss: 1.4770 - rmse: 0.4413\n",
      "Epoch 957: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3691 - loss: 1.4849 - rmse: 0.4426 - val_accuracy: 0.2000 - val_loss: 1.7528 - val_rmse: 0.4876\n",
      "Epoch 958/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2865 - loss: 1.6113 - rmse: 0.4596\n",
      "Epoch 958: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2909 - loss: 1.6044 - rmse: 0.4585 - val_accuracy: 0.1000 - val_loss: 1.9800 - val_rmse: 0.5071\n",
      "Epoch 959/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3682 - loss: 1.4036 - rmse: 0.4318\n",
      "Epoch 959: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3636 - loss: 1.4061 - rmse: 0.4325 - val_accuracy: 0.2500 - val_loss: 1.4630 - val_rmse: 0.4476\n",
      "Epoch 960/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3302 - loss: 1.3445 - rmse: 0.4293\n",
      "Epoch 960: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.3322 - loss: 1.3462 - rmse: 0.4295 - val_accuracy: 0.6000 - val_loss: 1.2341 - val_rmse: 0.4106\n",
      "Epoch 961/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4497 - loss: 1.2773 - rmse: 0.4170\n",
      "Epoch 961: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4494 - loss: 1.2779 - rmse: 0.4171 - val_accuracy: 0.5500 - val_loss: 1.2521 - val_rmse: 0.4192\n",
      "Epoch 962/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4931 - loss: 1.2560 - rmse: 0.4144\n",
      "Epoch 962: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4974 - loss: 1.2527 - rmse: 0.4138 - val_accuracy: 0.6500 - val_loss: 1.2052 - val_rmse: 0.4030\n",
      "Epoch 963/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5390 - loss: 1.3968 - rmse: 0.4086\n",
      "Epoch 963: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5309 - loss: 1.4518 - rmse: 0.4123 - val_accuracy: 0.2500 - val_loss: 4.2713 - val_rmse: 0.5898\n",
      "Epoch 964/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2153 - loss: 6.8473 - rmse: 0.5838\n",
      "Epoch 964: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2168 - loss: 6.8417 - rmse: 0.5826 - val_accuracy: 0.2500 - val_loss: 5.2575 - val_rmse: 0.5041\n",
      "Epoch 965/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1680 - loss: 3.1733 - rmse: 0.5075\n",
      "Epoch 965: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.1695 - loss: 3.0942 - rmse: 0.5052 - val_accuracy: 0.4500 - val_loss: 1.3604 - val_rmse: 0.4335\n",
      "Epoch 966/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2750 - loss: 1.5177 - rmse: 0.4485\n",
      "Epoch 966: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.2789 - loss: 1.5149 - rmse: 0.4481 - val_accuracy: 0.4500 - val_loss: 1.2685 - val_rmse: 0.4196\n",
      "Epoch 967/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2796 - loss: 1.4305 - rmse: 0.4375\n",
      "Epoch 967: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2805 - loss: 1.4310 - rmse: 0.4375 - val_accuracy: 0.4500 - val_loss: 1.2632 - val_rmse: 0.4207\n",
      "Epoch 968/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3461 - loss: 1.3603 - rmse: 0.4295\n",
      "Epoch 968: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3448 - loss: 1.3619 - rmse: 0.4296 - val_accuracy: 0.4500 - val_loss: 1.2847 - val_rmse: 0.4238\n",
      "Epoch 969/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4327 - loss: 1.3195 - rmse: 0.4240\n",
      "Epoch 969: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4287 - loss: 1.3267 - rmse: 0.4247 - val_accuracy: 0.2500 - val_loss: 1.2909 - val_rmse: 0.4246\n",
      "Epoch 970/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2533 - loss: 1.4314 - rmse: 0.4359\n",
      "Epoch 970: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2534 - loss: 1.4306 - rmse: 0.4358 - val_accuracy: 0.4500 - val_loss: 1.2658 - val_rmse: 0.4215\n",
      "Epoch 971/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3900 - loss: 1.4318 - rmse: 0.4344\n",
      "Epoch 971: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3888 - loss: 1.4308 - rmse: 0.4343 - val_accuracy: 0.5000 - val_loss: 1.2703 - val_rmse: 0.4230\n",
      "Epoch 972/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3311 - loss: 1.3562 - rmse: 0.4287\n",
      "Epoch 972: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3304 - loss: 1.3578 - rmse: 0.4288 - val_accuracy: 0.4000 - val_loss: 1.2911 - val_rmse: 0.4261\n",
      "Epoch 973/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.2724 - loss: 1.3821 - rmse: 0.4293\n",
      "Epoch 973: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.2732 - loss: 1.3827 - rmse: 0.4293 - val_accuracy: 0.4500 - val_loss: 1.2714 - val_rmse: 0.4223\n",
      "Epoch 974/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2840 - loss: 1.3961 - rmse: 0.4338\n",
      "Epoch 974: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2846 - loss: 1.3958 - rmse: 0.4337 - val_accuracy: 0.4000 - val_loss: 1.2725 - val_rmse: 0.4239\n",
      "Epoch 975/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3985 - loss: 1.5145 - rmse: 0.4378\n",
      "Epoch 975: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3946 - loss: 1.5029 - rmse: 0.4370 - val_accuracy: 0.4000 - val_loss: 1.2935 - val_rmse: 0.4266\n",
      "Epoch 976/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2590 - loss: 1.5291 - rmse: 0.4455\n",
      "Epoch 976: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.2600 - loss: 1.5206 - rmse: 0.4446 - val_accuracy: 0.4500 - val_loss: 1.2621 - val_rmse: 0.4226\n",
      "Epoch 977/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2549 - loss: 1.3865 - rmse: 0.4317\n",
      "Epoch 977: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2545 - loss: 1.3845 - rmse: 0.4314 - val_accuracy: 0.4500 - val_loss: 1.2714 - val_rmse: 0.4234\n",
      "Epoch 978/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3833 - loss: 1.3068 - rmse: 0.4205\n",
      "Epoch 978: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3827 - loss: 1.3109 - rmse: 0.4211 - val_accuracy: 0.4500 - val_loss: 1.2668 - val_rmse: 0.4224\n",
      "Epoch 979/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4911 - loss: 1.3396 - rmse: 0.4226\n",
      "Epoch 979: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4848 - loss: 1.3409 - rmse: 0.4228 - val_accuracy: 0.3500 - val_loss: 1.2977 - val_rmse: 0.4280\n",
      "Epoch 980/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2907 - loss: 1.3214 - rmse: 0.4221\n",
      "Epoch 980: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2915 - loss: 1.3243 - rmse: 0.4225 - val_accuracy: 0.3500 - val_loss: 1.2729 - val_rmse: 0.4242\n",
      "Epoch 981/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3159 - loss: 1.3653 - rmse: 0.4266\n",
      "Epoch 981: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3153 - loss: 1.3641 - rmse: 0.4265 - val_accuracy: 0.4000 - val_loss: 1.2643 - val_rmse: 0.4230\n",
      "Epoch 982/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4941 - loss: 1.2910 - rmse: 0.4164\n",
      "Epoch 982: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4924 - loss: 1.2924 - rmse: 0.4166 - val_accuracy: 0.5000 - val_loss: 1.2497 - val_rmse: 0.4211\n",
      "Epoch 983/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2832 - loss: 1.3673 - rmse: 0.4278\n",
      "Epoch 983: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2830 - loss: 1.3667 - rmse: 0.4277 - val_accuracy: 0.5500 - val_loss: 1.2461 - val_rmse: 0.4202\n",
      "Epoch 984/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3092 - loss: 1.3204 - rmse: 0.4214\n",
      "Epoch 984: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3101 - loss: 1.3220 - rmse: 0.4218 - val_accuracy: 0.5000 - val_loss: 1.2527 - val_rmse: 0.4205\n",
      "Epoch 985/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3893 - loss: 1.3431 - rmse: 0.4265\n",
      "Epoch 985: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3871 - loss: 1.3421 - rmse: 0.4263 - val_accuracy: 0.6000 - val_loss: 1.2456 - val_rmse: 0.4196\n",
      "Epoch 986/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3117 - loss: 1.2899 - rmse: 0.4203\n",
      "Epoch 986: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3121 - loss: 1.2922 - rmse: 0.4205 - val_accuracy: 0.6000 - val_loss: 1.2444 - val_rmse: 0.4208\n",
      "Epoch 987/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4042 - loss: 1.2759 - rmse: 0.4176\n",
      "Epoch 987: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.4022 - loss: 1.2791 - rmse: 0.4181 - val_accuracy: 0.5000 - val_loss: 1.2385 - val_rmse: 0.4174\n",
      "Epoch 988/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3689 - loss: 1.3735 - rmse: 0.4281\n",
      "Epoch 988: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3666 - loss: 1.3713 - rmse: 0.4279 - val_accuracy: 0.7000 - val_loss: 1.2293 - val_rmse: 0.4164\n",
      "Epoch 989/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4337 - loss: 1.2549 - rmse: 0.4130\n",
      "Epoch 989: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4334 - loss: 1.2559 - rmse: 0.4131 - val_accuracy: 0.5000 - val_loss: 1.2552 - val_rmse: 0.4205\n",
      "Epoch 990/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3956 - loss: 1.2600 - rmse: 0.4132\n",
      "Epoch 990: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3914 - loss: 1.2642 - rmse: 0.4139 - val_accuracy: 0.5000 - val_loss: 1.2374 - val_rmse: 0.4182\n",
      "Epoch 991/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3869 - loss: 1.3150 - rmse: 0.4215\n",
      "Epoch 991: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3881 - loss: 1.3147 - rmse: 0.4215 - val_accuracy: 0.6000 - val_loss: 1.2427 - val_rmse: 0.4231\n",
      "Epoch 992/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3318 - loss: 1.8096 - rmse: 0.4407\n",
      "Epoch 992: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3323 - loss: 1.8100 - rmse: 0.4405 - val_accuracy: 0.4000 - val_loss: 2.2571 - val_rmse: 0.4591\n",
      "Epoch 993/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3774 - loss: 1.5336 - rmse: 0.4308\n",
      "Epoch 993: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3758 - loss: 1.5371 - rmse: 0.4312 - val_accuracy: 0.4500 - val_loss: 1.7543 - val_rmse: 0.4501\n",
      "Epoch 994/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2748 - loss: 1.4852 - rmse: 0.4411\n",
      "Epoch 994: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.2746 - loss: 1.4847 - rmse: 0.4409 - val_accuracy: 0.4000 - val_loss: 1.4869 - val_rmse: 0.4340\n",
      "Epoch 995/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3349 - loss: 1.3772 - rmse: 0.4319\n",
      "Epoch 995: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.3367 - loss: 1.3769 - rmse: 0.4317 - val_accuracy: 0.6500 - val_loss: 1.3815 - val_rmse: 0.4156\n",
      "Epoch 996/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.3511 - loss: 1.3539 - rmse: 0.4236\n",
      "Epoch 996: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.3519 - loss: 1.3534 - rmse: 0.4236 - val_accuracy: 0.6500 - val_loss: 1.3828 - val_rmse: 0.4166\n",
      "Epoch 997/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4154 - loss: 1.3229 - rmse: 0.4228\n",
      "Epoch 997: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4154 - loss: 1.3228 - rmse: 0.4228 - val_accuracy: 0.3500 - val_loss: 1.4959 - val_rmse: 0.4398\n",
      "Epoch 998/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4619 - loss: 1.2683 - rmse: 0.4148\n",
      "Epoch 998: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4601 - loss: 1.2713 - rmse: 0.4152 - val_accuracy: 0.4500 - val_loss: 1.5438 - val_rmse: 0.4399\n",
      "Epoch 999/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5242 - loss: 1.1367 - rmse: 0.3921\n",
      "Epoch 999: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5220 - loss: 1.1412 - rmse: 0.3928 - val_accuracy: 0.4500 - val_loss: 1.4653 - val_rmse: 0.4326\n",
      "Epoch 1000/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4829 - loss: 1.2880 - rmse: 0.4201\n",
      "Epoch 1000: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4832 - loss: 1.2881 - rmse: 0.4201 - val_accuracy: 0.5000 - val_loss: 1.4117 - val_rmse: 0.4237\n",
      "Epoch 1001/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4527 - loss: 1.2465 - rmse: 0.4152\n",
      "Epoch 1001: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4545 - loss: 1.2462 - rmse: 0.4153 - val_accuracy: 0.5000 - val_loss: 1.3879 - val_rmse: 0.4191\n",
      "Epoch 1002/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4606 - loss: 1.2259 - rmse: 0.4173\n",
      "Epoch 1002: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4617 - loss: 1.2255 - rmse: 0.4171 - val_accuracy: 0.5000 - val_loss: 1.3704 - val_rmse: 0.4220\n",
      "Epoch 1003/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5714 - loss: 1.1643 - rmse: 0.4016\n",
      "Epoch 1003: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5684 - loss: 1.1669 - rmse: 0.4019 - val_accuracy: 0.5000 - val_loss: 1.3746 - val_rmse: 0.4214\n",
      "Epoch 1004/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5150 - loss: 1.1310 - rmse: 0.3951\n",
      "Epoch 1004: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5145 - loss: 1.1320 - rmse: 0.3954 - val_accuracy: 0.5000 - val_loss: 1.3677 - val_rmse: 0.4234\n",
      "Epoch 1005/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4534 - loss: 1.1651 - rmse: 0.4041\n",
      "Epoch 1005: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4553 - loss: 1.1645 - rmse: 0.4040 - val_accuracy: 0.5000 - val_loss: 1.3491 - val_rmse: 0.4181\n",
      "Epoch 1006/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5731 - loss: 1.1073 - rmse: 0.3914\n",
      "Epoch 1006: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5719 - loss: 1.1080 - rmse: 0.3915 - val_accuracy: 0.5000 - val_loss: 1.3315 - val_rmse: 0.4155\n",
      "Epoch 1007/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4365 - loss: 1.2005 - rmse: 0.4084\n",
      "Epoch 1007: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4377 - loss: 1.1991 - rmse: 0.4082 - val_accuracy: 0.5000 - val_loss: 1.3650 - val_rmse: 0.4235\n",
      "Epoch 1008/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4913 - loss: 1.1338 - rmse: 0.3987\n",
      "Epoch 1008: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4906 - loss: 1.1341 - rmse: 0.3988 - val_accuracy: 0.5500 - val_loss: 1.3847 - val_rmse: 0.4252\n",
      "Epoch 1009/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4935 - loss: 1.1574 - rmse: 0.4036\n",
      "Epoch 1009: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4946 - loss: 1.1556 - rmse: 0.4033 - val_accuracy: 0.5000 - val_loss: 1.3722 - val_rmse: 0.4241\n",
      "Epoch 1010/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4393 - loss: 1.1382 - rmse: 0.3983\n",
      "Epoch 1010: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4407 - loss: 1.1530 - rmse: 0.3995 - val_accuracy: 0.2500 - val_loss: 5.3060 - val_rmse: 0.5961\n",
      "Epoch 1011/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3611 - loss: 3.4082 - rmse: 0.4992\n",
      "Epoch 1011: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.3592 - loss: 3.3687 - rmse: 0.4984 - val_accuracy: 0.2000 - val_loss: 1.5064 - val_rmse: 0.4531\n",
      "Epoch 1012/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2761 - loss: 1.5559 - rmse: 0.4437\n",
      "Epoch 1012: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.2792 - loss: 1.5491 - rmse: 0.4432 - val_accuracy: 0.4000 - val_loss: 1.4233 - val_rmse: 0.4419\n",
      "Epoch 1013/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2983 - loss: 1.4252 - rmse: 0.4401\n",
      "Epoch 1013: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.2957 - loss: 1.4267 - rmse: 0.4403 - val_accuracy: 0.3000 - val_loss: 1.3799 - val_rmse: 0.4380\n",
      "Epoch 1014/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2692 - loss: 1.3389 - rmse: 0.4292\n",
      "Epoch 1014: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2710 - loss: 1.3390 - rmse: 0.4292 - val_accuracy: 0.2500 - val_loss: 1.3781 - val_rmse: 0.4383\n",
      "Epoch 1015/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4540 - loss: 1.3037 - rmse: 0.4229\n",
      "Epoch 1015: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4482 - loss: 1.3062 - rmse: 0.4233 - val_accuracy: 0.2000 - val_loss: 1.4100 - val_rmse: 0.4448\n",
      "Epoch 1016/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3037 - loss: 1.3851 - rmse: 0.4342\n",
      "Epoch 1016: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3053 - loss: 1.3827 - rmse: 0.4339 - val_accuracy: 0.5000 - val_loss: 1.3735 - val_rmse: 0.4339\n",
      "Epoch 1017/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3839 - loss: 1.3110 - rmse: 0.4225\n",
      "Epoch 1017: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3829 - loss: 1.3111 - rmse: 0.4225 - val_accuracy: 0.2500 - val_loss: 1.3548 - val_rmse: 0.4359\n",
      "Epoch 1018/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3989 - loss: 1.3262 - rmse: 0.4251\n",
      "Epoch 1018: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3977 - loss: 1.3263 - rmse: 0.4251 - val_accuracy: 0.2000 - val_loss: 1.3622 - val_rmse: 0.4397\n",
      "Epoch 1019/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2962 - loss: 1.3422 - rmse: 0.4272\n",
      "Epoch 1019: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2975 - loss: 1.3412 - rmse: 0.4270 - val_accuracy: 0.4000 - val_loss: 1.3591 - val_rmse: 0.4353\n",
      "Epoch 1020/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3490 - loss: 1.3009 - rmse: 0.4200\n",
      "Epoch 1020: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3480 - loss: 1.3020 - rmse: 0.4202 - val_accuracy: 0.3000 - val_loss: 1.3126 - val_rmse: 0.4264\n",
      "Epoch 1021/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3124 - loss: 1.3317 - rmse: 0.4253\n",
      "Epoch 1021: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3139 - loss: 1.3302 - rmse: 0.4250 - val_accuracy: 0.4000 - val_loss: 1.2885 - val_rmse: 0.4229\n",
      "Epoch 1022/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3333 - loss: 1.2802 - rmse: 0.4180\n",
      "Epoch 1022: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3344 - loss: 1.2804 - rmse: 0.4181 - val_accuracy: 0.4500 - val_loss: 1.2724 - val_rmse: 0.4198\n",
      "Epoch 1023/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4526 - loss: 1.2892 - rmse: 0.4199\n",
      "Epoch 1023: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4478 - loss: 1.2892 - rmse: 0.4199 - val_accuracy: 0.2500 - val_loss: 1.2772 - val_rmse: 0.4222\n",
      "Epoch 1024/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3917 - loss: 1.2680 - rmse: 0.4144\n",
      "Epoch 1024: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3885 - loss: 1.2688 - rmse: 0.4146 - val_accuracy: 0.3000 - val_loss: 1.3300 - val_rmse: 0.4288\n",
      "Epoch 1025/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3589 - loss: 1.2572 - rmse: 0.4183\n",
      "Epoch 1025: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3590 - loss: 1.2581 - rmse: 0.4183 - val_accuracy: 0.3500 - val_loss: 1.2986 - val_rmse: 0.4239\n",
      "Epoch 1026/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3674 - loss: 1.2539 - rmse: 0.4138\n",
      "Epoch 1026: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3671 - loss: 1.2554 - rmse: 0.4140 - val_accuracy: 0.3000 - val_loss: 1.2883 - val_rmse: 0.4233\n",
      "Epoch 1027/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3581 - loss: 1.2878 - rmse: 0.4188\n",
      "Epoch 1027: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3585 - loss: 1.2873 - rmse: 0.4187 - val_accuracy: 0.4000 - val_loss: 1.3237 - val_rmse: 0.4280\n",
      "Epoch 1028/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3977 - loss: 1.3117 - rmse: 0.4233\n",
      "Epoch 1028: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3973 - loss: 1.3111 - rmse: 0.4232 - val_accuracy: 0.5000 - val_loss: 1.2446 - val_rmse: 0.4165\n",
      "Epoch 1029/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4129 - loss: 1.2975 - rmse: 0.4199\n",
      "Epoch 1029: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4101 - loss: 1.2970 - rmse: 0.4199 - val_accuracy: 0.3500 - val_loss: 1.2577 - val_rmse: 0.4185\n",
      "Epoch 1030/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3636 - loss: 1.2812 - rmse: 0.4184\n",
      "Epoch 1030: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3630 - loss: 1.2825 - rmse: 0.4187 - val_accuracy: 0.4500 - val_loss: 1.2638 - val_rmse: 0.4186\n",
      "Epoch 1031/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2591 - loss: 1.3145 - rmse: 0.4256\n",
      "Epoch 1031: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.2609 - loss: 1.3142 - rmse: 0.4255 - val_accuracy: 0.4500 - val_loss: 1.2780 - val_rmse: 0.4199\n",
      "Epoch 1032/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4178 - loss: 1.2568 - rmse: 0.4128\n",
      "Epoch 1032: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4159 - loss: 1.2590 - rmse: 0.4132 - val_accuracy: 0.3500 - val_loss: 1.2470 - val_rmse: 0.4178\n",
      "Epoch 1033/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2703 - loss: 1.2957 - rmse: 0.4266\n",
      "Epoch 1033: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.2747 - loss: 1.2971 - rmse: 0.4264 - val_accuracy: 0.4000 - val_loss: 1.2533 - val_rmse: 0.4172\n",
      "Epoch 1034/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4253 - loss: 1.2678 - rmse: 0.4175\n",
      "Epoch 1034: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4249 - loss: 1.2677 - rmse: 0.4175 - val_accuracy: 0.3000 - val_loss: 1.2844 - val_rmse: 0.4223\n",
      "Epoch 1035/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3473 - loss: 1.2836 - rmse: 0.4190\n",
      "Epoch 1035: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3477 - loss: 1.2831 - rmse: 0.4189 - val_accuracy: 0.3500 - val_loss: 1.2496 - val_rmse: 0.4172\n",
      "Epoch 1036/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3924 - loss: 1.2885 - rmse: 0.4183\n",
      "Epoch 1036: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3938 - loss: 1.2865 - rmse: 0.4180 - val_accuracy: 0.5500 - val_loss: 1.2350 - val_rmse: 0.4142\n",
      "Epoch 1037/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4667 - loss: 1.2239 - rmse: 0.4091\n",
      "Epoch 1037: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4659 - loss: 1.2245 - rmse: 0.4092 - val_accuracy: 0.3500 - val_loss: 1.2518 - val_rmse: 0.4184\n",
      "Epoch 1038/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3835 - loss: 1.2666 - rmse: 0.4164\n",
      "Epoch 1038: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3840 - loss: 1.2661 - rmse: 0.4164 - val_accuracy: 0.4500 - val_loss: 1.2688 - val_rmse: 0.4181\n",
      "Epoch 1039/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4041 - loss: 1.2403 - rmse: 0.4120\n",
      "Epoch 1039: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4036 - loss: 1.2416 - rmse: 0.4122 - val_accuracy: 0.4000 - val_loss: 1.2359 - val_rmse: 0.4142\n",
      "Epoch 1040/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4006 - loss: 1.2706 - rmse: 0.4159\n",
      "Epoch 1040: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.4010 - loss: 1.2701 - rmse: 0.4158 - val_accuracy: 0.4000 - val_loss: 1.2500 - val_rmse: 0.4168\n",
      "Epoch 1041/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4015 - loss: 1.2449 - rmse: 0.4124\n",
      "Epoch 1041: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4015 - loss: 1.2451 - rmse: 0.4125 - val_accuracy: 0.4500 - val_loss: 1.2201 - val_rmse: 0.4133\n",
      "Epoch 1042/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5255 - loss: 1.2099 - rmse: 0.4050\n",
      "Epoch 1042: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5233 - loss: 1.2111 - rmse: 0.4053 - val_accuracy: 0.5000 - val_loss: 1.2552 - val_rmse: 0.4176\n",
      "Epoch 1043/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4099 - loss: 1.2368 - rmse: 0.4106\n",
      "Epoch 1043: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4092 - loss: 1.2384 - rmse: 0.4108 - val_accuracy: 0.5500 - val_loss: 1.2335 - val_rmse: 0.4137\n",
      "Epoch 1044/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.3576 - loss: 1.2995 - rmse: 0.4191\n",
      "Epoch 1044: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3602 - loss: 1.2968 - rmse: 0.4187 - val_accuracy: 0.3500 - val_loss: 1.3138 - val_rmse: 0.4278\n",
      "Epoch 1045/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4361 - loss: 1.2312 - rmse: 0.4116\n",
      "Epoch 1045: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4369 - loss: 1.2312 - rmse: 0.4115 - val_accuracy: 0.4000 - val_loss: 1.2549 - val_rmse: 0.4183\n",
      "Epoch 1046/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3004 - loss: 1.2745 - rmse: 0.4169\n",
      "Epoch 1046: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3071 - loss: 1.2740 - rmse: 0.4169 - val_accuracy: 0.3000 - val_loss: 1.2788 - val_rmse: 0.4209\n",
      "Epoch 1047/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2913 - loss: 1.3100 - rmse: 0.4232\n",
      "Epoch 1047: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2939 - loss: 1.3087 - rmse: 0.4230 - val_accuracy: 0.5500 - val_loss: 1.2152 - val_rmse: 0.4106\n",
      "Epoch 1048/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3814 - loss: 1.2399 - rmse: 0.4117\n",
      "Epoch 1048: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.3816 - loss: 1.2422 - rmse: 0.4120 - val_accuracy: 0.2500 - val_loss: 1.4096 - val_rmse: 0.4372\n",
      "Epoch 1049/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2674 - loss: 1.4415 - rmse: 0.4440\n",
      "Epoch 1049: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.2717 - loss: 1.4355 - rmse: 0.4430 - val_accuracy: 0.3000 - val_loss: 1.5627 - val_rmse: 0.4627\n",
      "Epoch 1050/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4328 - loss: 1.3545 - rmse: 0.4171\n",
      "Epoch 1050: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4284 - loss: 1.3566 - rmse: 0.4178 - val_accuracy: 0.3500 - val_loss: 1.4750 - val_rmse: 0.4419\n",
      "Epoch 1051/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3840 - loss: 1.3460 - rmse: 0.4215\n",
      "Epoch 1051: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3817 - loss: 1.3513 - rmse: 0.4220 - val_accuracy: 0.2000 - val_loss: 1.4513 - val_rmse: 0.4468\n",
      "Epoch 1052/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3343 - loss: 3.4535 - rmse: 0.4666\n",
      "Epoch 1052: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3300 - loss: 3.5226 - rmse: 0.4688 - val_accuracy: 0.2500 - val_loss: 1.7167 - val_rmse: 0.4821\n",
      "Epoch 1053/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2781 - loss: 1.5807 - rmse: 0.4591\n",
      "Epoch 1053: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.2753 - loss: 1.5712 - rmse: 0.4580 - val_accuracy: 0.3000 - val_loss: 1.3561 - val_rmse: 0.4332\n",
      "Epoch 1054/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3235 - loss: 1.2880 - rmse: 0.4219\n",
      "Epoch 1054: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3246 - loss: 1.2877 - rmse: 0.4217 - val_accuracy: 0.4000 - val_loss: 1.3316 - val_rmse: 0.4287\n",
      "Epoch 1055/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4337 - loss: 1.2577 - rmse: 0.4145\n",
      "Epoch 1055: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4324 - loss: 1.2588 - rmse: 0.4147 - val_accuracy: 0.4000 - val_loss: 1.3344 - val_rmse: 0.4284\n",
      "Epoch 1056/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3995 - loss: 1.2849 - rmse: 0.4199\n",
      "Epoch 1056: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3994 - loss: 1.2847 - rmse: 0.4198 - val_accuracy: 0.4500 - val_loss: 1.3322 - val_rmse: 0.4291\n",
      "Epoch 1057/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3895 - loss: 1.2668 - rmse: 0.4162\n",
      "Epoch 1057: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3880 - loss: 1.2680 - rmse: 0.4164 - val_accuracy: 0.3500 - val_loss: 1.3357 - val_rmse: 0.4297\n",
      "Epoch 1058/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3357 - loss: 1.2707 - rmse: 0.4168\n",
      "Epoch 1058: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.3368 - loss: 1.2708 - rmse: 0.4169 - val_accuracy: 0.2500 - val_loss: 1.3314 - val_rmse: 0.4282\n",
      "Epoch 1059/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4465 - loss: 1.2255 - rmse: 0.4102\n",
      "Epoch 1059: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.4464 - loss: 1.2280 - rmse: 0.4106 - val_accuracy: 0.4500 - val_loss: 1.3293 - val_rmse: 0.4279\n",
      "Epoch 1060/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4186 - loss: 1.2704 - rmse: 0.4184\n",
      "Epoch 1060: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.4183 - loss: 1.2704 - rmse: 0.4184 - val_accuracy: 0.3000 - val_loss: 1.3290 - val_rmse: 0.4280\n",
      "Epoch 1061/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2745 - loss: 1.3032 - rmse: 0.4225\n",
      "Epoch 1061: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.2795 - loss: 1.3016 - rmse: 0.4222 - val_accuracy: 0.3500 - val_loss: 1.3266 - val_rmse: 0.4280\n",
      "Epoch 1062/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3697 - loss: 1.2641 - rmse: 0.4156\n",
      "Epoch 1062: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.3691 - loss: 1.2641 - rmse: 0.4157 - val_accuracy: 0.4000 - val_loss: 1.3272 - val_rmse: 0.4286\n",
      "Epoch 1063/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2638 - loss: 1.2885 - rmse: 0.4203\n",
      "Epoch 1063: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.2694 - loss: 1.2873 - rmse: 0.4201 - val_accuracy: 0.4500 - val_loss: 1.3255 - val_rmse: 0.4281\n",
      "Epoch 1064/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5189 - loss: 1.2183 - rmse: 0.4083\n",
      "Epoch 1064: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5119 - loss: 1.2219 - rmse: 0.4089 - val_accuracy: 0.4500 - val_loss: 1.3239 - val_rmse: 0.4279\n",
      "Epoch 1065/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5091 - loss: 1.2378 - rmse: 0.4120\n",
      "Epoch 1065: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5040 - loss: 1.2400 - rmse: 0.4123 - val_accuracy: 0.5000 - val_loss: 1.3211 - val_rmse: 0.4272\n",
      "Epoch 1066/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4814 - loss: 1.2465 - rmse: 0.4134\n",
      "Epoch 1066: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4787 - loss: 1.2475 - rmse: 0.4135 - val_accuracy: 0.4000 - val_loss: 1.3245 - val_rmse: 0.4278\n",
      "Epoch 1067/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4624 - loss: 1.2461 - rmse: 0.4125\n",
      "Epoch 1067: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4622 - loss: 1.2468 - rmse: 0.4126 - val_accuracy: 0.4500 - val_loss: 1.3234 - val_rmse: 0.4274\n",
      "Epoch 1068/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4654 - loss: 1.2425 - rmse: 0.4125\n",
      "Epoch 1068: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4599 - loss: 1.2441 - rmse: 0.4128 - val_accuracy: 0.5000 - val_loss: 1.3180 - val_rmse: 0.4269\n",
      "Epoch 1069/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4265 - loss: 1.2582 - rmse: 0.4158\n",
      "Epoch 1069: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4257 - loss: 1.2584 - rmse: 0.4159 - val_accuracy: 0.4000 - val_loss: 1.3185 - val_rmse: 0.4266\n",
      "Epoch 1070/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4677 - loss: 1.2617 - rmse: 0.4168\n",
      "Epoch 1070: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4666 - loss: 1.2615 - rmse: 0.4167 - val_accuracy: 0.4000 - val_loss: 1.3208 - val_rmse: 0.4261\n",
      "Epoch 1071/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4416 - loss: 1.2388 - rmse: 0.4126\n",
      "Epoch 1071: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4403 - loss: 1.2396 - rmse: 0.4127 - val_accuracy: 0.4000 - val_loss: 1.3177 - val_rmse: 0.4275\n",
      "Epoch 1072/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4570 - loss: 1.2160 - rmse: 0.4084\n",
      "Epoch 1072: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4556 - loss: 1.2179 - rmse: 0.4087 - val_accuracy: 0.4500 - val_loss: 1.3140 - val_rmse: 0.4261\n",
      "Epoch 1073/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4928 - loss: 1.2714 - rmse: 0.4193\n",
      "Epoch 1073: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4924 - loss: 1.2702 - rmse: 0.4190 - val_accuracy: 0.5000 - val_loss: 1.3115 - val_rmse: 0.4256\n",
      "Epoch 1074/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4107 - loss: 1.2321 - rmse: 0.4106\n",
      "Epoch 1074: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.4112 - loss: 1.2326 - rmse: 0.4107 - val_accuracy: 0.4500 - val_loss: 1.3106 - val_rmse: 0.4256\n",
      "Epoch 1075/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4247 - loss: 1.2417 - rmse: 0.4126\n",
      "Epoch 1075: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.4250 - loss: 1.2422 - rmse: 0.4126 - val_accuracy: 0.4500 - val_loss: 1.3099 - val_rmse: 0.4251\n",
      "Epoch 1076/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4468 - loss: 1.2347 - rmse: 0.4109\n",
      "Epoch 1076: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4467 - loss: 1.2351 - rmse: 0.4110 - val_accuracy: 0.5000 - val_loss: 1.3070 - val_rmse: 0.4249\n",
      "Epoch 1077/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4679 - loss: 1.2386 - rmse: 0.4114\n",
      "Epoch 1077: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4655 - loss: 1.2394 - rmse: 0.4115 - val_accuracy: 0.4000 - val_loss: 1.3114 - val_rmse: 0.4263\n",
      "Epoch 1078/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.3591 - loss: 1.2360 - rmse: 0.4131\n",
      "Epoch 1078: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3610 - loss: 1.2370 - rmse: 0.4132 - val_accuracy: 0.4000 - val_loss: 1.3177 - val_rmse: 0.4253\n",
      "Epoch 1079/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4300 - loss: 1.2555 - rmse: 0.4149\n",
      "Epoch 1079: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4308 - loss: 1.2553 - rmse: 0.4148 - val_accuracy: 0.4500 - val_loss: 1.3057 - val_rmse: 0.4248\n",
      "Epoch 1080/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3936 - loss: 1.2682 - rmse: 0.4172\n",
      "Epoch 1080: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3911 - loss: 1.2670 - rmse: 0.4170 - val_accuracy: 0.4000 - val_loss: 1.3139 - val_rmse: 0.4275\n",
      "Epoch 1081/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4799 - loss: 1.2240 - rmse: 0.4092\n",
      "Epoch 1081: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4797 - loss: 1.2247 - rmse: 0.4093 - val_accuracy: 0.3500 - val_loss: 1.3071 - val_rmse: 0.4258\n",
      "Epoch 1082/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3735 - loss: 1.2651 - rmse: 0.4158\n",
      "Epoch 1082: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.3740 - loss: 1.2640 - rmse: 0.4156 - val_accuracy: 0.4000 - val_loss: 1.3077 - val_rmse: 0.4260\n",
      "Epoch 1083/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3892 - loss: 1.2331 - rmse: 0.4100\n",
      "Epoch 1083: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.3896 - loss: 1.2336 - rmse: 0.4101 - val_accuracy: 0.4500 - val_loss: 1.3020 - val_rmse: 0.4248\n",
      "Epoch 1084/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4526 - loss: 1.2320 - rmse: 0.4105\n",
      "Epoch 1084: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4498 - loss: 1.2335 - rmse: 0.4108 - val_accuracy: 0.4000 - val_loss: 1.3028 - val_rmse: 0.4246\n",
      "Epoch 1085/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4842 - loss: 1.2519 - rmse: 0.4158\n",
      "Epoch 1085: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4821 - loss: 1.2510 - rmse: 0.4156 - val_accuracy: 0.3500 - val_loss: 1.2985 - val_rmse: 0.4242\n",
      "Epoch 1086/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5444 - loss: 1.1987 - rmse: 0.4045\n",
      "Epoch 1086: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5405 - loss: 1.2006 - rmse: 0.4049 - val_accuracy: 0.4000 - val_loss: 1.2973 - val_rmse: 0.4231\n",
      "Epoch 1087/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4818 - loss: 1.2216 - rmse: 0.4084\n",
      "Epoch 1087: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.4757 - loss: 1.2235 - rmse: 0.4088 - val_accuracy: 0.4500 - val_loss: 1.2937 - val_rmse: 0.4227\n",
      "Epoch 1088/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4653 - loss: 1.2271 - rmse: 0.4093\n",
      "Epoch 1088: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4615 - loss: 1.2283 - rmse: 0.4096 - val_accuracy: 0.4500 - val_loss: 1.2968 - val_rmse: 0.4237\n",
      "Epoch 1089/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4705 - loss: 1.2278 - rmse: 0.4082\n",
      "Epoch 1089: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4692 - loss: 1.2283 - rmse: 0.4084 - val_accuracy: 0.4500 - val_loss: 1.2961 - val_rmse: 0.4241\n",
      "Epoch 1090/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4354 - loss: 1.2462 - rmse: 0.4138\n",
      "Epoch 1090: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4351 - loss: 1.2463 - rmse: 0.4138 - val_accuracy: 0.4000 - val_loss: 1.2960 - val_rmse: 0.4226\n",
      "Epoch 1091/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4037 - loss: 1.2301 - rmse: 0.4133\n",
      "Epoch 1091: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4033 - loss: 1.2306 - rmse: 0.4133 - val_accuracy: 0.3000 - val_loss: 1.3059 - val_rmse: 0.4238\n",
      "Epoch 1092/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3105 - loss: 1.2758 - rmse: 0.4183\n",
      "Epoch 1092: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3171 - loss: 1.2726 - rmse: 0.4178 - val_accuracy: 0.4000 - val_loss: 1.2958 - val_rmse: 0.4225\n",
      "Epoch 1093/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4820 - loss: 1.2237 - rmse: 0.4089\n",
      "Epoch 1093: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4811 - loss: 1.2236 - rmse: 0.4089 - val_accuracy: 0.4500 - val_loss: 1.2876 - val_rmse: 0.4223\n",
      "Epoch 1094/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5604 - loss: 1.1930 - rmse: 0.4044\n",
      "Epoch 1094: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5535 - loss: 1.1959 - rmse: 0.4049 - val_accuracy: 0.4500 - val_loss: 1.2871 - val_rmse: 0.4224\n",
      "Epoch 1095/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5096 - loss: 1.2168 - rmse: 0.4080\n",
      "Epoch 1095: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5091 - loss: 1.2178 - rmse: 0.4082 - val_accuracy: 0.4500 - val_loss: 1.2852 - val_rmse: 0.4224\n",
      "Epoch 1096/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4690 - loss: 1.2217 - rmse: 0.4093\n",
      "Epoch 1096: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4679 - loss: 1.2217 - rmse: 0.4093 - val_accuracy: 0.4000 - val_loss: 1.2891 - val_rmse: 0.4214\n",
      "Epoch 1097/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4955 - loss: 1.2349 - rmse: 0.4107\n",
      "Epoch 1097: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4953 - loss: 1.2346 - rmse: 0.4107 - val_accuracy: 0.5000 - val_loss: 1.2824 - val_rmse: 0.4218\n",
      "Epoch 1098/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4577 - loss: 1.2203 - rmse: 0.4099\n",
      "Epoch 1098: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4573 - loss: 1.2204 - rmse: 0.4099 - val_accuracy: 0.4000 - val_loss: 1.2805 - val_rmse: 0.4210\n",
      "Epoch 1099/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3921 - loss: 1.2206 - rmse: 0.4084\n",
      "Epoch 1099: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3934 - loss: 1.2213 - rmse: 0.4086 - val_accuracy: 0.4500 - val_loss: 1.2870 - val_rmse: 0.4239\n",
      "Epoch 1100/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4588 - loss: 1.2304 - rmse: 0.4096\n",
      "Epoch 1100: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4580 - loss: 1.2303 - rmse: 0.4096 - val_accuracy: 0.4500 - val_loss: 1.2844 - val_rmse: 0.4232\n",
      "Epoch 1101/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4039 - loss: 1.2306 - rmse: 0.4126\n",
      "Epoch 1101: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4040 - loss: 1.2300 - rmse: 0.4125 - val_accuracy: 0.4000 - val_loss: 1.3245 - val_rmse: 0.4274\n",
      "Epoch 1102/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4435 - loss: 1.2437 - rmse: 0.4142\n",
      "Epoch 1102: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4447 - loss: 1.2424 - rmse: 0.4140 - val_accuracy: 0.4000 - val_loss: 1.2915 - val_rmse: 0.4217\n",
      "Epoch 1103/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4296 - loss: 1.2364 - rmse: 0.4111\n",
      "Epoch 1103: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4300 - loss: 1.2355 - rmse: 0.4110 - val_accuracy: 0.4500 - val_loss: 1.2833 - val_rmse: 0.4235\n",
      "Epoch 1104/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4400 - loss: 1.2255 - rmse: 0.4104\n",
      "Epoch 1104: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.4400 - loss: 1.2253 - rmse: 0.4104 - val_accuracy: 0.2000 - val_loss: 1.2887 - val_rmse: 0.4244\n",
      "Epoch 1105/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4167 - loss: 1.2180 - rmse: 0.4105\n",
      "Epoch 1105: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4176 - loss: 1.2182 - rmse: 0.4105 - val_accuracy: 0.4000 - val_loss: 1.2754 - val_rmse: 0.4221\n",
      "Epoch 1106/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4375 - loss: 1.2196 - rmse: 0.4100\n",
      "Epoch 1106: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4382 - loss: 1.2193 - rmse: 0.4099 - val_accuracy: 0.5000 - val_loss: 1.2716 - val_rmse: 0.4214\n",
      "Epoch 1107/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4116 - loss: 1.2310 - rmse: 0.4127\n",
      "Epoch 1107: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4132 - loss: 1.2304 - rmse: 0.4126 - val_accuracy: 0.5000 - val_loss: 1.2650 - val_rmse: 0.4199\n",
      "Epoch 1108/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4300 - loss: 1.2276 - rmse: 0.4110\n",
      "Epoch 1108: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4321 - loss: 1.2261 - rmse: 0.4108 - val_accuracy: 0.4500 - val_loss: 1.2638 - val_rmse: 0.4194\n",
      "Epoch 1109/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4684 - loss: 1.2025 - rmse: 0.4060\n",
      "Epoch 1109: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4680 - loss: 1.2025 - rmse: 0.4060 - val_accuracy: 0.4500 - val_loss: 1.2592 - val_rmse: 0.4184\n",
      "Epoch 1110/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5492 - loss: 1.1903 - rmse: 0.4040\n",
      "Epoch 1110: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5433 - loss: 1.1916 - rmse: 0.4044 - val_accuracy: 0.5000 - val_loss: 1.2714 - val_rmse: 0.4228\n",
      "Epoch 1111/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4816 - loss: 1.1727 - rmse: 0.4035\n",
      "Epoch 1111: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4799 - loss: 1.1749 - rmse: 0.4037 - val_accuracy: 0.4000 - val_loss: 1.2711 - val_rmse: 0.4198\n",
      "Epoch 1112/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5103 - loss: 1.2006 - rmse: 0.4055\n",
      "Epoch 1112: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5109 - loss: 1.2002 - rmse: 0.4055 - val_accuracy: 0.4500 - val_loss: 1.2493 - val_rmse: 0.4175\n",
      "Epoch 1113/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3561 - loss: 1.2213 - rmse: 0.4101\n",
      "Epoch 1113: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3582 - loss: 1.2203 - rmse: 0.4100 - val_accuracy: 0.4000 - val_loss: 1.2599 - val_rmse: 0.4184\n",
      "Epoch 1114/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4770 - loss: 1.1695 - rmse: 0.3992\n",
      "Epoch 1114: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4767 - loss: 1.1699 - rmse: 0.3993 - val_accuracy: 0.3500 - val_loss: 1.2590 - val_rmse: 0.4207\n",
      "Epoch 1115/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4358 - loss: 1.1656 - rmse: 0.4026\n",
      "Epoch 1115: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4380 - loss: 1.1668 - rmse: 0.4027 - val_accuracy: 0.3500 - val_loss: 1.2805 - val_rmse: 0.4227\n",
      "Epoch 1116/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4894 - loss: 1.1818 - rmse: 0.4014\n",
      "Epoch 1116: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4855 - loss: 1.1822 - rmse: 0.4016 - val_accuracy: 0.5500 - val_loss: 1.2398 - val_rmse: 0.4164\n",
      "Epoch 1117/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5518 - loss: 1.1377 - rmse: 0.3961\n",
      "Epoch 1117: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5471 - loss: 1.1408 - rmse: 0.3966 - val_accuracy: 0.5000 - val_loss: 1.2359 - val_rmse: 0.4158\n",
      "Epoch 1118/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5772 - loss: 1.1432 - rmse: 0.3962\n",
      "Epoch 1118: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5700 - loss: 1.1472 - rmse: 0.3970 - val_accuracy: 0.5500 - val_loss: 1.2429 - val_rmse: 0.4180\n",
      "Epoch 1119/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4808 - loss: 1.1975 - rmse: 0.4081\n",
      "Epoch 1119: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4788 - loss: 1.1966 - rmse: 0.4078 - val_accuracy: 0.4500 - val_loss: 1.2334 - val_rmse: 0.4157\n",
      "Epoch 1120/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5147 - loss: 1.1938 - rmse: 0.4059\n",
      "Epoch 1120: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5137 - loss: 1.1933 - rmse: 0.4058 - val_accuracy: 0.4500 - val_loss: 1.2338 - val_rmse: 0.4137\n",
      "Epoch 1121/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4902 - loss: 1.2070 - rmse: 0.4059\n",
      "Epoch 1121: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4885 - loss: 1.2051 - rmse: 0.4057 - val_accuracy: 0.5000 - val_loss: 1.2292 - val_rmse: 0.4150\n",
      "Epoch 1122/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4373 - loss: 1.1746 - rmse: 0.4032\n",
      "Epoch 1122: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4373 - loss: 1.1747 - rmse: 0.4032 - val_accuracy: 0.4000 - val_loss: 1.2484 - val_rmse: 0.4159\n",
      "Epoch 1123/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4030 - loss: 1.2018 - rmse: 0.4079\n",
      "Epoch 1123: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4047 - loss: 1.2013 - rmse: 0.4078 - val_accuracy: 0.3000 - val_loss: 1.2532 - val_rmse: 0.4199\n",
      "Epoch 1124/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4249 - loss: 1.2282 - rmse: 0.4112\n",
      "Epoch 1124: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4258 - loss: 1.2273 - rmse: 0.4110 - val_accuracy: 0.4500 - val_loss: 1.2336 - val_rmse: 0.4166\n",
      "Epoch 1125/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5498 - loss: 1.1425 - rmse: 0.3975\n",
      "Epoch 1125: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5484 - loss: 1.1435 - rmse: 0.3977 - val_accuracy: 0.4000 - val_loss: 1.2523 - val_rmse: 0.4191\n",
      "Epoch 1126/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4038 - loss: 1.2275 - rmse: 0.4102\n",
      "Epoch 1126: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4036 - loss: 1.2273 - rmse: 0.4102 - val_accuracy: 0.2000 - val_loss: 1.2696 - val_rmse: 0.4229\n",
      "Epoch 1127/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4659 - loss: 1.1751 - rmse: 0.4049\n",
      "Epoch 1127: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4647 - loss: 1.1757 - rmse: 0.4049 - val_accuracy: 0.4000 - val_loss: 1.2152 - val_rmse: 0.4128\n",
      "Epoch 1128/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5616 - loss: 1.1356 - rmse: 0.3947\n",
      "Epoch 1128: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5587 - loss: 1.1368 - rmse: 0.3949 - val_accuracy: 0.5500 - val_loss: 1.2222 - val_rmse: 0.4150\n",
      "Epoch 1129/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5017 - loss: 1.1838 - rmse: 0.4053\n",
      "Epoch 1129: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5020 - loss: 1.1833 - rmse: 0.4053 - val_accuracy: 0.5000 - val_loss: 1.2045 - val_rmse: 0.4114\n",
      "Epoch 1130/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4643 - loss: 1.1557 - rmse: 0.3996\n",
      "Epoch 1130: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4636 - loss: 1.1573 - rmse: 0.3998 - val_accuracy: 0.4500 - val_loss: 1.2107 - val_rmse: 0.4115\n",
      "Epoch 1131/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5319 - loss: 1.1339 - rmse: 0.3979\n",
      "Epoch 1131: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5299 - loss: 1.1350 - rmse: 0.3981 - val_accuracy: 0.4500 - val_loss: 1.2016 - val_rmse: 0.4133\n",
      "Epoch 1132/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5348 - loss: 1.1469 - rmse: 0.3980\n",
      "Epoch 1132: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5311 - loss: 1.1479 - rmse: 0.3982 - val_accuracy: 0.4500 - val_loss: 1.2031 - val_rmse: 0.4109\n",
      "Epoch 1133/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.3631 - loss: 1.2096 - rmse: 0.4095\n",
      "Epoch 1133: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3681 - loss: 1.2063 - rmse: 0.4089 - val_accuracy: 0.4500 - val_loss: 1.2218 - val_rmse: 0.4124\n",
      "Epoch 1134/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.3665 - loss: 1.2046 - rmse: 0.4098\n",
      "Epoch 1134: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.3682 - loss: 1.2040 - rmse: 0.4097 - val_accuracy: 0.5000 - val_loss: 1.1949 - val_rmse: 0.4080\n",
      "Epoch 1135/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4356 - loss: 1.1870 - rmse: 0.4058\n",
      "Epoch 1135: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4362 - loss: 1.1868 - rmse: 0.4058 - val_accuracy: 0.5500 - val_loss: 1.1919 - val_rmse: 0.4081\n",
      "Epoch 1136/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4886 - loss: 1.1179 - rmse: 0.3925\n",
      "Epoch 1136: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4880 - loss: 1.1217 - rmse: 0.3933 - val_accuracy: 0.4000 - val_loss: 1.2095 - val_rmse: 0.4132\n",
      "Epoch 1137/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4371 - loss: 1.2294 - rmse: 0.4084\n",
      "Epoch 1137: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4382 - loss: 1.2308 - rmse: 0.4083 - val_accuracy: 0.5000 - val_loss: 1.1868 - val_rmse: 0.4081\n",
      "Epoch 1138/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4873 - loss: 1.2016 - rmse: 0.4044\n",
      "Epoch 1138: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4876 - loss: 1.2020 - rmse: 0.4043 - val_accuracy: 0.5500 - val_loss: 1.1926 - val_rmse: 0.4096\n",
      "Epoch 1139/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4523 - loss: 1.1956 - rmse: 0.4026\n",
      "Epoch 1139: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4517 - loss: 1.1968 - rmse: 0.4027 - val_accuracy: 0.5000 - val_loss: 1.2191 - val_rmse: 0.4145\n",
      "Epoch 1140/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4875 - loss: 1.1645 - rmse: 0.3966\n",
      "Epoch 1140: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4861 - loss: 1.1662 - rmse: 0.3968 - val_accuracy: 0.5000 - val_loss: 1.1406 - val_rmse: 0.4004\n",
      "Epoch 1141/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4956 - loss: 1.1791 - rmse: 0.4018\n",
      "Epoch 1141: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4978 - loss: 1.1795 - rmse: 0.4018 - val_accuracy: 0.4500 - val_loss: 1.1724 - val_rmse: 0.4059\n",
      "Epoch 1142/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5159 - loss: 1.1152 - rmse: 0.3861\n",
      "Epoch 1142: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5147 - loss: 1.1165 - rmse: 0.3865 - val_accuracy: 0.5500 - val_loss: 1.1609 - val_rmse: 0.4030\n",
      "Epoch 1143/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4864 - loss: 1.1945 - rmse: 0.4044\n",
      "Epoch 1143: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4870 - loss: 1.1927 - rmse: 0.4040 - val_accuracy: 0.5000 - val_loss: 1.0930 - val_rmse: 0.3934\n",
      "Epoch 1144/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4936 - loss: 1.1417 - rmse: 0.3957\n",
      "Epoch 1144: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4930 - loss: 1.1424 - rmse: 0.3959 - val_accuracy: 0.5500 - val_loss: 1.1649 - val_rmse: 0.4045\n",
      "Epoch 1145/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5490 - loss: 1.0657 - rmse: 0.3863\n",
      "Epoch 1145: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5428 - loss: 1.0698 - rmse: 0.3869 - val_accuracy: 0.5500 - val_loss: 1.1235 - val_rmse: 0.3985\n",
      "Epoch 1146/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5258 - loss: 1.0841 - rmse: 0.3880\n",
      "Epoch 1146: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5250 - loss: 1.0846 - rmse: 0.3881 - val_accuracy: 0.6000 - val_loss: 1.0695 - val_rmse: 0.3881\n",
      "Epoch 1147/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5194 - loss: 1.0614 - rmse: 0.3811\n",
      "Epoch 1147: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5198 - loss: 1.0617 - rmse: 0.3812 - val_accuracy: 0.6000 - val_loss: 1.0750 - val_rmse: 0.3888\n",
      "Epoch 1148/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5488 - loss: 1.0526 - rmse: 0.3806\n",
      "Epoch 1148: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5477 - loss: 1.0541 - rmse: 0.3810 - val_accuracy: 0.6000 - val_loss: 1.0532 - val_rmse: 0.3864\n",
      "Epoch 1149/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6048 - loss: 1.0237 - rmse: 0.3758\n",
      "Epoch 1149: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6028 - loss: 1.0254 - rmse: 0.3761 - val_accuracy: 0.4500 - val_loss: 1.0594 - val_rmse: 0.3879\n",
      "Epoch 1150/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4680 - loss: 1.0850 - rmse: 0.3863\n",
      "Epoch 1150: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.4676 - loss: 1.0861 - rmse: 0.3865 - val_accuracy: 0.3500 - val_loss: 1.1656 - val_rmse: 0.4023\n",
      "Epoch 1151/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4886 - loss: 1.1067 - rmse: 0.3907\n",
      "Epoch 1151: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4885 - loss: 1.1077 - rmse: 0.3909 - val_accuracy: 0.4500 - val_loss: 1.0923 - val_rmse: 0.3931\n",
      "Epoch 1152/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5430 - loss: 1.0537 - rmse: 0.3825\n",
      "Epoch 1152: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5396 - loss: 1.0548 - rmse: 0.3828 - val_accuracy: 0.4000 - val_loss: 1.0891 - val_rmse: 0.3941\n",
      "Epoch 1153/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5208 - loss: 1.0632 - rmse: 0.3878\n",
      "Epoch 1153: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5219 - loss: 1.0625 - rmse: 0.3875 - val_accuracy: 0.5500 - val_loss: 1.0702 - val_rmse: 0.3922\n",
      "Epoch 1154/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4807 - loss: 3.7637 - rmse: 0.4131\n",
      "Epoch 1154: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4772 - loss: 4.0228 - rmse: 0.4168 - val_accuracy: 0.3000 - val_loss: 3.5611 - val_rmse: 0.5486\n",
      "Epoch 1155/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2443 - loss: 3.3412 - rmse: 0.5375\n",
      "Epoch 1155: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.2450 - loss: 3.3299 - rmse: 0.5369 - val_accuracy: 0.2500 - val_loss: 3.9732 - val_rmse: 0.5445\n",
      "Epoch 1156/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4092 - loss: 2.4908 - rmse: 0.4768\n",
      "Epoch 1156: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4077 - loss: 2.4703 - rmse: 0.4768 - val_accuracy: 0.3000 - val_loss: 1.6967 - val_rmse: 0.4807\n",
      "Epoch 1157/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2815 - loss: 1.8350 - rmse: 0.4734\n",
      "Epoch 1157: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2828 - loss: 1.8304 - rmse: 0.4731 - val_accuracy: 0.3000 - val_loss: 1.4825 - val_rmse: 0.4508\n",
      "Epoch 1158/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4978 - loss: 1.2159 - rmse: 0.4042\n",
      "Epoch 1158: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4960 - loss: 1.2191 - rmse: 0.4047 - val_accuracy: 0.3500 - val_loss: 1.2892 - val_rmse: 0.4214\n",
      "Epoch 1159/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3431 - loss: 1.5496 - rmse: 0.4513\n",
      "Epoch 1159: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3441 - loss: 1.5482 - rmse: 0.4512 - val_accuracy: 0.3500 - val_loss: 1.5622 - val_rmse: 0.4610\n",
      "Epoch 1160/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5293 - loss: 1.2556 - rmse: 0.4201\n",
      "Epoch 1160: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5274 - loss: 1.2537 - rmse: 0.4197 - val_accuracy: 0.3500 - val_loss: 1.3621 - val_rmse: 0.4292\n",
      "Epoch 1161/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4692 - loss: 1.1894 - rmse: 0.4033\n",
      "Epoch 1161: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4695 - loss: 1.1911 - rmse: 0.4035 - val_accuracy: 0.2500 - val_loss: 2.3675 - val_rmse: 0.4995\n",
      "Epoch 1162/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3287 - loss: 2.5775 - rmse: 0.4961\n",
      "Epoch 1162: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.3278 - loss: 2.5695 - rmse: 0.4959 - val_accuracy: 0.3500 - val_loss: 1.9677 - val_rmse: 0.4908\n",
      "Epoch 1163/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2831 - loss: 2.2839 - rmse: 0.5013\n",
      "Epoch 1163: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.2828 - loss: 2.2795 - rmse: 0.5009 - val_accuracy: 0.2000 - val_loss: 1.5128 - val_rmse: 0.4568\n",
      "Epoch 1164/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4818 - loss: 1.2810 - rmse: 0.4121\n",
      "Epoch 1164: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.4791 - loss: 1.2850 - rmse: 0.4128 - val_accuracy: 0.2500 - val_loss: 1.4811 - val_rmse: 0.4439\n",
      "Epoch 1165/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3366 - loss: 1.5391 - rmse: 0.4458\n",
      "Epoch 1165: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3357 - loss: 1.5494 - rmse: 0.4464 - val_accuracy: 0.1500 - val_loss: 2.3935 - val_rmse: 0.5091\n",
      "Epoch 1166/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3122 - loss: 1.6789 - rmse: 0.4509\n",
      "Epoch 1166: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3145 - loss: 1.6659 - rmse: 0.4499 - val_accuracy: 0.2000 - val_loss: 1.4309 - val_rmse: 0.4408\n",
      "Epoch 1167/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3503 - loss: 1.3626 - rmse: 0.4282\n",
      "Epoch 1167: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3537 - loss: 1.3678 - rmse: 0.4285 - val_accuracy: 0.3000 - val_loss: 2.4174 - val_rmse: 0.4968\n",
      "Epoch 1168/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2488 - loss: 2.2529 - rmse: 0.4943\n",
      "Epoch 1168: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.2498 - loss: 2.2444 - rmse: 0.4940 - val_accuracy: 0.2000 - val_loss: 1.9039 - val_rmse: 0.4833\n",
      "Epoch 1169/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2412 - loss: 1.9015 - rmse: 0.4787\n",
      "Epoch 1169: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.2409 - loss: 1.8981 - rmse: 0.4788 - val_accuracy: 0.1000 - val_loss: 1.7474 - val_rmse: 0.4741\n",
      "Epoch 1170/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2892 - loss: 1.6229 - rmse: 0.4569\n",
      "Epoch 1170: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.2895 - loss: 1.6212 - rmse: 0.4568 - val_accuracy: 0.5500 - val_loss: 1.2146 - val_rmse: 0.4031\n",
      "Epoch 1171/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3776 - loss: 1.3690 - rmse: 0.4305\n",
      "Epoch 1171: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.3762 - loss: 1.3692 - rmse: 0.4306 - val_accuracy: 0.2000 - val_loss: 1.4532 - val_rmse: 0.4496\n",
      "Epoch 1172/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2452 - loss: 1.4720 - rmse: 0.4506\n",
      "Epoch 1172: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.2444 - loss: 1.4712 - rmse: 0.4505 - val_accuracy: 0.1000 - val_loss: 1.4588 - val_rmse: 0.4490\n",
      "Epoch 1173/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3187 - loss: 1.3302 - rmse: 0.4329\n",
      "Epoch 1173: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3144 - loss: 1.3327 - rmse: 0.4330 - val_accuracy: 0.2000 - val_loss: 1.8979 - val_rmse: 0.4925\n",
      "Epoch 1174/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2796 - loss: 1.6859 - rmse: 0.4790\n",
      "Epoch 1174: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.2831 - loss: 1.6856 - rmse: 0.4784 - val_accuracy: 0.2500 - val_loss: 1.7227 - val_rmse: 0.4702\n",
      "Epoch 1175/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1508 - loss: 1.7474 - rmse: 0.4678\n",
      "Epoch 1175: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.1506 - loss: 1.7467 - rmse: 0.4676 - val_accuracy: 0.3000 - val_loss: 1.2886 - val_rmse: 0.4274\n",
      "Epoch 1176/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2638 - loss: 1.5175 - rmse: 0.4426\n",
      "Epoch 1176: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2636 - loss: 1.5204 - rmse: 0.4430 - val_accuracy: 0.3000 - val_loss: 1.5010 - val_rmse: 0.4482\n",
      "Epoch 1177/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4755 - loss: 1.2612 - rmse: 0.4139\n",
      "Epoch 1177: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4739 - loss: 1.2629 - rmse: 0.4141 - val_accuracy: 0.4500 - val_loss: 1.3826 - val_rmse: 0.4280\n",
      "Epoch 1178/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4337 - loss: 1.2027 - rmse: 0.4095\n",
      "Epoch 1178: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4316 - loss: 1.2077 - rmse: 0.4100 - val_accuracy: 0.4500 - val_loss: 1.3354 - val_rmse: 0.4204\n",
      "Epoch 1179/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4527 - loss: 1.5112 - rmse: 0.4307\n",
      "Epoch 1179: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4433 - loss: 1.5133 - rmse: 0.4317 - val_accuracy: 0.2500 - val_loss: 1.4868 - val_rmse: 0.4553\n",
      "Epoch 1180/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3332 - loss: 1.4377 - rmse: 0.4400\n",
      "Epoch 1180: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3362 - loss: 1.4331 - rmse: 0.4393 - val_accuracy: 0.4000 - val_loss: 1.3813 - val_rmse: 0.4281\n",
      "Epoch 1181/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4162 - loss: 1.3061 - rmse: 0.4180\n",
      "Epoch 1181: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4131 - loss: 1.3061 - rmse: 0.4182 - val_accuracy: 0.2000 - val_loss: 1.3398 - val_rmse: 0.4319\n",
      "Epoch 1182/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3557 - loss: 1.3035 - rmse: 0.4227\n",
      "Epoch 1182: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3552 - loss: 1.3059 - rmse: 0.4230 - val_accuracy: 0.2500 - val_loss: 1.3756 - val_rmse: 0.4386\n",
      "Epoch 1183/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3795 - loss: 1.3475 - rmse: 0.4283\n",
      "Epoch 1183: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3788 - loss: 1.3452 - rmse: 0.4280 - val_accuracy: 0.2000 - val_loss: 1.4701 - val_rmse: 0.4474\n",
      "Epoch 1184/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3404 - loss: 1.2166 - rmse: 0.4075\n",
      "Epoch 1184: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3444 - loss: 1.2193 - rmse: 0.4079 - val_accuracy: 0.3500 - val_loss: 1.4341 - val_rmse: 0.4415\n",
      "Epoch 1185/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4734 - loss: 1.1748 - rmse: 0.4031\n",
      "Epoch 1185: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4730 - loss: 1.1760 - rmse: 0.4033 - val_accuracy: 0.4000 - val_loss: 1.2955 - val_rmse: 0.4212\n",
      "Epoch 1186/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4657 - loss: 1.1853 - rmse: 0.4003\n",
      "Epoch 1186: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4638 - loss: 1.1891 - rmse: 0.4009 - val_accuracy: 0.2500 - val_loss: 1.4323 - val_rmse: 0.4465\n",
      "Epoch 1187/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2905 - loss: 1.3506 - rmse: 0.4295\n",
      "Epoch 1187: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.2884 - loss: 1.3529 - rmse: 0.4298 - val_accuracy: 0.3000 - val_loss: 1.2716 - val_rmse: 0.4206\n",
      "Epoch 1188/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.3827 - loss: 1.3342 - rmse: 0.4271\n",
      "Epoch 1188: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3782 - loss: 1.3361 - rmse: 0.4274 - val_accuracy: 0.3500 - val_loss: 1.4758 - val_rmse: 0.4352\n",
      "Epoch 1189/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2283 - loss: 1.4568 - rmse: 0.4459\n",
      "Epoch 1189: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.2339 - loss: 1.4523 - rmse: 0.4451 - val_accuracy: 0.3500 - val_loss: 1.3198 - val_rmse: 0.4277\n",
      "Epoch 1190/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2904 - loss: 1.3847 - rmse: 0.4364\n",
      "Epoch 1190: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.2923 - loss: 1.3836 - rmse: 0.4362 - val_accuracy: 0.4500 - val_loss: 1.2036 - val_rmse: 0.4081\n",
      "Epoch 1191/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.3874 - loss: 1.2599 - rmse: 0.4168\n",
      "Epoch 1191: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.3880 - loss: 1.2602 - rmse: 0.4168 - val_accuracy: 0.4500 - val_loss: 1.1848 - val_rmse: 0.4047\n",
      "Epoch 1192/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.3914 - loss: 1.2517 - rmse: 0.4148\n",
      "Epoch 1192: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.3909 - loss: 1.2522 - rmse: 0.4149 - val_accuracy: 0.4500 - val_loss: 1.2285 - val_rmse: 0.4134\n",
      "Epoch 1193/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.3951 - loss: 1.2503 - rmse: 0.4115\n",
      "Epoch 1193: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.3954 - loss: 1.2494 - rmse: 0.4114 - val_accuracy: 0.2500 - val_loss: 1.3572 - val_rmse: 0.4310\n",
      "Epoch 1194/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3968 - loss: 1.3282 - rmse: 0.4222\n",
      "Epoch 1194: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4001 - loss: 1.3235 - rmse: 0.4215 - val_accuracy: 0.5000 - val_loss: 1.1951 - val_rmse: 0.4084\n",
      "Epoch 1195/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5059 - loss: 1.1307 - rmse: 0.3921\n",
      "Epoch 1195: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5003 - loss: 1.1378 - rmse: 0.3933 - val_accuracy: 0.4000 - val_loss: 1.3801 - val_rmse: 0.4317\n",
      "Epoch 1196/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.3158 - loss: 1.2954 - rmse: 0.4240\n",
      "Epoch 1196: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3168 - loss: 1.2964 - rmse: 0.4240 - val_accuracy: 0.4000 - val_loss: 1.2555 - val_rmse: 0.4214\n",
      "Epoch 1197/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4265 - loss: 1.5436 - rmse: 0.4340\n",
      "Epoch 1197: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4262 - loss: 1.5420 - rmse: 0.4338 - val_accuracy: 0.4500 - val_loss: 1.3131 - val_rmse: 0.4236\n",
      "Epoch 1198/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4460 - loss: 1.3035 - rmse: 0.4192\n",
      "Epoch 1198: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4469 - loss: 1.3019 - rmse: 0.4190 - val_accuracy: 0.4000 - val_loss: 1.3251 - val_rmse: 0.4256\n",
      "Epoch 1199/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5481 - loss: 1.2103 - rmse: 0.4045\n",
      "Epoch 1199: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5470 - loss: 1.2101 - rmse: 0.4045 - val_accuracy: 0.3500 - val_loss: 1.6450 - val_rmse: 0.4653\n",
      "Epoch 1200/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2940 - loss: 1.4643 - rmse: 0.4405\n",
      "Epoch 1200: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.2957 - loss: 1.4600 - rmse: 0.4401 - val_accuracy: 0.4500 - val_loss: 1.3107 - val_rmse: 0.4185\n",
      "Epoch 1201/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3182 - loss: 1.5482 - rmse: 0.4396\n",
      "Epoch 1201: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.3156 - loss: 1.5527 - rmse: 0.4400 - val_accuracy: 0.3500 - val_loss: 1.4992 - val_rmse: 0.4494\n",
      "Epoch 1202/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6480 - loss: 1.1891 - rmse: 0.3976\n",
      "Epoch 1202: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6472 - loss: 1.1907 - rmse: 0.3978 - val_accuracy: 0.4000 - val_loss: 1.3523 - val_rmse: 0.4333\n",
      "Epoch 1203/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5528 - loss: 1.2531 - rmse: 0.4103\n",
      "Epoch 1203: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5522 - loss: 1.2530 - rmse: 0.4102 - val_accuracy: 0.3500 - val_loss: 1.4142 - val_rmse: 0.4348\n",
      "Epoch 1204/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.3785 - loss: 1.3424 - rmse: 0.4291\n",
      "Epoch 1204: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.3790 - loss: 1.3413 - rmse: 0.4289 - val_accuracy: 0.4000 - val_loss: 1.2088 - val_rmse: 0.4095\n",
      "Epoch 1205/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4467 - loss: 1.1976 - rmse: 0.4041\n",
      "Epoch 1205: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.4474 - loss: 1.1971 - rmse: 0.4041 - val_accuracy: 0.4500 - val_loss: 1.1957 - val_rmse: 0.4085\n",
      "Epoch 1206/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4502 - loss: 1.2043 - rmse: 0.4074\n",
      "Epoch 1206: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4486 - loss: 1.2063 - rmse: 0.4077 - val_accuracy: 0.3000 - val_loss: 1.3593 - val_rmse: 0.4289\n",
      "Epoch 1207/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4952 - loss: 1.3677 - rmse: 0.4227\n",
      "Epoch 1207: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4944 - loss: 1.3638 - rmse: 0.4222 - val_accuracy: 0.3000 - val_loss: 1.2125 - val_rmse: 0.4118\n",
      "Epoch 1208/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4199 - loss: 1.2495 - rmse: 0.4144\n",
      "Epoch 1208: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.4187 - loss: 1.2523 - rmse: 0.4147 - val_accuracy: 0.2500 - val_loss: 1.5043 - val_rmse: 0.4498\n",
      "Epoch 1209/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.2901 - loss: 1.5373 - rmse: 0.4578\n",
      "Epoch 1209: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.2922 - loss: 1.5340 - rmse: 0.4573 - val_accuracy: 0.2500 - val_loss: 1.4233 - val_rmse: 0.4419\n",
      "Epoch 1210/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5486 - loss: 1.1593 - rmse: 0.3939\n",
      "Epoch 1210: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5471 - loss: 1.1607 - rmse: 0.3940 - val_accuracy: 0.2500 - val_loss: 1.3726 - val_rmse: 0.4381\n",
      "Epoch 1211/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5199 - loss: 1.1836 - rmse: 0.4003\n",
      "Epoch 1211: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5208 - loss: 1.1827 - rmse: 0.4001 - val_accuracy: 0.2500 - val_loss: 1.4270 - val_rmse: 0.4457\n",
      "Epoch 1212/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5665 - loss: 1.2285 - rmse: 0.4035\n",
      "Epoch 1212: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5681 - loss: 1.2258 - rmse: 0.4032 - val_accuracy: 0.3000 - val_loss: 1.3595 - val_rmse: 0.4398\n",
      "Epoch 1213/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5791 - loss: 1.1571 - rmse: 0.3952\n",
      "Epoch 1213: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5775 - loss: 1.1562 - rmse: 0.3951 - val_accuracy: 0.2500 - val_loss: 1.3630 - val_rmse: 0.4397\n",
      "Epoch 1214/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5340 - loss: 1.0875 - rmse: 0.3848\n",
      "Epoch 1214: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5349 - loss: 1.0892 - rmse: 0.3850 - val_accuracy: 0.4000 - val_loss: 1.3092 - val_rmse: 0.4305\n",
      "Epoch 1215/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6059 - loss: 1.1492 - rmse: 0.3955\n",
      "Epoch 1215: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6054 - loss: 1.1481 - rmse: 0.3953 - val_accuracy: 0.2500 - val_loss: 1.3765 - val_rmse: 0.4428\n",
      "Epoch 1216/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5502 - loss: 1.0885 - rmse: 0.3846\n",
      "Epoch 1216: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5505 - loss: 1.0899 - rmse: 0.3849 - val_accuracy: 0.2500 - val_loss: 1.3882 - val_rmse: 0.4455\n",
      "Epoch 1217/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5841 - loss: 1.0786 - rmse: 0.3808\n",
      "Epoch 1217: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5814 - loss: 1.0801 - rmse: 0.3811 - val_accuracy: 0.3000 - val_loss: 1.3289 - val_rmse: 0.4353\n",
      "Epoch 1218/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5164 - loss: 1.1388 - rmse: 0.3935\n",
      "Epoch 1218: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5202 - loss: 1.1357 - rmse: 0.3930 - val_accuracy: 0.3000 - val_loss: 1.3220 - val_rmse: 0.4321\n",
      "Epoch 1219/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6099 - loss: 1.0125 - rmse: 0.3689\n",
      "Epoch 1219: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6086 - loss: 1.0143 - rmse: 0.3692 - val_accuracy: 0.4000 - val_loss: 1.3183 - val_rmse: 0.4339\n",
      "Epoch 1220/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5101 - loss: 1.1770 - rmse: 0.4034\n",
      "Epoch 1220: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5103 - loss: 1.1756 - rmse: 0.4031 - val_accuracy: 0.3000 - val_loss: 1.3246 - val_rmse: 0.4307\n",
      "Epoch 1221/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6051 - loss: 1.0180 - rmse: 0.3688\n",
      "Epoch 1221: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6017 - loss: 1.0221 - rmse: 0.3697 - val_accuracy: 0.3000 - val_loss: 1.3373 - val_rmse: 0.4359\n",
      "Epoch 1222/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6158 - loss: 1.0943 - rmse: 0.3863\n",
      "Epoch 1222: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6144 - loss: 1.0953 - rmse: 0.3865 - val_accuracy: 0.2500 - val_loss: 1.5558 - val_rmse: 0.4601\n",
      "Epoch 1223/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4589 - loss: 1.2033 - rmse: 0.4069\n",
      "Epoch 1223: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4549 - loss: 1.2139 - rmse: 0.4081 - val_accuracy: 0.3000 - val_loss: 2.3143 - val_rmse: 0.4897\n",
      "Epoch 1224/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4058 - loss: 1.4790 - rmse: 0.4312\n",
      "Epoch 1224: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4008 - loss: 1.4833 - rmse: 0.4320 - val_accuracy: 0.1500 - val_loss: 1.6542 - val_rmse: 0.4627\n",
      "Epoch 1225/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3319 - loss: 1.4393 - rmse: 0.4408\n",
      "Epoch 1225: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3342 - loss: 1.4366 - rmse: 0.4406 - val_accuracy: 0.2500 - val_loss: 1.6327 - val_rmse: 0.4745\n",
      "Epoch 1226/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2284 - loss: 1.6012 - rmse: 0.4724\n",
      "Epoch 1226: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.2307 - loss: 1.5966 - rmse: 0.4717 - val_accuracy: 0.3500 - val_loss: 1.4838 - val_rmse: 0.4467\n",
      "Epoch 1227/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2354 - loss: 1.5552 - rmse: 0.4556\n",
      "Epoch 1227: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.2392 - loss: 1.5492 - rmse: 0.4548 - val_accuracy: 0.3500 - val_loss: 1.4614 - val_rmse: 0.4380\n",
      "Epoch 1228/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3200 - loss: 1.3931 - rmse: 0.4333\n",
      "Epoch 1228: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3213 - loss: 1.3912 - rmse: 0.4330 - val_accuracy: 0.3500 - val_loss: 1.3551 - val_rmse: 0.4252\n",
      "Epoch 1229/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5067 - loss: 1.2916 - rmse: 0.4120\n",
      "Epoch 1229: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5001 - loss: 1.2887 - rmse: 0.4121 - val_accuracy: 0.2500 - val_loss: 1.4476 - val_rmse: 0.4406\n",
      "Epoch 1230/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4542 - loss: 1.2868 - rmse: 0.4141\n",
      "Epoch 1230: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4548 - loss: 1.2844 - rmse: 0.4139 - val_accuracy: 0.2000 - val_loss: 1.6646 - val_rmse: 0.4502\n",
      "Epoch 1231/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3259 - loss: 1.4319 - rmse: 0.4340\n",
      "Epoch 1231: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3249 - loss: 1.4341 - rmse: 0.4344 - val_accuracy: 0.2500 - val_loss: 1.6440 - val_rmse: 0.4626\n",
      "Epoch 1232/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2020 - loss: 1.5339 - rmse: 0.4576\n",
      "Epoch 1232: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2043 - loss: 1.5354 - rmse: 0.4575 - val_accuracy: 0.2500 - val_loss: 1.4197 - val_rmse: 0.4389\n",
      "Epoch 1233/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1778 - loss: 1.5260 - rmse: 0.4557\n",
      "Epoch 1233: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1831 - loss: 1.5282 - rmse: 0.4558 - val_accuracy: 0.4500 - val_loss: 1.5147 - val_rmse: 0.4439\n",
      "Epoch 1234/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3277 - loss: 1.3879 - rmse: 0.4369\n",
      "Epoch 1234: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3274 - loss: 1.3876 - rmse: 0.4369 - val_accuracy: 0.3000 - val_loss: 1.3679 - val_rmse: 0.4316\n",
      "Epoch 1235/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3524 - loss: 1.3492 - rmse: 0.4285\n",
      "Epoch 1235: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3540 - loss: 1.3518 - rmse: 0.4289 - val_accuracy: 0.4000 - val_loss: 1.4328 - val_rmse: 0.4281\n",
      "Epoch 1236/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3150 - loss: 1.5540 - rmse: 0.4536\n",
      "Epoch 1236: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3181 - loss: 1.5521 - rmse: 0.4532 - val_accuracy: 0.4500 - val_loss: 1.3716 - val_rmse: 0.4244\n",
      "Epoch 1237/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4050 - loss: 1.4314 - rmse: 0.4307\n",
      "Epoch 1237: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4023 - loss: 1.4296 - rmse: 0.4310 - val_accuracy: 0.3500 - val_loss: 1.4005 - val_rmse: 0.4299\n",
      "Epoch 1238/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3435 - loss: 1.3401 - rmse: 0.4268\n",
      "Epoch 1238: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3456 - loss: 1.3388 - rmse: 0.4266 - val_accuracy: 0.5000 - val_loss: 1.2706 - val_rmse: 0.4144\n",
      "Epoch 1239/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4643 - loss: 1.2959 - rmse: 0.4161\n",
      "Epoch 1239: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4602 - loss: 1.3011 - rmse: 0.4170 - val_accuracy: 0.3000 - val_loss: 1.4663 - val_rmse: 0.4445\n",
      "Epoch 1240/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3690 - loss: 1.4070 - rmse: 0.4325\n",
      "Epoch 1240: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3693 - loss: 1.4033 - rmse: 0.4321 - val_accuracy: 0.5000 - val_loss: 1.3353 - val_rmse: 0.4307\n",
      "Epoch 1241/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4252 - loss: 1.2446 - rmse: 0.4127\n",
      "Epoch 1241: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4255 - loss: 1.2444 - rmse: 0.4126 - val_accuracy: 0.5000 - val_loss: 1.2941 - val_rmse: 0.4234\n",
      "Epoch 1242/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5433 - loss: 1.1347 - rmse: 0.3938\n",
      "Epoch 1242: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5436 - loss: 1.1365 - rmse: 0.3939 - val_accuracy: 0.3000 - val_loss: 1.3402 - val_rmse: 0.4335\n",
      "Epoch 1243/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5478 - loss: 1.1400 - rmse: 0.3930\n",
      "Epoch 1243: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5479 - loss: 1.1409 - rmse: 0.3930 - val_accuracy: 0.4500 - val_loss: 1.2995 - val_rmse: 0.4264\n",
      "Epoch 1244/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5793 - loss: 1.1251 - rmse: 0.3893\n",
      "Epoch 1244: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5776 - loss: 1.1270 - rmse: 0.3895 - val_accuracy: 0.3500 - val_loss: 1.3773 - val_rmse: 0.4351\n",
      "Epoch 1245/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5293 - loss: 1.1580 - rmse: 0.3951\n",
      "Epoch 1245: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5304 - loss: 1.1567 - rmse: 0.3949 - val_accuracy: 0.4500 - val_loss: 1.2712 - val_rmse: 0.4185\n",
      "Epoch 1246/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5977 - loss: 1.0608 - rmse: 0.3754\n",
      "Epoch 1246: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5977 - loss: 1.0613 - rmse: 0.3755 - val_accuracy: 0.4000 - val_loss: 1.3087 - val_rmse: 0.4301\n",
      "Epoch 1247/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6151 - loss: 1.0755 - rmse: 0.3816\n",
      "Epoch 1247: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6152 - loss: 1.0753 - rmse: 0.3815 - val_accuracy: 0.4500 - val_loss: 1.3579 - val_rmse: 0.4307\n",
      "Epoch 1248/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5936 - loss: 1.1087 - rmse: 0.3862\n",
      "Epoch 1248: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5950 - loss: 1.1073 - rmse: 0.3859 - val_accuracy: 0.4500 - val_loss: 1.3435 - val_rmse: 0.4343\n",
      "Epoch 1249/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5266 - loss: 1.1394 - rmse: 0.3885\n",
      "Epoch 1249: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5320 - loss: 1.1336 - rmse: 0.3878 - val_accuracy: 0.5000 - val_loss: 1.3959 - val_rmse: 0.4366\n",
      "Epoch 1250/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6535 - loss: 1.0262 - rmse: 0.3723\n",
      "Epoch 1250: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6531 - loss: 1.0263 - rmse: 0.3723 - val_accuracy: 0.4500 - val_loss: 1.4190 - val_rmse: 0.4397\n",
      "Epoch 1251/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5616 - loss: 1.0785 - rmse: 0.3852\n",
      "Epoch 1251: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5639 - loss: 1.0760 - rmse: 0.3846 - val_accuracy: 0.4000 - val_loss: 1.3527 - val_rmse: 0.4370\n",
      "Epoch 1252/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6082 - loss: 1.0874 - rmse: 0.3802\n",
      "Epoch 1252: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6060 - loss: 1.0890 - rmse: 0.3806 - val_accuracy: 0.4000 - val_loss: 1.5493 - val_rmse: 0.4636\n",
      "Epoch 1253/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2027 - loss: 1.5786 - rmse: 0.4692\n",
      "Epoch 1253: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.2116 - loss: 1.5674 - rmse: 0.4672 - val_accuracy: 0.4500 - val_loss: 1.4269 - val_rmse: 0.4365\n",
      "Epoch 1254/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4914 - loss: 1.2105 - rmse: 0.4033\n",
      "Epoch 1254: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4941 - loss: 1.2055 - rmse: 0.4025 - val_accuracy: 0.4500 - val_loss: 1.3282 - val_rmse: 0.4251\n",
      "Epoch 1255/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6690 - loss: 1.0015 - rmse: 0.3636\n",
      "Epoch 1255: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6688 - loss: 1.0018 - rmse: 0.3637 - val_accuracy: 0.5000 - val_loss: 1.3270 - val_rmse: 0.4263\n",
      "Epoch 1256/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6258 - loss: 1.0474 - rmse: 0.3747\n",
      "Epoch 1256: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6273 - loss: 1.0470 - rmse: 0.3745 - val_accuracy: 0.5000 - val_loss: 1.2802 - val_rmse: 0.4187\n",
      "Epoch 1257/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6202 - loss: 1.0474 - rmse: 0.3700\n",
      "Epoch 1257: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6154 - loss: 1.0496 - rmse: 0.3708 - val_accuracy: 0.5000 - val_loss: 1.2975 - val_rmse: 0.4227\n",
      "Epoch 1258/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6183 - loss: 0.9450 - rmse: 0.3525\n",
      "Epoch 1258: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6175 - loss: 0.9483 - rmse: 0.3533 - val_accuracy: 0.5000 - val_loss: 1.2787 - val_rmse: 0.4182\n",
      "Epoch 1259/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6395 - loss: 0.9320 - rmse: 0.3526\n",
      "Epoch 1259: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6384 - loss: 0.9340 - rmse: 0.3529 - val_accuracy: 0.5000 - val_loss: 1.3207 - val_rmse: 0.4317\n",
      "Epoch 1260/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5232 - loss: 1.2052 - rmse: 0.3995\n",
      "Epoch 1260: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5205 - loss: 1.2062 - rmse: 0.3998 - val_accuracy: 0.2000 - val_loss: 1.3358 - val_rmse: 0.4328\n",
      "Epoch 1261/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3712 - loss: 1.1927 - rmse: 0.4075\n",
      "Epoch 1261: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3733 - loss: 1.1920 - rmse: 0.4072 - val_accuracy: 0.3000 - val_loss: 1.4128 - val_rmse: 0.4479\n",
      "Epoch 1262/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6366 - loss: 1.0070 - rmse: 0.3654\n",
      "Epoch 1262: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6364 - loss: 1.0075 - rmse: 0.3656 - val_accuracy: 0.4500 - val_loss: 1.3689 - val_rmse: 0.4357\n",
      "Epoch 1263/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5935 - loss: 1.0265 - rmse: 0.3747\n",
      "Epoch 1263: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5928 - loss: 1.0265 - rmse: 0.3747 - val_accuracy: 0.2000 - val_loss: 1.4471 - val_rmse: 0.4573\n",
      "Epoch 1264/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5586 - loss: 1.0600 - rmse: 0.3749\n",
      "Epoch 1264: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5607 - loss: 1.0565 - rmse: 0.3744 - val_accuracy: 0.5000 - val_loss: 1.3566 - val_rmse: 0.4323\n",
      "Epoch 1265/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4250 - loss: 1.4736 - rmse: 0.4380\n",
      "Epoch 1265: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4205 - loss: 1.4785 - rmse: 0.4387 - val_accuracy: 0.2000 - val_loss: 1.5517 - val_rmse: 0.4533\n",
      "Epoch 1266/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2757 - loss: 1.4962 - rmse: 0.4454\n",
      "Epoch 1266: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.2772 - loss: 1.4961 - rmse: 0.4454 - val_accuracy: 0.3500 - val_loss: 1.4588 - val_rmse: 0.4354\n",
      "Epoch 1267/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.3946 - loss: 1.3745 - rmse: 0.4292\n",
      "Epoch 1267: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.3928 - loss: 1.3736 - rmse: 0.4292 - val_accuracy: 0.3500 - val_loss: 1.3115 - val_rmse: 0.4237\n",
      "Epoch 1268/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.3683 - loss: 1.3482 - rmse: 0.4272\n",
      "Epoch 1268: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.3698 - loss: 1.3457 - rmse: 0.4269 - val_accuracy: 0.3500 - val_loss: 1.3810 - val_rmse: 0.4190\n",
      "Epoch 1269/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3763 - loss: 1.3800 - rmse: 0.4263\n",
      "Epoch 1269: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3768 - loss: 1.3795 - rmse: 0.4263 - val_accuracy: 0.5500 - val_loss: 1.3364 - val_rmse: 0.4187\n",
      "Epoch 1270/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3539 - loss: 1.3492 - rmse: 0.4286\n",
      "Epoch 1270: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.3532 - loss: 1.3487 - rmse: 0.4286 - val_accuracy: 0.3500 - val_loss: 1.3047 - val_rmse: 0.4233\n",
      "Epoch 1271/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1918 - loss: 1.5943 - rmse: 0.4607\n",
      "Epoch 1271: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1979 - loss: 1.5843 - rmse: 0.4594 - val_accuracy: 0.4000 - val_loss: 1.3534 - val_rmse: 0.4249\n",
      "Epoch 1272/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4562 - loss: 1.1972 - rmse: 0.4045\n",
      "Epoch 1272: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4565 - loss: 1.1970 - rmse: 0.4045 - val_accuracy: 0.5500 - val_loss: 1.2080 - val_rmse: 0.4033\n",
      "Epoch 1273/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4644 - loss: 1.1429 - rmse: 0.3970\n",
      "Epoch 1273: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4633 - loss: 1.1449 - rmse: 0.3974 - val_accuracy: 0.5500 - val_loss: 1.1125 - val_rmse: 0.3880\n",
      "Epoch 1274/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.3892 - loss: 1.2807 - rmse: 0.4172\n",
      "Epoch 1274: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.3847 - loss: 1.2854 - rmse: 0.4178 - val_accuracy: 0.4000 - val_loss: 1.2908 - val_rmse: 0.4151\n",
      "Epoch 1275/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.3927 - loss: 1.2680 - rmse: 0.4139\n",
      "Epoch 1275: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.3924 - loss: 1.2679 - rmse: 0.4139 - val_accuracy: 0.4500 - val_loss: 1.3032 - val_rmse: 0.4179\n",
      "Epoch 1276/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4401 - loss: 1.1824 - rmse: 0.3986\n",
      "Epoch 1276: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.4370 - loss: 1.1855 - rmse: 0.3993 - val_accuracy: 0.6000 - val_loss: 1.1889 - val_rmse: 0.4012\n",
      "Epoch 1277/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.3812 - loss: 1.2243 - rmse: 0.4097\n",
      "Epoch 1277: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.3790 - loss: 1.2267 - rmse: 0.4102 - val_accuracy: 0.6000 - val_loss: 1.1103 - val_rmse: 0.3900\n",
      "Epoch 1278/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3458 - loss: 1.2763 - rmse: 0.4177\n",
      "Epoch 1278: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.3479 - loss: 1.2757 - rmse: 0.4176 - val_accuracy: 0.2000 - val_loss: 1.3363 - val_rmse: 0.4270\n",
      "Epoch 1279/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.3217 - loss: 1.3679 - rmse: 0.4327\n",
      "Epoch 1279: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.3213 - loss: 1.3684 - rmse: 0.4327 - val_accuracy: 0.5000 - val_loss: 1.2509 - val_rmse: 0.4135\n",
      "Epoch 1280/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4032 - loss: 1.2910 - rmse: 0.4182\n",
      "Epoch 1280: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4013 - loss: 1.2932 - rmse: 0.4185 - val_accuracy: 0.5000 - val_loss: 1.1921 - val_rmse: 0.4062\n",
      "Epoch 1281/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3520 - loss: 1.3916 - rmse: 0.4256\n",
      "Epoch 1281: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.3521 - loss: 1.3897 - rmse: 0.4255 - val_accuracy: 0.5000 - val_loss: 1.1387 - val_rmse: 0.3959\n",
      "Epoch 1282/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4111 - loss: 1.2365 - rmse: 0.4119\n",
      "Epoch 1282: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4110 - loss: 1.2373 - rmse: 0.4120 - val_accuracy: 0.4500 - val_loss: 1.0867 - val_rmse: 0.3819\n",
      "Epoch 1283/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3996 - loss: 1.3325 - rmse: 0.4219\n",
      "Epoch 1283: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4015 - loss: 1.3292 - rmse: 0.4215 - val_accuracy: 0.5500 - val_loss: 1.0577 - val_rmse: 0.3792\n",
      "Epoch 1284/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4437 - loss: 1.1702 - rmse: 0.3974\n",
      "Epoch 1284: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4453 - loss: 1.1700 - rmse: 0.3974 - val_accuracy: 0.2500 - val_loss: 1.2749 - val_rmse: 0.4155\n",
      "Epoch 1285/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2891 - loss: 1.3981 - rmse: 0.4319\n",
      "Epoch 1285: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.2899 - loss: 1.3994 - rmse: 0.4320 - val_accuracy: 0.4500 - val_loss: 1.2625 - val_rmse: 0.4085\n",
      "Epoch 1286/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2630 - loss: 1.4432 - rmse: 0.4414\n",
      "Epoch 1286: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.2623 - loss: 1.4435 - rmse: 0.4415 - val_accuracy: 0.3500 - val_loss: 1.2579 - val_rmse: 0.4107\n",
      "Epoch 1287/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4084 - loss: 1.2632 - rmse: 0.4163\n",
      "Epoch 1287: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4085 - loss: 1.2634 - rmse: 0.4163 - val_accuracy: 0.3000 - val_loss: 1.3121 - val_rmse: 0.4180\n",
      "Epoch 1288/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3763 - loss: 1.3151 - rmse: 0.4242\n",
      "Epoch 1288: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.3762 - loss: 1.3129 - rmse: 0.4238 - val_accuracy: 0.5500 - val_loss: 1.1324 - val_rmse: 0.3917\n",
      "Epoch 1289/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3843 - loss: 1.2316 - rmse: 0.4112\n",
      "Epoch 1289: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.3859 - loss: 1.2311 - rmse: 0.4111 - val_accuracy: 0.5500 - val_loss: 1.1572 - val_rmse: 0.3991\n",
      "Epoch 1290/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4634 - loss: 1.1849 - rmse: 0.4046\n",
      "Epoch 1290: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4642 - loss: 1.1846 - rmse: 0.4045 - val_accuracy: 0.4500 - val_loss: 1.1466 - val_rmse: 0.3968\n",
      "Epoch 1291/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5372 - loss: 1.1368 - rmse: 0.3926\n",
      "Epoch 1291: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5348 - loss: 1.1375 - rmse: 0.3928 - val_accuracy: 0.6000 - val_loss: 1.0904 - val_rmse: 0.3831\n",
      "Epoch 1292/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4868 - loss: 1.1421 - rmse: 0.3953\n",
      "Epoch 1292: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4860 - loss: 1.1429 - rmse: 0.3955 - val_accuracy: 0.5000 - val_loss: 1.1812 - val_rmse: 0.4067\n",
      "Epoch 1293/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5018 - loss: 1.1317 - rmse: 0.3921\n",
      "Epoch 1293: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5022 - loss: 1.1317 - rmse: 0.3921 - val_accuracy: 0.5500 - val_loss: 1.0970 - val_rmse: 0.3890\n",
      "Epoch 1294/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4753 - loss: 1.1803 - rmse: 0.4023\n",
      "Epoch 1294: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.4781 - loss: 1.1762 - rmse: 0.4016 - val_accuracy: 0.5500 - val_loss: 1.0813 - val_rmse: 0.3829\n",
      "Epoch 1295/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5724 - loss: 1.0750 - rmse: 0.3857\n",
      "Epoch 1295: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5708 - loss: 1.0763 - rmse: 0.3858 - val_accuracy: 0.6000 - val_loss: 1.0768 - val_rmse: 0.3838\n",
      "Epoch 1296/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4483 - loss: 1.1589 - rmse: 0.4000\n",
      "Epoch 1296: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4439 - loss: 1.1655 - rmse: 0.4011 - val_accuracy: 0.5000 - val_loss: 1.2951 - val_rmse: 0.4113\n",
      "Epoch 1297/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3225 - loss: 1.3369 - rmse: 0.4258\n",
      "Epoch 1297: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.3224 - loss: 1.3386 - rmse: 0.4261 - val_accuracy: 0.3500 - val_loss: 1.4859 - val_rmse: 0.4377\n",
      "Epoch 1298/1500\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4217 - loss: 1.3820 - rmse: 0.4290\n",
      "Epoch 1298: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4184 - loss: 1.3818 - rmse: 0.4292 - val_accuracy: 0.4500 - val_loss: 1.3317 - val_rmse: 0.4278\n",
      "Epoch 1299/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.3451 - loss: 1.4046 - rmse: 0.4386\n",
      "Epoch 1299: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.3445 - loss: 1.4041 - rmse: 0.4385 - val_accuracy: 0.3500 - val_loss: 1.3610 - val_rmse: 0.4259\n",
      "Epoch 1300/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.3043 - loss: 1.3709 - rmse: 0.4342\n",
      "Epoch 1300: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.3064 - loss: 1.3698 - rmse: 0.4340 - val_accuracy: 0.4500 - val_loss: 1.2588 - val_rmse: 0.4130\n",
      "Epoch 1301/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4190 - loss: 1.2701 - rmse: 0.4156\n",
      "Epoch 1301: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4223 - loss: 1.2689 - rmse: 0.4154 - val_accuracy: 0.5500 - val_loss: 1.1626 - val_rmse: 0.4009\n",
      "Epoch 1302/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4606 - loss: 1.1673 - rmse: 0.4007\n",
      "Epoch 1302: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4588 - loss: 1.1699 - rmse: 0.4011 - val_accuracy: 0.7000 - val_loss: 0.9797 - val_rmse: 0.3652\n",
      "Epoch 1303/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3558 - loss: 1.5955 - rmse: 0.4407\n",
      "Epoch 1303: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.3552 - loss: 1.5952 - rmse: 0.4408 - val_accuracy: 0.3000 - val_loss: 1.3201 - val_rmse: 0.4272\n",
      "Epoch 1304/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3394 - loss: 1.3805 - rmse: 0.4357\n",
      "Epoch 1304: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.3387 - loss: 1.3800 - rmse: 0.4356 - val_accuracy: 0.2500 - val_loss: 1.3468 - val_rmse: 0.4302\n",
      "Epoch 1305/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2580 - loss: 1.3823 - rmse: 0.4348\n",
      "Epoch 1305: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.2595 - loss: 1.3820 - rmse: 0.4348 - val_accuracy: 0.3000 - val_loss: 1.4102 - val_rmse: 0.4400\n",
      "Epoch 1306/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.3700 - loss: 1.4022 - rmse: 0.4349\n",
      "Epoch 1306: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.3699 - loss: 1.4028 - rmse: 0.4352 - val_accuracy: 0.5000 - val_loss: 1.3254 - val_rmse: 0.4248\n",
      "Epoch 1307/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.3639 - loss: 1.4015 - rmse: 0.4378\n",
      "Epoch 1307: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.3642 - loss: 1.3999 - rmse: 0.4375 - val_accuracy: 0.4000 - val_loss: 1.3485 - val_rmse: 0.4243\n",
      "Epoch 1308/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3452 - loss: 1.2753 - rmse: 0.4188\n",
      "Epoch 1308: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.3467 - loss: 1.2754 - rmse: 0.4189 - val_accuracy: 0.4000 - val_loss: 1.3732 - val_rmse: 0.4324\n",
      "Epoch 1309/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.3669 - loss: 1.2583 - rmse: 0.4173\n",
      "Epoch 1309: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.3680 - loss: 1.2578 - rmse: 0.4172 - val_accuracy: 0.4500 - val_loss: 1.3478 - val_rmse: 0.4277\n",
      "Epoch 1310/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4258 - loss: 1.2698 - rmse: 0.4191\n",
      "Epoch 1310: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.4254 - loss: 1.2700 - rmse: 0.4191 - val_accuracy: 0.3000 - val_loss: 1.3228 - val_rmse: 0.4240\n",
      "Epoch 1311/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4348 - loss: 1.2674 - rmse: 0.4174\n",
      "Epoch 1311: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.4338 - loss: 1.2689 - rmse: 0.4176 - val_accuracy: 0.3500 - val_loss: 1.2508 - val_rmse: 0.4169\n",
      "Epoch 1312/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3573 - loss: 1.3105 - rmse: 0.4258\n",
      "Epoch 1312: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.3583 - loss: 1.3113 - rmse: 0.4258 - val_accuracy: 0.4000 - val_loss: 1.2066 - val_rmse: 0.4109\n",
      "Epoch 1313/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.3543 - loss: 1.3451 - rmse: 0.4280\n",
      "Epoch 1313: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.3535 - loss: 1.3451 - rmse: 0.4279 - val_accuracy: 0.2000 - val_loss: 1.3496 - val_rmse: 0.4333\n",
      "Epoch 1314/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5000 - loss: 1.2248 - rmse: 0.4077\n",
      "Epoch 1314: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.4988 - loss: 1.2252 - rmse: 0.4077 - val_accuracy: 0.3000 - val_loss: 1.3984 - val_rmse: 0.4341\n",
      "Epoch 1315/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.3925 - loss: 1.2240 - rmse: 0.4069\n",
      "Epoch 1315: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.3942 - loss: 1.2231 - rmse: 0.4068 - val_accuracy: 0.3500 - val_loss: 1.3013 - val_rmse: 0.4210\n",
      "Epoch 1316/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5117 - loss: 1.1427 - rmse: 0.3955\n",
      "Epoch 1316: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5112 - loss: 1.1430 - rmse: 0.3956 - val_accuracy: 0.4500 - val_loss: 1.2098 - val_rmse: 0.4044\n",
      "Epoch 1317/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4562 - loss: 1.1707 - rmse: 0.3993\n",
      "Epoch 1317: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.4544 - loss: 1.1728 - rmse: 0.3996 - val_accuracy: 0.4000 - val_loss: 1.3376 - val_rmse: 0.4264\n",
      "Epoch 1318/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2452 - loss: 1.5018 - rmse: 0.4388\n",
      "Epoch 1318: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.2458 - loss: 1.5054 - rmse: 0.4390 - val_accuracy: 0.5500 - val_loss: 1.7190 - val_rmse: 0.4253\n",
      "Epoch 1319/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2780 - loss: 1.8641 - rmse: 0.4632\n",
      "Epoch 1319: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.2786 - loss: 1.8569 - rmse: 0.4628 - val_accuracy: 0.4500 - val_loss: 1.2912 - val_rmse: 0.4125\n",
      "Epoch 1320/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3274 - loss: 1.4224 - rmse: 0.4440\n",
      "Epoch 1320: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.3250 - loss: 1.4225 - rmse: 0.4440 - val_accuracy: 0.4000 - val_loss: 1.2401 - val_rmse: 0.4106\n",
      "Epoch 1321/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3908 - loss: 1.2659 - rmse: 0.4194\n",
      "Epoch 1321: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.3904 - loss: 1.2662 - rmse: 0.4194 - val_accuracy: 0.4500 - val_loss: 1.1876 - val_rmse: 0.4025\n",
      "Epoch 1322/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4179 - loss: 1.1976 - rmse: 0.4079\n",
      "Epoch 1322: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.4182 - loss: 1.1987 - rmse: 0.4081 - val_accuracy: 0.4000 - val_loss: 1.1523 - val_rmse: 0.3955\n",
      "Epoch 1323/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4997 - loss: 1.1324 - rmse: 0.3975\n",
      "Epoch 1323: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.4982 - loss: 1.1337 - rmse: 0.3978 - val_accuracy: 0.4500 - val_loss: 1.1536 - val_rmse: 0.3970\n",
      "Epoch 1324/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4387 - loss: 1.1790 - rmse: 0.4067\n",
      "Epoch 1324: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.4385 - loss: 1.1789 - rmse: 0.4067 - val_accuracy: 0.4000 - val_loss: 1.1473 - val_rmse: 0.3962\n",
      "Epoch 1325/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4215 - loss: 1.1733 - rmse: 0.4058\n",
      "Epoch 1325: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.4216 - loss: 1.1732 - rmse: 0.4058 - val_accuracy: 0.4000 - val_loss: 1.1459 - val_rmse: 0.3959\n",
      "Epoch 1326/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5064 - loss: 1.0922 - rmse: 0.3909\n",
      "Epoch 1326: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5041 - loss: 1.0949 - rmse: 0.3915 - val_accuracy: 0.3500 - val_loss: 1.1903 - val_rmse: 0.4058\n",
      "Epoch 1327/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4982 - loss: 1.1137 - rmse: 0.3965\n",
      "Epoch 1327: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4964 - loss: 1.1154 - rmse: 0.3967 - val_accuracy: 0.3500 - val_loss: 1.2050 - val_rmse: 0.4089\n",
      "Epoch 1328/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4168 - loss: 1.2031 - rmse: 0.4108\n",
      "Epoch 1328: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.4181 - loss: 1.2015 - rmse: 0.4105 - val_accuracy: 0.4000 - val_loss: 1.1973 - val_rmse: 0.4075\n",
      "Epoch 1329/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4734 - loss: 1.1348 - rmse: 0.3969\n",
      "Epoch 1329: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.4732 - loss: 1.1349 - rmse: 0.3970 - val_accuracy: 0.4000 - val_loss: 1.1882 - val_rmse: 0.4058\n",
      "Epoch 1330/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5203 - loss: 1.1167 - rmse: 0.3951\n",
      "Epoch 1330: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.5193 - loss: 1.1171 - rmse: 0.3952 - val_accuracy: 0.4500 - val_loss: 1.1892 - val_rmse: 0.4067\n",
      "Epoch 1331/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5059 - loss: 1.0763 - rmse: 0.3913\n",
      "Epoch 1331: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5053 - loss: 1.0790 - rmse: 0.3916 - val_accuracy: 0.5000 - val_loss: 1.2154 - val_rmse: 0.4126\n",
      "Epoch 1332/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5140 - loss: 1.1249 - rmse: 0.3953\n",
      "Epoch 1332: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.5138 - loss: 1.1247 - rmse: 0.3953 - val_accuracy: 0.4500 - val_loss: 1.2018 - val_rmse: 0.4094\n",
      "Epoch 1333/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5464 - loss: 1.0825 - rmse: 0.3883\n",
      "Epoch 1333: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.5450 - loss: 1.0833 - rmse: 0.3885 - val_accuracy: 0.4500 - val_loss: 1.2004 - val_rmse: 0.4093\n",
      "Epoch 1334/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5185 - loss: 1.1046 - rmse: 0.3942\n",
      "Epoch 1334: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.5180 - loss: 1.1048 - rmse: 0.3942 - val_accuracy: 0.5000 - val_loss: 1.1934 - val_rmse: 0.4080\n",
      "Epoch 1335/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5242 - loss: 1.0763 - rmse: 0.3860\n",
      "Epoch 1335: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.5225 - loss: 1.0781 - rmse: 0.3864 - val_accuracy: 0.4000 - val_loss: 1.1952 - val_rmse: 0.4088\n",
      "Epoch 1336/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 3s/step - accuracy: 0.5703 - loss: 1.0613 - rmse: 0.3829\n",
      "Epoch 1336: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 2s/step - accuracy: 0.5680 - loss: 1.0643 - rmse: 0.3835 - val_accuracy: 0.5000 - val_loss: 1.1844 - val_rmse: 0.4064\n",
      "Epoch 1337/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.4765 - loss: 1.0992 - rmse: 0.3945\n",
      "Epoch 1337: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.4789 - loss: 1.0996 - rmse: 0.3944 - val_accuracy: 0.5000 - val_loss: 1.1817 - val_rmse: 0.4061\n",
      "Epoch 1338/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.4595 - loss: 1.1074 - rmse: 0.3945\n",
      "Epoch 1338: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.4620 - loss: 1.1068 - rmse: 0.3943 - val_accuracy: 0.5000 - val_loss: 1.1764 - val_rmse: 0.4051\n",
      "Epoch 1339/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5893 - loss: 1.0867 - rmse: 0.3875\n",
      "Epoch 1339: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.5878 - loss: 1.0867 - rmse: 0.3876 - val_accuracy: 0.5000 - val_loss: 1.1708 - val_rmse: 0.4039\n",
      "Epoch 1340/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5266 - loss: 1.0709 - rmse: 0.3861\n",
      "Epoch 1340: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.5261 - loss: 1.0713 - rmse: 0.3861 - val_accuracy: 0.4500 - val_loss: 1.1651 - val_rmse: 0.4027\n",
      "Epoch 1341/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5531 - loss: 1.1037 - rmse: 0.3909\n",
      "Epoch 1341: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.5527 - loss: 1.1031 - rmse: 0.3908 - val_accuracy: 0.5500 - val_loss: 1.1371 - val_rmse: 0.3976\n",
      "Epoch 1342/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5933 - loss: 1.0316 - rmse: 0.3818\n",
      "Epoch 1342: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.5917 - loss: 1.0326 - rmse: 0.3819 - val_accuracy: 0.5000 - val_loss: 1.1282 - val_rmse: 0.3957\n",
      "Epoch 1343/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5400 - loss: 1.0552 - rmse: 0.3860\n",
      "Epoch 1343: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.5399 - loss: 1.0557 - rmse: 0.3860 - val_accuracy: 0.5000 - val_loss: 1.1233 - val_rmse: 0.3950\n",
      "Epoch 1344/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.4890 - loss: 1.0741 - rmse: 0.3873\n",
      "Epoch 1344: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.4923 - loss: 1.0731 - rmse: 0.3871 - val_accuracy: 0.5000 - val_loss: 1.1178 - val_rmse: 0.3939\n",
      "Epoch 1345/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.4430 - loss: 1.1415 - rmse: 0.3987\n",
      "Epoch 1345: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.4491 - loss: 1.1375 - rmse: 0.3981 - val_accuracy: 0.5000 - val_loss: 1.0939 - val_rmse: 0.3903\n",
      "Epoch 1346/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5053 - loss: 1.1138 - rmse: 0.3956\n",
      "Epoch 1346: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.5095 - loss: 1.1102 - rmse: 0.3949 - val_accuracy: 0.5000 - val_loss: 1.1058 - val_rmse: 0.3917\n",
      "Epoch 1347/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6396 - loss: 1.0229 - rmse: 0.3770\n",
      "Epoch 1347: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.6384 - loss: 1.0227 - rmse: 0.3770 - val_accuracy: 0.5000 - val_loss: 1.0994 - val_rmse: 0.3904\n",
      "Epoch 1348/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5278 - loss: 1.1463 - rmse: 0.3954\n",
      "Epoch 1348: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.5289 - loss: 1.1451 - rmse: 0.3953 - val_accuracy: 0.6000 - val_loss: 1.2901 - val_rmse: 0.3961\n",
      "Epoch 1349/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6135 - loss: 1.0085 - rmse: 0.3778\n",
      "Epoch 1349: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6119 - loss: 1.0091 - rmse: 0.3779 - val_accuracy: 0.6500 - val_loss: 1.0600 - val_rmse: 0.3856\n",
      "Epoch 1350/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5576 - loss: 0.9711 - rmse: 0.3703\n",
      "Epoch 1350: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.5587 - loss: 0.9716 - rmse: 0.3704 - val_accuracy: 0.6000 - val_loss: 1.1696 - val_rmse: 0.3931\n",
      "Epoch 1351/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.3542 - loss: 1.8893 - rmse: 0.4620\n",
      "Epoch 1351: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.3523 - loss: 1.9180 - rmse: 0.4628 - val_accuracy: 0.1000 - val_loss: 3.2909 - val_rmse: 0.5226\n",
      "Epoch 1352/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.2838 - loss: 2.2130 - rmse: 0.4875\n",
      "Epoch 1352: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.2824 - loss: 2.2094 - rmse: 0.4874 - val_accuracy: 0.2000 - val_loss: 3.5681 - val_rmse: 0.5026\n",
      "Epoch 1353/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.2905 - loss: 2.4217 - rmse: 0.4653\n",
      "Epoch 1353: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.2905 - loss: 2.4066 - rmse: 0.4652 - val_accuracy: 0.1500 - val_loss: 1.7861 - val_rmse: 0.4865\n",
      "Epoch 1354/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.2395 - loss: 1.6674 - rmse: 0.4687\n",
      "Epoch 1354: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.2398 - loss: 1.6721 - rmse: 0.4687 - val_accuracy: 0.4500 - val_loss: 1.2976 - val_rmse: 0.4226\n",
      "Epoch 1355/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.3029 - loss: 1.8365 - rmse: 0.4611\n",
      "Epoch 1355: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.3013 - loss: 1.8378 - rmse: 0.4613 - val_accuracy: 0.1500 - val_loss: 2.0124 - val_rmse: 0.5230\n",
      "Epoch 1356/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.3499 - loss: 1.6122 - rmse: 0.4648\n",
      "Epoch 1356: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.3485 - loss: 1.6096 - rmse: 0.4646 - val_accuracy: 0.2000 - val_loss: 1.4446 - val_rmse: 0.4587\n",
      "Epoch 1357/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.1551 - loss: 1.8341 - rmse: 0.4832\n",
      "Epoch 1357: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.1617 - loss: 1.8226 - rmse: 0.4819 - val_accuracy: 0.5500 - val_loss: 1.2009 - val_rmse: 0.4112\n",
      "Epoch 1358/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5134 - loss: 1.0789 - rmse: 0.3886\n",
      "Epoch 1358: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.5100 - loss: 1.0828 - rmse: 0.3894 - val_accuracy: 0.4000 - val_loss: 1.3366 - val_rmse: 0.4358\n",
      "Epoch 1359/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4455 - loss: 1.1876 - rmse: 0.4027\n",
      "Epoch 1359: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.4413 - loss: 1.1971 - rmse: 0.4041 - val_accuracy: 0.3000 - val_loss: 1.5110 - val_rmse: 0.4492\n",
      "Epoch 1360/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.4256 - loss: 1.3077 - rmse: 0.4124\n",
      "Epoch 1360: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.4277 - loss: 1.3011 - rmse: 0.4118 - val_accuracy: 0.4000 - val_loss: 1.2217 - val_rmse: 0.4130\n",
      "Epoch 1361/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5432 - loss: 1.1050 - rmse: 0.3874\n",
      "Epoch 1361: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.5435 - loss: 1.1045 - rmse: 0.3873 - val_accuracy: 0.5500 - val_loss: 1.1599 - val_rmse: 0.4090\n",
      "Epoch 1362/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6981 - loss: 0.9601 - rmse: 0.3654\n",
      "Epoch 1362: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.6964 - loss: 0.9637 - rmse: 0.3659 - val_accuracy: 0.5500 - val_loss: 1.1190 - val_rmse: 0.4032\n",
      "Epoch 1363/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5963 - loss: 1.0719 - rmse: 0.3871\n",
      "Epoch 1363: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.5974 - loss: 1.0703 - rmse: 0.3867 - val_accuracy: 0.5500 - val_loss: 1.0976 - val_rmse: 0.3979\n",
      "Epoch 1364/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6555 - loss: 1.0035 - rmse: 0.3753\n",
      "Epoch 1364: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.6564 - loss: 1.0032 - rmse: 0.3751 - val_accuracy: 0.6000 - val_loss: 1.0710 - val_rmse: 0.3964\n",
      "Epoch 1365/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6809 - loss: 0.9783 - rmse: 0.3676\n",
      "Epoch 1365: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.6811 - loss: 0.9785 - rmse: 0.3676 - val_accuracy: 0.6000 - val_loss: 1.0660 - val_rmse: 0.3957\n",
      "Epoch 1366/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6385 - loss: 1.0471 - rmse: 0.3765\n",
      "Epoch 1366: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6397 - loss: 1.0435 - rmse: 0.3761 - val_accuracy: 0.6500 - val_loss: 1.0536 - val_rmse: 0.3941\n",
      "Epoch 1367/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7101 - loss: 0.9225 - rmse: 0.3573\n",
      "Epoch 1367: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.7066 - loss: 0.9258 - rmse: 0.3579 - val_accuracy: 0.5500 - val_loss: 1.0584 - val_rmse: 0.3960\n",
      "Epoch 1368/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6987 - loss: 0.9056 - rmse: 0.3555\n",
      "Epoch 1368: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.6962 - loss: 0.9087 - rmse: 0.3561 - val_accuracy: 0.5500 - val_loss: 1.0514 - val_rmse: 0.3942\n",
      "Epoch 1369/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6717 - loss: 0.9473 - rmse: 0.3641\n",
      "Epoch 1369: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.6720 - loss: 0.9477 - rmse: 0.3641 - val_accuracy: 0.6000 - val_loss: 1.0219 - val_rmse: 0.3931\n",
      "Epoch 1370/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6287 - loss: 1.0723 - rmse: 0.3807\n",
      "Epoch 1370: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.6293 - loss: 1.0695 - rmse: 0.3804 - val_accuracy: 0.5500 - val_loss: 1.0331 - val_rmse: 0.3936\n",
      "Epoch 1371/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6360 - loss: 1.0126 - rmse: 0.3766\n",
      "Epoch 1371: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.6365 - loss: 1.0114 - rmse: 0.3763 - val_accuracy: 0.5500 - val_loss: 1.0318 - val_rmse: 0.3932\n",
      "Epoch 1372/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.6757 - loss: 0.9682 - rmse: 0.3656\n",
      "Epoch 1372: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.6756 - loss: 0.9681 - rmse: 0.3656 - val_accuracy: 0.5500 - val_loss: 1.0119 - val_rmse: 0.3908\n",
      "Epoch 1373/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6156 - loss: 0.9547 - rmse: 0.3708\n",
      "Epoch 1373: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.6180 - loss: 0.9542 - rmse: 0.3704 - val_accuracy: 0.5500 - val_loss: 0.9880 - val_rmse: 0.3882\n",
      "Epoch 1374/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7087 - loss: 0.8895 - rmse: 0.3542\n",
      "Epoch 1374: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.7072 - loss: 0.8926 - rmse: 0.3548 - val_accuracy: 0.6000 - val_loss: 0.9859 - val_rmse: 0.3879\n",
      "Epoch 1375/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7241 - loss: 0.9208 - rmse: 0.3571\n",
      "Epoch 1375: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.7225 - loss: 0.9216 - rmse: 0.3574 - val_accuracy: 0.5500 - val_loss: 0.9736 - val_rmse: 0.3858\n",
      "Epoch 1376/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7363 - loss: 0.9331 - rmse: 0.3584\n",
      "Epoch 1376: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.7333 - loss: 0.9332 - rmse: 0.3586 - val_accuracy: 0.5500 - val_loss: 0.9634 - val_rmse: 0.3834\n",
      "Epoch 1377/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6195 - loss: 0.9572 - rmse: 0.3680\n",
      "Epoch 1377: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.6193 - loss: 0.9582 - rmse: 0.3682 - val_accuracy: 0.5500 - val_loss: 0.9202 - val_rmse: 0.3792\n",
      "Epoch 1378/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6371 - loss: 0.9558 - rmse: 0.3669\n",
      "Epoch 1378: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.6390 - loss: 0.9553 - rmse: 0.3668 - val_accuracy: 0.6500 - val_loss: 1.1030 - val_rmse: 0.3946\n",
      "Epoch 1379/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7115 - loss: 0.9295 - rmse: 0.3569\n",
      "Epoch 1379: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7109 - loss: 0.9301 - rmse: 0.3570 - val_accuracy: 0.6000 - val_loss: 1.1037 - val_rmse: 0.3938\n",
      "Epoch 1380/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7535 - loss: 0.8842 - rmse: 0.3506\n",
      "Epoch 1380: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7521 - loss: 0.8860 - rmse: 0.3509 - val_accuracy: 0.6000 - val_loss: 1.0906 - val_rmse: 0.3907\n",
      "Epoch 1381/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6363 - loss: 1.0111 - rmse: 0.3756\n",
      "Epoch 1381: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.6377 - loss: 1.0092 - rmse: 0.3752 - val_accuracy: 0.6000 - val_loss: 1.0870 - val_rmse: 0.3902\n",
      "Epoch 1382/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6962 - loss: 0.8762 - rmse: 0.3439\n",
      "Epoch 1382: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6927 - loss: 0.8796 - rmse: 0.3449 - val_accuracy: 0.6000 - val_loss: 1.0873 - val_rmse: 0.3916\n",
      "Epoch 1383/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6824 - loss: 0.9297 - rmse: 0.3638\n",
      "Epoch 1383: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.6823 - loss: 0.9306 - rmse: 0.3638 - val_accuracy: 0.6000 - val_loss: 1.0670 - val_rmse: 0.3870\n",
      "Epoch 1384/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6420 - loss: 0.9631 - rmse: 0.3661\n",
      "Epoch 1384: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.6449 - loss: 0.9610 - rmse: 0.3657 - val_accuracy: 0.6500 - val_loss: 1.0514 - val_rmse: 0.3832\n",
      "Epoch 1385/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6407 - loss: 0.9301 - rmse: 0.3636\n",
      "Epoch 1385: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.6421 - loss: 0.9299 - rmse: 0.3634 - val_accuracy: 0.6000 - val_loss: 1.0208 - val_rmse: 0.3825\n",
      "Epoch 1386/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7298 - loss: 0.8726 - rmse: 0.3469\n",
      "Epoch 1386: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.7293 - loss: 0.8738 - rmse: 0.3471 - val_accuracy: 0.6500 - val_loss: 1.0139 - val_rmse: 0.3807\n",
      "Epoch 1387/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7051 - loss: 0.9107 - rmse: 0.3532\n",
      "Epoch 1387: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.7045 - loss: 0.9111 - rmse: 0.3535 - val_accuracy: 0.6000 - val_loss: 1.0292 - val_rmse: 0.3798\n",
      "Epoch 1388/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7145 - loss: 0.9022 - rmse: 0.3530\n",
      "Epoch 1388: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.7140 - loss: 0.9026 - rmse: 0.3531 - val_accuracy: 0.6500 - val_loss: 1.0057 - val_rmse: 0.3796\n",
      "Epoch 1389/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6926 - loss: 0.9533 - rmse: 0.3582\n",
      "Epoch 1389: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.6921 - loss: 0.9524 - rmse: 0.3582 - val_accuracy: 0.6000 - val_loss: 1.0262 - val_rmse: 0.3788\n",
      "Epoch 1390/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7073 - loss: 0.9184 - rmse: 0.3565\n",
      "Epoch 1390: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7076 - loss: 0.9181 - rmse: 0.3564 - val_accuracy: 0.6000 - val_loss: 1.0002 - val_rmse: 0.3794\n",
      "Epoch 1391/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6957 - loss: 0.9486 - rmse: 0.3573\n",
      "Epoch 1391: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.6956 - loss: 0.9460 - rmse: 0.3570 - val_accuracy: 0.6000 - val_loss: 1.0115 - val_rmse: 0.3795\n",
      "Epoch 1392/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6547 - loss: 0.9160 - rmse: 0.3603\n",
      "Epoch 1392: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.6558 - loss: 0.9157 - rmse: 0.3601 - val_accuracy: 0.6500 - val_loss: 0.9942 - val_rmse: 0.3762\n",
      "Epoch 1393/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7110 - loss: 0.9221 - rmse: 0.3550\n",
      "Epoch 1393: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.7111 - loss: 0.9214 - rmse: 0.3549 - val_accuracy: 0.6000 - val_loss: 0.9912 - val_rmse: 0.3757\n",
      "Epoch 1394/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7265 - loss: 0.8628 - rmse: 0.3449\n",
      "Epoch 1394: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.7232 - loss: 0.8650 - rmse: 0.3454 - val_accuracy: 0.6500 - val_loss: 0.9912 - val_rmse: 0.3757\n",
      "Epoch 1395/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7632 - loss: 0.8339 - rmse: 0.3372\n",
      "Epoch 1395: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.7621 - loss: 0.8358 - rmse: 0.3376 - val_accuracy: 0.6000 - val_loss: 0.9890 - val_rmse: 0.3752\n",
      "Epoch 1396/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7621 - loss: 0.8053 - rmse: 0.3355\n",
      "Epoch 1396: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.7573 - loss: 0.8103 - rmse: 0.3364 - val_accuracy: 0.6000 - val_loss: 1.0088 - val_rmse: 0.3750\n",
      "Epoch 1397/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6225 - loss: 0.8955 - rmse: 0.3574\n",
      "Epoch 1397: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.6256 - loss: 0.8957 - rmse: 0.3571 - val_accuracy: 0.6500 - val_loss: 0.9860 - val_rmse: 0.3735\n",
      "Epoch 1398/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7371 - loss: 0.8129 - rmse: 0.3392\n",
      "Epoch 1398: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.7361 - loss: 0.8152 - rmse: 0.3396 - val_accuracy: 0.6000 - val_loss: 0.9755 - val_rmse: 0.3732\n",
      "Epoch 1399/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6480 - loss: 0.9548 - rmse: 0.3627\n",
      "Epoch 1399: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.6491 - loss: 0.9532 - rmse: 0.3624 - val_accuracy: 0.7000 - val_loss: 0.9753 - val_rmse: 0.3705\n",
      "Epoch 1400/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7273 - loss: 0.8236 - rmse: 0.3372\n",
      "Epoch 1400: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7266 - loss: 0.8254 - rmse: 0.3376 - val_accuracy: 0.7000 - val_loss: 0.9783 - val_rmse: 0.3709\n",
      "Epoch 1401/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6943 - loss: 0.8813 - rmse: 0.3484\n",
      "Epoch 1401: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6943 - loss: 0.8812 - rmse: 0.3484 - val_accuracy: 0.6000 - val_loss: 0.9681 - val_rmse: 0.3716\n",
      "Epoch 1402/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6547 - loss: 0.9185 - rmse: 0.3561\n",
      "Epoch 1402: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6584 - loss: 0.9161 - rmse: 0.3555 - val_accuracy: 0.6500 - val_loss: 0.9499 - val_rmse: 0.3649\n",
      "Epoch 1403/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6738 - loss: 0.8855 - rmse: 0.3485\n",
      "Epoch 1403: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6740 - loss: 0.8852 - rmse: 0.3485 - val_accuracy: 0.6000 - val_loss: 0.9436 - val_rmse: 0.3676\n",
      "Epoch 1404/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6808 - loss: 0.8847 - rmse: 0.3474\n",
      "Epoch 1404: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.6810 - loss: 0.8839 - rmse: 0.3473 - val_accuracy: 0.7000 - val_loss: 0.9243 - val_rmse: 0.3593\n",
      "Epoch 1405/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7107 - loss: 0.8615 - rmse: 0.3372\n",
      "Epoch 1405: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.7104 - loss: 0.8613 - rmse: 0.3374 - val_accuracy: 0.6500 - val_loss: 0.9343 - val_rmse: 0.3610\n",
      "Epoch 1406/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6206 - loss: 0.9448 - rmse: 0.3652\n",
      "Epoch 1406: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.6228 - loss: 0.9426 - rmse: 0.3647 - val_accuracy: 0.7000 - val_loss: 0.9275 - val_rmse: 0.3619\n",
      "Epoch 1407/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6908 - loss: 0.9007 - rmse: 0.3467\n",
      "Epoch 1407: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.6921 - loss: 0.8982 - rmse: 0.3465 - val_accuracy: 0.6500 - val_loss: 0.9202 - val_rmse: 0.3599\n",
      "Epoch 1408/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6711 - loss: 0.8866 - rmse: 0.3446\n",
      "Epoch 1408: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.6716 - loss: 0.8848 - rmse: 0.3445 - val_accuracy: 0.6500 - val_loss: 0.9358 - val_rmse: 0.3634\n",
      "Epoch 1409/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7015 - loss: 0.9091 - rmse: 0.3498\n",
      "Epoch 1409: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.7026 - loss: 0.9064 - rmse: 0.3494 - val_accuracy: 0.7000 - val_loss: 0.9209 - val_rmse: 0.3594\n",
      "Epoch 1410/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7589 - loss: 0.8196 - rmse: 0.3322\n",
      "Epoch 1410: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.7569 - loss: 0.8218 - rmse: 0.3327 - val_accuracy: 0.7500 - val_loss: 0.9351 - val_rmse: 0.3585\n",
      "Epoch 1411/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7342 - loss: 0.9124 - rmse: 0.3488\n",
      "Epoch 1411: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.7343 - loss: 0.9090 - rmse: 0.3484 - val_accuracy: 0.6500 - val_loss: 0.9253 - val_rmse: 0.3576\n",
      "Epoch 1412/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7423 - loss: 0.8584 - rmse: 0.3397\n",
      "Epoch 1412: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.7421 - loss: 0.8578 - rmse: 0.3396 - val_accuracy: 0.6000 - val_loss: 0.9748 - val_rmse: 0.3724\n",
      "Epoch 1413/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6304 - loss: 0.9292 - rmse: 0.3588\n",
      "Epoch 1413: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.6327 - loss: 0.9254 - rmse: 0.3580 - val_accuracy: 0.5500 - val_loss: 1.2927 - val_rmse: 0.4072\n",
      "Epoch 1414/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6468 - loss: 0.8854 - rmse: 0.3501\n",
      "Epoch 1414: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6479 - loss: 0.8852 - rmse: 0.3500 - val_accuracy: 0.6000 - val_loss: 1.1247 - val_rmse: 0.3867\n",
      "Epoch 1415/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7018 - loss: 0.8037 - rmse: 0.3292\n",
      "Epoch 1415: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.7014 - loss: 0.8050 - rmse: 0.3295 - val_accuracy: 0.5500 - val_loss: 1.2155 - val_rmse: 0.4041\n",
      "Epoch 1416/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6880 - loss: 0.8671 - rmse: 0.3452\n",
      "Epoch 1416: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.6876 - loss: 0.8670 - rmse: 0.3452 - val_accuracy: 0.6000 - val_loss: 1.1989 - val_rmse: 0.3980\n",
      "Epoch 1417/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6839 - loss: 0.8373 - rmse: 0.3401\n",
      "Epoch 1417: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.6851 - loss: 0.8368 - rmse: 0.3399 - val_accuracy: 0.5500 - val_loss: 1.1801 - val_rmse: 0.3911\n",
      "Epoch 1418/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6974 - loss: 0.8743 - rmse: 0.3417\n",
      "Epoch 1418: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.6981 - loss: 0.8727 - rmse: 0.3414 - val_accuracy: 0.6000 - val_loss: 1.1797 - val_rmse: 0.3928\n",
      "Epoch 1419/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6906 - loss: 0.8209 - rmse: 0.3368\n",
      "Epoch 1419: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.6889 - loss: 0.8233 - rmse: 0.3373 - val_accuracy: 0.5500 - val_loss: 1.2883 - val_rmse: 0.4151\n",
      "Epoch 1420/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7030 - loss: 0.7805 - rmse: 0.3256\n",
      "Epoch 1420: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.7020 - loss: 0.7820 - rmse: 0.3260 - val_accuracy: 0.6000 - val_loss: 0.8948 - val_rmse: 0.3658\n",
      "Epoch 1421/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5767 - loss: 0.9583 - rmse: 0.3713\n",
      "Epoch 1421: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.5782 - loss: 0.9566 - rmse: 0.3708 - val_accuracy: 0.7500 - val_loss: 0.7877 - val_rmse: 0.3378\n",
      "Epoch 1422/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6603 - loss: 0.8646 - rmse: 0.3488\n",
      "Epoch 1422: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.6582 - loss: 0.8688 - rmse: 0.3496 - val_accuracy: 0.5000 - val_loss: 1.1611 - val_rmse: 0.4069\n",
      "Epoch 1423/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5087 - loss: 1.0720 - rmse: 0.3939\n",
      "Epoch 1423: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.5113 - loss: 1.0688 - rmse: 0.3933 - val_accuracy: 0.5500 - val_loss: 0.9213 - val_rmse: 0.3775\n",
      "Epoch 1424/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5394 - loss: 0.9302 - rmse: 0.3685\n",
      "Epoch 1424: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.5429 - loss: 0.9302 - rmse: 0.3682 - val_accuracy: 0.6000 - val_loss: 1.0362 - val_rmse: 0.3789\n",
      "Epoch 1425/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6928 - loss: 0.8981 - rmse: 0.3531\n",
      "Epoch 1425: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.6921 - loss: 0.8980 - rmse: 0.3531 - val_accuracy: 0.6500 - val_loss: 0.8679 - val_rmse: 0.3624\n",
      "Epoch 1426/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6984 - loss: 0.8106 - rmse: 0.3351\n",
      "Epoch 1426: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.6967 - loss: 0.8141 - rmse: 0.3359 - val_accuracy: 0.6500 - val_loss: 0.9806 - val_rmse: 0.3669\n",
      "Epoch 1427/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6861 - loss: 0.9192 - rmse: 0.3523\n",
      "Epoch 1427: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.6869 - loss: 0.9160 - rmse: 0.3519 - val_accuracy: 0.6000 - val_loss: 1.1215 - val_rmse: 0.3889\n",
      "Epoch 1428/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7432 - loss: 0.8233 - rmse: 0.3322\n",
      "Epoch 1428: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.7420 - loss: 0.8236 - rmse: 0.3324 - val_accuracy: 0.5500 - val_loss: 1.1355 - val_rmse: 0.3885\n",
      "Epoch 1429/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7186 - loss: 0.8226 - rmse: 0.3341\n",
      "Epoch 1429: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.7188 - loss: 0.8224 - rmse: 0.3341 - val_accuracy: 0.6000 - val_loss: 1.1183 - val_rmse: 0.3856\n",
      "Epoch 1430/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7049 - loss: 0.8015 - rmse: 0.3215\n",
      "Epoch 1430: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.7036 - loss: 0.8023 - rmse: 0.3221 - val_accuracy: 0.5000 - val_loss: 1.1598 - val_rmse: 0.3970\n",
      "Epoch 1431/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6261 - loss: 0.8858 - rmse: 0.3533\n",
      "Epoch 1431: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.6287 - loss: 0.8838 - rmse: 0.3528 - val_accuracy: 0.6000 - val_loss: 1.0912 - val_rmse: 0.3798\n",
      "Epoch 1432/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6547 - loss: 0.8112 - rmse: 0.3328\n",
      "Epoch 1432: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.6580 - loss: 0.8098 - rmse: 0.3324 - val_accuracy: 0.6000 - val_loss: 1.1723 - val_rmse: 0.3990\n",
      "Epoch 1433/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7250 - loss: 0.7929 - rmse: 0.3314\n",
      "Epoch 1433: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.7219 - loss: 0.7974 - rmse: 0.3323 - val_accuracy: 0.5000 - val_loss: 1.2275 - val_rmse: 0.4233\n",
      "Epoch 1434/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.4872 - loss: 1.3301 - rmse: 0.4306\n",
      "Epoch 1434: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.4883 - loss: 1.3281 - rmse: 0.4303 - val_accuracy: 0.4500 - val_loss: 1.3011 - val_rmse: 0.4102\n",
      "Epoch 1435/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5933 - loss: 0.9744 - rmse: 0.3698\n",
      "Epoch 1435: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.5938 - loss: 0.9755 - rmse: 0.3699 - val_accuracy: 0.5500 - val_loss: 1.2523 - val_rmse: 0.4022\n",
      "Epoch 1436/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.6106 - loss: 1.0549 - rmse: 0.3772\n",
      "Epoch 1436: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.6106 - loss: 1.0539 - rmse: 0.3771 - val_accuracy: 0.4500 - val_loss: 1.3523 - val_rmse: 0.4215\n",
      "Epoch 1437/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6235 - loss: 1.0001 - rmse: 0.3702\n",
      "Epoch 1437: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.6228 - loss: 1.0004 - rmse: 0.3702 - val_accuracy: 0.4500 - val_loss: 1.3478 - val_rmse: 0.4207\n",
      "Epoch 1438/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5930 - loss: 0.9500 - rmse: 0.3632\n",
      "Epoch 1438: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.5929 - loss: 0.9528 - rmse: 0.3636 - val_accuracy: 0.4500 - val_loss: 1.3094 - val_rmse: 0.4178\n",
      "Epoch 1439/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6692 - loss: 0.9652 - rmse: 0.3633\n",
      "Epoch 1439: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.6670 - loss: 0.9661 - rmse: 0.3635 - val_accuracy: 0.5000 - val_loss: 1.2084 - val_rmse: 0.4053\n",
      "Epoch 1440/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6273 - loss: 0.9706 - rmse: 0.3633\n",
      "Epoch 1440: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.6271 - loss: 0.9708 - rmse: 0.3633 - val_accuracy: 0.5000 - val_loss: 1.1745 - val_rmse: 0.4008\n",
      "Epoch 1441/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6722 - loss: 0.9421 - rmse: 0.3577\n",
      "Epoch 1441: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.6716 - loss: 0.9428 - rmse: 0.3579 - val_accuracy: 0.4500 - val_loss: 1.1834 - val_rmse: 0.4002\n",
      "Epoch 1442/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5874 - loss: 1.0640 - rmse: 0.3818\n",
      "Epoch 1442: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.5891 - loss: 1.0612 - rmse: 0.3813 - val_accuracy: 0.5000 - val_loss: 1.1681 - val_rmse: 0.3987\n",
      "Epoch 1443/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6479 - loss: 0.9269 - rmse: 0.3583\n",
      "Epoch 1443: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.6455 - loss: 0.9284 - rmse: 0.3585 - val_accuracy: 0.5000 - val_loss: 1.2053 - val_rmse: 0.4041\n",
      "Epoch 1444/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5919 - loss: 1.0113 - rmse: 0.3736\n",
      "Epoch 1444: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.5934 - loss: 1.0101 - rmse: 0.3733 - val_accuracy: 0.4500 - val_loss: 1.1647 - val_rmse: 0.4008\n",
      "Epoch 1445/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6501 - loss: 0.9574 - rmse: 0.3639\n",
      "Epoch 1445: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.6503 - loss: 0.9575 - rmse: 0.3638 - val_accuracy: 0.5000 - val_loss: 1.1567 - val_rmse: 0.3976\n",
      "Epoch 1446/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6070 - loss: 0.9919 - rmse: 0.3671\n",
      "Epoch 1446: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.6083 - loss: 0.9908 - rmse: 0.3670 - val_accuracy: 0.4500 - val_loss: 1.1505 - val_rmse: 0.4001\n",
      "Epoch 1447/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5828 - loss: 0.9350 - rmse: 0.3585\n",
      "Epoch 1447: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.5855 - loss: 0.9365 - rmse: 0.3587 - val_accuracy: 0.5000 - val_loss: 1.1415 - val_rmse: 0.3972\n",
      "Epoch 1448/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6649 - loss: 0.9125 - rmse: 0.3571\n",
      "Epoch 1448: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.6650 - loss: 0.9149 - rmse: 0.3573 - val_accuracy: 0.5000 - val_loss: 1.1256 - val_rmse: 0.3959\n",
      "Epoch 1449/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6018 - loss: 0.9655 - rmse: 0.3643\n",
      "Epoch 1449: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.6024 - loss: 0.9653 - rmse: 0.3643 - val_accuracy: 0.4500 - val_loss: 1.1341 - val_rmse: 0.3978\n",
      "Epoch 1450/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5479 - loss: 1.0374 - rmse: 0.3740\n",
      "Epoch 1450: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.5517 - loss: 1.0339 - rmse: 0.3734 - val_accuracy: 0.5500 - val_loss: 1.1217 - val_rmse: 0.3942\n",
      "Epoch 1451/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6157 - loss: 0.9654 - rmse: 0.3629\n",
      "Epoch 1451: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.6158 - loss: 0.9664 - rmse: 0.3631 - val_accuracy: 0.4500 - val_loss: 1.1175 - val_rmse: 0.3935\n",
      "Epoch 1452/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6005 - loss: 1.0043 - rmse: 0.3726\n",
      "Epoch 1452: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.6003 - loss: 1.0046 - rmse: 0.3725 - val_accuracy: 0.5000 - val_loss: 1.0705 - val_rmse: 0.3836\n",
      "Epoch 1453/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5558 - loss: 1.0270 - rmse: 0.3711\n",
      "Epoch 1453: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.5577 - loss: 1.0270 - rmse: 0.3712 - val_accuracy: 0.6000 - val_loss: 1.1117 - val_rmse: 0.3903\n",
      "Epoch 1454/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5504 - loss: 1.0499 - rmse: 0.3781\n",
      "Epoch 1454: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.5499 - loss: 1.0504 - rmse: 0.3782 - val_accuracy: 0.4000 - val_loss: 1.2014 - val_rmse: 0.4062\n",
      "Epoch 1455/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5196 - loss: 1.0764 - rmse: 0.3830\n",
      "Epoch 1455: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.5227 - loss: 1.0721 - rmse: 0.3823 - val_accuracy: 0.5500 - val_loss: 1.0534 - val_rmse: 0.3829\n",
      "Epoch 1456/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6215 - loss: 0.9868 - rmse: 0.3703\n",
      "Epoch 1456: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.6213 - loss: 0.9855 - rmse: 0.3699 - val_accuracy: 0.4500 - val_loss: 1.0954 - val_rmse: 0.3920\n",
      "Epoch 1457/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5653 - loss: 1.0294 - rmse: 0.3810\n",
      "Epoch 1457: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.5665 - loss: 1.0283 - rmse: 0.3807 - val_accuracy: 0.5000 - val_loss: 1.0631 - val_rmse: 0.3866\n",
      "Epoch 1458/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6409 - loss: 0.9115 - rmse: 0.3532\n",
      "Epoch 1458: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6370 - loss: 0.9161 - rmse: 0.3542 - val_accuracy: 0.4500 - val_loss: 1.0589 - val_rmse: 0.3866\n",
      "Epoch 1459/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6601 - loss: 0.9659 - rmse: 0.3652\n",
      "Epoch 1459: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6567 - loss: 0.9678 - rmse: 0.3656 - val_accuracy: 0.4500 - val_loss: 1.2061 - val_rmse: 0.4148\n",
      "Epoch 1460/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5892 - loss: 0.9543 - rmse: 0.3640\n",
      "Epoch 1460: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.5894 - loss: 0.9547 - rmse: 0.3641 - val_accuracy: 0.4500 - val_loss: 1.1910 - val_rmse: 0.4113\n",
      "Epoch 1461/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6234 - loss: 0.9142 - rmse: 0.3559\n",
      "Epoch 1461: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.6201 - loss: 0.9182 - rmse: 0.3567 - val_accuracy: 0.4000 - val_loss: 1.2556 - val_rmse: 0.4240\n",
      "Epoch 1462/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6119 - loss: 0.9252 - rmse: 0.3549\n",
      "Epoch 1462: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.6111 - loss: 0.9267 - rmse: 0.3553 - val_accuracy: 0.4500 - val_loss: 1.2022 - val_rmse: 0.4149\n",
      "Epoch 1463/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6057 - loss: 0.9830 - rmse: 0.3673\n",
      "Epoch 1463: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.6063 - loss: 0.9804 - rmse: 0.3668 - val_accuracy: 0.4000 - val_loss: 1.2086 - val_rmse: 0.4136\n",
      "Epoch 1464/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5291 - loss: 1.0365 - rmse: 0.3792\n",
      "Epoch 1464: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.5321 - loss: 1.0338 - rmse: 0.3787 - val_accuracy: 0.4000 - val_loss: 1.2046 - val_rmse: 0.4106\n",
      "Epoch 1465/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5702 - loss: 0.9518 - rmse: 0.3609\n",
      "Epoch 1465: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.5702 - loss: 0.9526 - rmse: 0.3611 - val_accuracy: 0.4000 - val_loss: 1.2667 - val_rmse: 0.4264\n",
      "Epoch 1466/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6553 - loss: 0.8820 - rmse: 0.3485\n",
      "Epoch 1466: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6540 - loss: 0.8834 - rmse: 0.3488 - val_accuracy: 0.4500 - val_loss: 1.2055 - val_rmse: 0.4092\n",
      "Epoch 1467/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6244 - loss: 0.9076 - rmse: 0.3569\n",
      "Epoch 1467: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.6252 - loss: 0.9088 - rmse: 0.3571 - val_accuracy: 0.4000 - val_loss: 1.2117 - val_rmse: 0.4115\n",
      "Epoch 1468/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5743 - loss: 0.9776 - rmse: 0.3621\n",
      "Epoch 1468: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.5743 - loss: 0.9785 - rmse: 0.3622 - val_accuracy: 0.4000 - val_loss: 1.2420 - val_rmse: 0.4149\n",
      "Epoch 1469/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6578 - loss: 0.9061 - rmse: 0.3502\n",
      "Epoch 1469: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6565 - loss: 0.9069 - rmse: 0.3504 - val_accuracy: 0.5000 - val_loss: 1.1728 - val_rmse: 0.4026\n",
      "Epoch 1470/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6207 - loss: 0.9252 - rmse: 0.3596\n",
      "Epoch 1470: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.6210 - loss: 0.9253 - rmse: 0.3596 - val_accuracy: 0.4500 - val_loss: 1.1688 - val_rmse: 0.4012\n",
      "Epoch 1471/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5462 - loss: 0.9968 - rmse: 0.3742\n",
      "Epoch 1471: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.5454 - loss: 0.9997 - rmse: 0.3746 - val_accuracy: 0.4000 - val_loss: 1.2204 - val_rmse: 0.4123\n",
      "Epoch 1472/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6034 - loss: 0.9574 - rmse: 0.3616\n",
      "Epoch 1472: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.6019 - loss: 0.9588 - rmse: 0.3618 - val_accuracy: 0.5000 - val_loss: 1.1539 - val_rmse: 0.4018\n",
      "Epoch 1473/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6410 - loss: 0.8767 - rmse: 0.3481\n",
      "Epoch 1473: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.6408 - loss: 0.8770 - rmse: 0.3482 - val_accuracy: 0.5500 - val_loss: 1.1072 - val_rmse: 0.3938\n",
      "Epoch 1474/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6404 - loss: 0.8403 - rmse: 0.3417\n",
      "Epoch 1474: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6388 - loss: 0.8437 - rmse: 0.3423 - val_accuracy: 0.4500 - val_loss: 1.1370 - val_rmse: 0.3995\n",
      "Epoch 1475/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6289 - loss: 0.9272 - rmse: 0.3602\n",
      "Epoch 1475: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6287 - loss: 0.9263 - rmse: 0.3600 - val_accuracy: 0.3500 - val_loss: 1.2776 - val_rmse: 0.4241\n",
      "Epoch 1476/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6847 - loss: 0.8864 - rmse: 0.3510\n",
      "Epoch 1476: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.6842 - loss: 0.8862 - rmse: 0.3509 - val_accuracy: 0.5500 - val_loss: 1.1123 - val_rmse: 0.3954\n",
      "Epoch 1477/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6770 - loss: 0.8180 - rmse: 0.3368\n",
      "Epoch 1477: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6768 - loss: 0.8202 - rmse: 0.3372 - val_accuracy: 0.4500 - val_loss: 1.1177 - val_rmse: 0.3977\n",
      "Epoch 1478/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6703 - loss: 0.8088 - rmse: 0.3348\n",
      "Epoch 1478: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6700 - loss: 0.8098 - rmse: 0.3350 - val_accuracy: 0.5000 - val_loss: 1.1678 - val_rmse: 0.4064\n",
      "Epoch 1479/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7315 - loss: 0.7797 - rmse: 0.3303\n",
      "Epoch 1479: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.7314 - loss: 0.7796 - rmse: 0.3302 - val_accuracy: 0.5500 - val_loss: 1.1155 - val_rmse: 0.3921\n",
      "Epoch 1480/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6762 - loss: 0.8597 - rmse: 0.3420\n",
      "Epoch 1480: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.6756 - loss: 0.8594 - rmse: 0.3420 - val_accuracy: 0.5500 - val_loss: 1.0696 - val_rmse: 0.3856\n",
      "Epoch 1481/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5679 - loss: 1.0369 - rmse: 0.3676\n",
      "Epoch 1481: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.5706 - loss: 1.0344 - rmse: 0.3673 - val_accuracy: 0.5000 - val_loss: 1.0568 - val_rmse: 0.3927\n",
      "Epoch 1482/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5566 - loss: 1.1545 - rmse: 0.3836\n",
      "Epoch 1482: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.5547 - loss: 1.1619 - rmse: 0.3846 - val_accuracy: 0.4500 - val_loss: 1.6822 - val_rmse: 0.4455\n",
      "Epoch 1483/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4831 - loss: 1.5633 - rmse: 0.4282\n",
      "Epoch 1483: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.4825 - loss: 1.5603 - rmse: 0.4282 - val_accuracy: 0.4500 - val_loss: 1.4102 - val_rmse: 0.4350\n",
      "Epoch 1484/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4334 - loss: 1.4286 - rmse: 0.4325\n",
      "Epoch 1484: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.4347 - loss: 1.4258 - rmse: 0.4321 - val_accuracy: 0.2500 - val_loss: 1.7094 - val_rmse: 0.4806\n",
      "Epoch 1485/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4077 - loss: 1.6966 - rmse: 0.4575\n",
      "Epoch 1485: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.4101 - loss: 1.6851 - rmse: 0.4563 - val_accuracy: 0.4000 - val_loss: 1.2487 - val_rmse: 0.4211\n",
      "Epoch 1486/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3920 - loss: 1.3030 - rmse: 0.4176\n",
      "Epoch 1486: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.3889 - loss: 1.3103 - rmse: 0.4186 - val_accuracy: 0.5500 - val_loss: 1.2418 - val_rmse: 0.4113\n",
      "Epoch 1487/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4393 - loss: 1.5871 - rmse: 0.4534\n",
      "Epoch 1487: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.4422 - loss: 1.5826 - rmse: 0.4526 - val_accuracy: 0.5000 - val_loss: 1.1613 - val_rmse: 0.3976\n",
      "Epoch 1488/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4230 - loss: 1.4984 - rmse: 0.4290\n",
      "Epoch 1488: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.4221 - loss: 1.4982 - rmse: 0.4291 - val_accuracy: 0.4000 - val_loss: 1.3941 - val_rmse: 0.4319\n",
      "Epoch 1489/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5113 - loss: 1.3102 - rmse: 0.4126\n",
      "Epoch 1489: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.5081 - loss: 1.3122 - rmse: 0.4129 - val_accuracy: 0.5500 - val_loss: 1.1525 - val_rmse: 0.3995\n",
      "Epoch 1490/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4760 - loss: 1.2993 - rmse: 0.4146\n",
      "Epoch 1490: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.4759 - loss: 1.2983 - rmse: 0.4146 - val_accuracy: 0.4500 - val_loss: 1.2212 - val_rmse: 0.4120\n",
      "Epoch 1491/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.4236 - loss: 1.3457 - rmse: 0.4173\n",
      "Epoch 1491: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.4258 - loss: 1.3486 - rmse: 0.4176 - val_accuracy: 0.4000 - val_loss: 1.1831 - val_rmse: 0.4061\n",
      "Epoch 1492/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.3548 - loss: 1.4648 - rmse: 0.4417\n",
      "Epoch 1492: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.3574 - loss: 1.4618 - rmse: 0.4412 - val_accuracy: 0.4000 - val_loss: 1.1363 - val_rmse: 0.4011\n",
      "Epoch 1493/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3715 - loss: 1.3594 - rmse: 0.4286\n",
      "Epoch 1493: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.3725 - loss: 1.3581 - rmse: 0.4285 - val_accuracy: 0.4000 - val_loss: 1.2103 - val_rmse: 0.4144\n",
      "Epoch 1494/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4744 - loss: 1.2337 - rmse: 0.4108\n",
      "Epoch 1494: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.4758 - loss: 1.2342 - rmse: 0.4111 - val_accuracy: 0.4500 - val_loss: 1.1462 - val_rmse: 0.3923\n",
      "Epoch 1495/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4366 - loss: 1.2887 - rmse: 0.4209\n",
      "Epoch 1495: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.4378 - loss: 1.2876 - rmse: 0.4207 - val_accuracy: 0.4500 - val_loss: 1.1406 - val_rmse: 0.3962\n",
      "Epoch 1496/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4118 - loss: 1.2330 - rmse: 0.4089\n",
      "Epoch 1496: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.4121 - loss: 1.2322 - rmse: 0.4088 - val_accuracy: 0.4500 - val_loss: 1.1544 - val_rmse: 0.4019\n",
      "Epoch 1497/1500\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4461 - loss: 1.1894 - rmse: 0.4018\n",
      "Epoch 1497: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.4449 - loss: 1.1882 - rmse: 0.4017 - val_accuracy: 0.4000 - val_loss: 1.1892 - val_rmse: 0.4066\n",
      "Epoch 1498/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4467 - loss: 1.1108 - rmse: 0.3930\n",
      "Epoch 1498: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.4470 - loss: 1.1119 - rmse: 0.3932 - val_accuracy: 0.4500 - val_loss: 1.1822 - val_rmse: 0.4055\n",
      "Epoch 1499/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.3847 - loss: 1.1932 - rmse: 0.4064\n",
      "Epoch 1499: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.3865 - loss: 1.1917 - rmse: 0.4062 - val_accuracy: 0.4000 - val_loss: 1.1943 - val_rmse: 0.4077\n",
      "Epoch 1500/1500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.4932 - loss: 1.1348 - rmse: 0.3964\n",
      "Epoch 1500: val_loss did not improve from 0.72543\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.4932 - loss: 1.1347 - rmse: 0.3964 - val_accuracy: 0.3500 - val_loss: 1.1890 - val_rmse: 0.4094\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6070 - loss: 0.9917 - rmse: 0.3544 \n",
      "Test Loss: 0.9980, Test Accuracy: 0.6136, Test RMSE: 0.3534\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "# Compile the model\n",
    "rnn_model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy', tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "\n",
    "# Create a ModelCheckpoint callback to save the best model\n",
    "rnn_checkpoint = ModelCheckpoint(\"best_rnn_model_weights.keras\", monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "\n",
    "# Train the model with ModelCheckpoint callback\n",
    "rnn_history = rnn_model.fit(x_train, y_train, epochs=1500, batch_size=4, validation_data=(x_val, y_val), callbacks=[rnn_checkpoint], verbose=1)\n",
    "\n",
    "# Load the best model weights\n",
    "rnn_model.load_weights(\"best_rnn_model_weights.keras\")\n",
    "\n",
    "# Save training history to a file\n",
    "np.save('rnn_history', rnn_history.history)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy, rmse = rnn_model.evaluate(x_test, y_test)\n",
    "print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}, Test RMSE: {rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14ea6f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the saved history\n",
    "rnn_history = np.load('rnn_history.npy', allow_pickle='TRUE').item()\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(rnn_history['accuracy'])\n",
    "plt.plot(rnn_history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(rnn_history['loss'])\n",
    "plt.plot(rnn_history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim(0, 1.5)\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot RMSE vs epoch\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(rnn_history['rmse'])\n",
    "plt.title('Root Mean Squared Error (RMSE) vs Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('RMSE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fc67922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = rnn_model.predict(x_test)\n",
    "y_val_pred = rnn_model.predict(x_val)\n",
    "y_train_pred = rnn_model.predict(x_train)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis = 1)\n",
    "y_test_classes = np.argmax(y_test, axis = 1)\n",
    "y_val_pred_classes = np.argmax(y_val_pred, axis = 1)\n",
    "y_val_classes = np.argmax(y_val, axis = 1)\n",
    "y_train_pred_classes = np.argmax(y_train_pred, axis = 1)\n",
    "y_train_classes = np.argmax(y_train, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70818418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a confusion matrix\n",
    "conf_matrix_1 = confusion_matrix(y_train_classes, y_train_pred_classes)\n",
    "conf_matrix_2 = confusion_matrix(y_val_classes, y_val_pred_classes)\n",
    "conf_matrix_3 = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "\n",
    "# Visualize the confusion matrix for training data\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.heatmap(conf_matrix_1, annot=True, fmt='d', cmap='Blues', xticklabels=[1, 2, 3, 4], yticklabels=[1, 2, 3, 4])\n",
    "plt.xlabel('Training Class')\n",
    "plt.ylabel('Predicted Training Class')\n",
    "plt.title('Confusion Matrix for Training Data')\n",
    "\n",
    "# Visualize the confusion matrix for validation data\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.heatmap(conf_matrix_2, annot=True, fmt='d', cmap='Blues', xticklabels=[1, 2, 3, 4], yticklabels=[1, 2, 3, 4])\n",
    "plt.xlabel('Validation Class')\n",
    "plt.ylabel('Predicted Validation Class')\n",
    "plt.title('Confusion Matrix for Validation Data')\n",
    "\n",
    "# Visualize the confusion matrix for testing data\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.heatmap(conf_matrix_3, annot=True, fmt='d', cmap='Blues', xticklabels=[1, 2, 3, 4], yticklabels=[1, 2, 3, 4])\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('True Class')\n",
    "plt.title('Confusion Matrix for Testing Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d9dfc7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Epoch: 363, Best Validation Loss: 0.7254, Best Validation Accuracy: 0.7000\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy and loss when the model performed best\n",
    "best_epoch = np.argmin(rnn_history['val_loss'])\n",
    "best_val_loss = rnn_history['val_loss'][best_epoch]\n",
    "best_val_accuracy = rnn_history['val_accuracy'][best_epoch]\n",
    "\n",
    "print(f'Best Epoch: {best_epoch + 1}, Best Validation Loss: {best_val_loss:.4f}, Best Validation Accuracy: {best_val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e659b43e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
